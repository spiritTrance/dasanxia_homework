{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入实验环境"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import sys\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import mindspore\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.nn as nn\n",
    "from mindspore import context\n",
    "from mindspore.nn.metrics import Accuracy\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor, TimeMonitor\n",
    "from mindspore import Tensor\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target='CPU') \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = edict({\n",
    "    # 'train_size': 60000,  # 训练集大小\n",
    "    # 'test_size': 10000,  # 测试集大小\n",
    "    'train_size': 600,  # 训练集大小\n",
    "    'test_size': 100,  # 测试集大小\n",
    "    'channel': 1,  # 图片通道数\n",
    "    'image_height': 28,  # 图片高度\n",
    "    'image_width': 28,  # 图片宽度\n",
    "    'batch_size': 64,\n",
    "    'num_classes': 10,  # 分类类别\n",
    "    'lr': 0.001,  # 学习率\n",
    "    'epoch_size': 1,  # 训练次数\n",
    "    'data_dir_train': os.path.join('fashion-mnist', 'train'),\n",
    "    'data_dir_test': os.path.join('fashion-mnist', 'test'),\n",
    "}) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据读取和预处理"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 步骤 1\t定义函数用于读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(file_name):\n",
    "    '''\n",
    "    :param file_name: 文件路径\n",
    "    :return:  训练或者测试数据\n",
    "    如下是训练的图片的二进制格式\n",
    "    [offset] [type]          [value]          [description]\n",
    "    0000     32 bit integer  0x00000803(2051) magic number\n",
    "    0004     32 bit integer  60000            number of images\n",
    "    0008     32 bit integer  28               number of rows\n",
    "    0012     32 bit integer  28               number of columns\n",
    "    0016     unsigned byte   ??               pixel\n",
    "    0017     unsigned byte   ??               pixel\n",
    "    ........\n",
    "    xxxx     unsigned byte   ??               pixel\n",
    "    '''\n",
    "    file_handle = open(file_name, \"rb\")  # 以二进制打开文档\n",
    "    file_content = file_handle.read()  # 读取到缓冲区中\n",
    "    head = struct.unpack_from('>IIII', file_content, 0)  # 取前4个整数，返回一个元组\n",
    "    offset = struct.calcsize('>IIII')\n",
    "    imgNum = head[1]  # 图片数\n",
    "    width = head[2]  # 宽度\n",
    "    height = head[3]  # 高度\n",
    "    bits = imgNum * width * height  # data一共有60000*28*28个像素值\n",
    "    bitsString = '>' + str(bits) + 'B'  # fmt格式：'>47040000B'\n",
    "    imgs = struct.unpack_from(bitsString, file_content, offset)  # 取data数据，返回一个元组\n",
    "    imgs_array = np.array(imgs, np.float32).reshape((imgNum, width * height))  # 最后将读取的数据reshape成 【图片数，图片像素】二维数组\n",
    "    return imgs_array\n",
    "\n",
    "\n",
    "def read_label(file_name):\n",
    "    '''\n",
    "    :param file_name:\n",
    "    :return:\n",
    "    标签的格式如下：\n",
    "    [offset] [type]          [value]          [description]\n",
    "    0000     32 bit integer  0x00000801(2049) magic number (MSB first)\n",
    "    0004     32 bit integer  60000            number of items\n",
    "    0008     unsigned byte   ??               label\n",
    "    0009     unsigned byte   ??               label\n",
    "    ........\n",
    "    xxxx     unsigned byte   ??               label\n",
    "    The labels values are 0 to 9.\n",
    "    '''\n",
    "    file_handle = open(file_name, \"rb\")  # 以二进制打开文档\n",
    "    file_content = file_handle.read()  # 读取到缓冲区中\n",
    "    head = struct.unpack_from('>II', file_content, 0)  # 取前2个整数，返回一个元组\n",
    "    offset = struct.calcsize('>II')\n",
    "    labelNum = head[1]  # label数\n",
    "    bitsString = '>' + str(labelNum) + 'B'  # fmt格式：'>47040000B'\n",
    "    label = struct.unpack_from(bitsString, file_content, offset)  # 取data数据，返回一个元组\n",
    "    return np.array(label, np.int32)\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    # 文件获取\n",
    "    train_image = os.path.join(cfg.data_dir_train, 'train-images-idx3-ubyte')\n",
    "    test_image = os.path.join(cfg.data_dir_test, \"t10k-images-idx3-ubyte\")\n",
    "    train_label = os.path.join(cfg.data_dir_train, \"train-labels-idx1-ubyte\")\n",
    "    test_label = os.path.join(cfg.data_dir_test, \"t10k-labels-idx1-ubyte\")\n",
    "    # 读取数据\n",
    "    train_x = read_image(train_image)\n",
    "    test_x = read_image(test_image)\n",
    "    train_y = read_label(train_label)\n",
    "    test_y = read_label(test_label)\n",
    "    return train_x, train_y, test_x, test_y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据集样本数： 60000\n",
      "测试数据集样本数： 10000\n",
      "通道数/图像长/宽： (1, 28, 28)\n",
      "一张图像的标签样式： 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y = get_data()\n",
    "train_x = train_x.reshape(-1, 1, cfg.image_height, cfg.image_width)\n",
    "test_x = test_x.reshape(-1, 1, cfg.image_height, cfg.image_width)\n",
    "train_x = train_x / 255.0\n",
    "test_x = test_x / 255.0\n",
    "\n",
    "print('训练数据集样本数：', train_x.shape[0])\n",
    "print('测试数据集样本数：', test_y.shape[0])\n",
    "print('通道数/图像长/宽：', train_x.shape[1:])\n",
    "print('一张图像的标签样式：', train_y[0])  # 一共10类，用0-9的数字表达类别。\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(train_x[0,0,...])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据集预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换数据类型为Dataset\n",
    "def create_dataset():\n",
    "    XY_train = list(zip(train_x, train_y))\n",
    "    ds_train = ds.GeneratorDataset(XY_train, ['x', 'y'])\n",
    "    ds_train = ds_train.shuffle(buffer_size=1000).batch(cfg.batch_size, drop_remainder=True)\n",
    "    XY_test = list(zip(test_x, test_y))\n",
    "    ds_test = ds.GeneratorDataset(XY_test, ['x', 'y'])\n",
    "    ds_test = ds_test.shuffle(buffer_size=1000).batch(cfg.batch_size, drop_remainder=True)\n",
    "    return ds_train, ds_test \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义卷积神经网络，BaseLine\n",
    "class ForwardFashion(nn.Cell):\n",
    "    def __init__(self, num_class=10):  # 一共分十类，图片通道数是1\n",
    "        super(ForwardFashion, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.conv1 = nn.Conv2d(1, 32,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "        self.conv2 = nn.Conv2d(32, 64,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "        self.conv3 = nn.Conv2d(64, 128,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "        self.maxpool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Dense(128 * 11 * 11, 128)\n",
    "        self.fc2 = nn.Dense(128, self.num_class)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2d(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义卷积神经网络，有正则化\n",
    "class ForwardFashionRegularization(nn.Cell):\n",
    "    def __init__(self, num_class=10):  # 一共分十类，图片通道数是1\n",
    "        super(ForwardFashionRegularization, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.conv1 = nn.Conv2d(1, 32,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "        self.conv2 = nn.Conv2d(32, 64,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "        self.conv3 = nn.Conv2d(64, 128,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "        self.maxpool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Dense(3200, 128)\n",
    "        self.bn = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Dense(128, self.num_class)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2d(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2d(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义卷积神经网络，有Dropout正则化\n",
    "class ForwardFashionWithDropout(nn.Cell):\n",
    "    def __init__(self, num_class=10):  # 一共分十类，图片通道数是1\n",
    "        super(ForwardFashionWithDropout, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.conv1 = nn.Conv2d(1, 32,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "        self.conv2 = nn.Conv2d(32, 64,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "        self.conv3 = nn.Conv2d(64, 128,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "        self.maxpool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Dense(3200, 128)\n",
    "        self.fc2 = nn.Dense(128, self.num_class)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2d(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2d(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 启动训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Net):\n",
    "    ds_train, ds_test = create_dataset()\n",
    "    # 构建网络\n",
    "    network = Net(cfg.num_classes)\n",
    "    # 定义模型的损失函数，优化器\n",
    "    net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\n",
    "    net_opt = nn.Adam(network.trainable_params(), cfg.lr)\n",
    "    # 训练模型\n",
    "    model = Model(network, loss_fn=net_loss, optimizer=net_opt, metrics={'acc': Accuracy()})\n",
    "    loss_cb = LossMonitor()\n",
    "    print(\"============== Starting Training ==============\")\n",
    "    model.train(cfg.epoch_size, ds_train, callbacks=[loss_cb], dataset_sink_mode=True)\n",
    "    # 验证\n",
    "    metric = model.eval(ds_test)\n",
    "    print(metric)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Training ==============\n",
      "epoch: 1 step: 1, loss is 2.3025851249694824\n",
      "epoch: 1 step: 2, loss is 2.3024115562438965\n",
      "epoch: 1 step: 3, loss is 2.3024981021881104\n",
      "epoch: 1 step: 4, loss is 2.3017826080322266\n",
      "epoch: 1 step: 5, loss is 2.300419569015503\n",
      "epoch: 1 step: 6, loss is 2.2962634563446045\n",
      "epoch: 1 step: 7, loss is 2.279592752456665\n",
      "epoch: 1 step: 8, loss is 2.263939142227173\n",
      "epoch: 1 step: 9, loss is 2.2377941608428955\n",
      "epoch: 1 step: 10, loss is 2.165936231613159\n",
      "epoch: 1 step: 11, loss is 2.0613808631896973\n",
      "epoch: 1 step: 12, loss is 1.9758968353271484\n",
      "epoch: 1 step: 13, loss is 1.841408610343933\n",
      "epoch: 1 step: 14, loss is 1.7683721780776978\n",
      "epoch: 1 step: 15, loss is 1.435143232345581\n",
      "epoch: 1 step: 16, loss is 1.137600064277649\n",
      "epoch: 1 step: 17, loss is 1.6107063293457031\n",
      "epoch: 1 step: 18, loss is 1.3166133165359497\n",
      "epoch: 1 step: 19, loss is 1.108257532119751\n",
      "epoch: 1 step: 20, loss is 1.2429336309432983\n",
      "epoch: 1 step: 21, loss is 1.4975557327270508\n",
      "epoch: 1 step: 22, loss is 1.0430744886398315\n",
      "epoch: 1 step: 23, loss is 1.3100993633270264\n",
      "epoch: 1 step: 24, loss is 1.1712182760238647\n",
      "epoch: 1 step: 25, loss is 1.0822616815567017\n",
      "epoch: 1 step: 26, loss is 1.1754930019378662\n",
      "epoch: 1 step: 27, loss is 0.9335957765579224\n",
      "epoch: 1 step: 28, loss is 1.198169231414795\n",
      "epoch: 1 step: 29, loss is 1.1015616655349731\n",
      "epoch: 1 step: 30, loss is 0.9768542051315308\n",
      "epoch: 1 step: 31, loss is 1.019232153892517\n",
      "epoch: 1 step: 32, loss is 1.0857813358306885\n",
      "epoch: 1 step: 33, loss is 1.210749626159668\n",
      "epoch: 1 step: 34, loss is 1.3092633485794067\n",
      "epoch: 1 step: 35, loss is 1.2195016145706177\n",
      "epoch: 1 step: 36, loss is 1.013898253440857\n",
      "epoch: 1 step: 37, loss is 1.0102567672729492\n",
      "epoch: 1 step: 38, loss is 1.0936216115951538\n",
      "epoch: 1 step: 39, loss is 1.0025959014892578\n",
      "epoch: 1 step: 40, loss is 0.9967981576919556\n",
      "epoch: 1 step: 41, loss is 1.0379343032836914\n",
      "epoch: 1 step: 42, loss is 0.7999228835105896\n",
      "epoch: 1 step: 43, loss is 0.9011515378952026\n",
      "epoch: 1 step: 44, loss is 0.8064178824424744\n",
      "epoch: 1 step: 45, loss is 1.0986822843551636\n",
      "epoch: 1 step: 46, loss is 0.9788650870323181\n",
      "epoch: 1 step: 47, loss is 0.6877329349517822\n",
      "epoch: 1 step: 48, loss is 0.8964042663574219\n",
      "epoch: 1 step: 49, loss is 0.6927467584609985\n",
      "epoch: 1 step: 50, loss is 1.1362286806106567\n",
      "epoch: 1 step: 51, loss is 0.8732380270957947\n",
      "epoch: 1 step: 52, loss is 1.2007522583007812\n",
      "epoch: 1 step: 53, loss is 1.144183874130249\n",
      "epoch: 1 step: 54, loss is 0.8260635733604431\n",
      "epoch: 1 step: 55, loss is 0.8252952098846436\n",
      "epoch: 1 step: 56, loss is 0.8645696640014648\n",
      "epoch: 1 step: 57, loss is 0.7960712909698486\n",
      "epoch: 1 step: 58, loss is 0.9040221571922302\n",
      "epoch: 1 step: 59, loss is 0.8313300013542175\n",
      "epoch: 1 step: 60, loss is 0.8869890570640564\n",
      "epoch: 1 step: 61, loss is 1.0049982070922852\n",
      "epoch: 1 step: 62, loss is 0.691939651966095\n",
      "epoch: 1 step: 63, loss is 0.8071767091751099\n",
      "epoch: 1 step: 64, loss is 0.9451525211334229\n",
      "epoch: 1 step: 65, loss is 1.0398906469345093\n",
      "epoch: 1 step: 66, loss is 0.7190499305725098\n",
      "epoch: 1 step: 67, loss is 1.0445595979690552\n",
      "epoch: 1 step: 68, loss is 0.7034260630607605\n",
      "epoch: 1 step: 69, loss is 0.9577748775482178\n",
      "epoch: 1 step: 70, loss is 0.8342830538749695\n",
      "epoch: 1 step: 71, loss is 1.076361894607544\n",
      "epoch: 1 step: 72, loss is 0.6933413147926331\n",
      "epoch: 1 step: 73, loss is 0.9247701168060303\n",
      "epoch: 1 step: 74, loss is 0.7939679622650146\n",
      "epoch: 1 step: 75, loss is 0.7853676080703735\n",
      "epoch: 1 step: 76, loss is 0.7233548164367676\n",
      "epoch: 1 step: 77, loss is 0.8264066576957703\n",
      "epoch: 1 step: 78, loss is 0.9018977880477905\n",
      "epoch: 1 step: 79, loss is 0.6459662914276123\n",
      "epoch: 1 step: 80, loss is 0.8223913311958313\n",
      "epoch: 1 step: 81, loss is 0.859819769859314\n",
      "epoch: 1 step: 82, loss is 0.7889602780342102\n",
      "epoch: 1 step: 83, loss is 0.771938681602478\n",
      "epoch: 1 step: 84, loss is 0.48574644327163696\n",
      "epoch: 1 step: 85, loss is 0.7681835889816284\n",
      "epoch: 1 step: 86, loss is 0.7209176421165466\n",
      "epoch: 1 step: 87, loss is 0.7187040448188782\n",
      "epoch: 1 step: 88, loss is 0.6013532280921936\n",
      "epoch: 1 step: 89, loss is 0.7157543897628784\n",
      "epoch: 1 step: 90, loss is 0.5163282752037048\n",
      "epoch: 1 step: 91, loss is 0.5940107107162476\n",
      "epoch: 1 step: 92, loss is 0.8051691651344299\n",
      "epoch: 1 step: 93, loss is 0.5295707583427429\n",
      "epoch: 1 step: 94, loss is 0.8630924820899963\n",
      "epoch: 1 step: 95, loss is 0.5699713826179504\n",
      "epoch: 1 step: 96, loss is 0.7567411065101624\n",
      "epoch: 1 step: 97, loss is 0.48181548714637756\n",
      "epoch: 1 step: 98, loss is 0.5267273783683777\n",
      "epoch: 1 step: 99, loss is 0.5552140474319458\n",
      "epoch: 1 step: 100, loss is 0.5564138293266296\n",
      "epoch: 1 step: 101, loss is 0.8225575089454651\n",
      "epoch: 1 step: 102, loss is 0.6080836653709412\n",
      "epoch: 1 step: 103, loss is 0.5942725539207458\n",
      "epoch: 1 step: 104, loss is 0.4922260046005249\n",
      "epoch: 1 step: 105, loss is 0.7864219546318054\n",
      "epoch: 1 step: 106, loss is 0.9852521419525146\n",
      "epoch: 1 step: 107, loss is 0.5541313886642456\n",
      "epoch: 1 step: 108, loss is 0.6834374070167542\n",
      "epoch: 1 step: 109, loss is 0.6929017901420593\n",
      "epoch: 1 step: 110, loss is 0.7143498063087463\n",
      "epoch: 1 step: 111, loss is 0.5248827934265137\n",
      "epoch: 1 step: 112, loss is 0.789193332195282\n",
      "epoch: 1 step: 113, loss is 0.6719540953636169\n",
      "epoch: 1 step: 114, loss is 0.6268616914749146\n",
      "epoch: 1 step: 115, loss is 0.7407875061035156\n",
      "epoch: 1 step: 116, loss is 0.5889456868171692\n",
      "epoch: 1 step: 117, loss is 0.8580220937728882\n",
      "epoch: 1 step: 118, loss is 0.5466036796569824\n",
      "epoch: 1 step: 119, loss is 0.5923011302947998\n",
      "epoch: 1 step: 120, loss is 0.8152178525924683\n",
      "epoch: 1 step: 121, loss is 0.6442744731903076\n",
      "epoch: 1 step: 122, loss is 0.6421869993209839\n",
      "epoch: 1 step: 123, loss is 0.6324437260627747\n",
      "epoch: 1 step: 124, loss is 0.735624372959137\n",
      "epoch: 1 step: 125, loss is 0.6706729531288147\n",
      "epoch: 1 step: 126, loss is 0.5955044627189636\n",
      "epoch: 1 step: 127, loss is 0.7971440553665161\n",
      "epoch: 1 step: 128, loss is 0.7680071592330933\n",
      "epoch: 1 step: 129, loss is 0.6786565780639648\n",
      "epoch: 1 step: 130, loss is 0.6229141354560852\n",
      "epoch: 1 step: 131, loss is 0.5604609251022339\n",
      "epoch: 1 step: 132, loss is 0.5344277024269104\n",
      "epoch: 1 step: 133, loss is 0.5243370532989502\n",
      "epoch: 1 step: 134, loss is 0.3930525779724121\n",
      "epoch: 1 step: 135, loss is 0.7945117354393005\n",
      "epoch: 1 step: 136, loss is 0.4946069121360779\n",
      "epoch: 1 step: 137, loss is 0.9164473414421082\n",
      "epoch: 1 step: 138, loss is 0.811059296131134\n",
      "epoch: 1 step: 139, loss is 0.602175235748291\n",
      "epoch: 1 step: 140, loss is 0.5384207367897034\n",
      "epoch: 1 step: 141, loss is 0.5652334094047546\n",
      "epoch: 1 step: 142, loss is 0.6558800339698792\n",
      "epoch: 1 step: 143, loss is 0.8489854335784912\n",
      "epoch: 1 step: 144, loss is 0.6433403491973877\n",
      "epoch: 1 step: 145, loss is 0.6569198369979858\n",
      "epoch: 1 step: 146, loss is 0.6043864488601685\n",
      "epoch: 1 step: 147, loss is 0.4438340961933136\n",
      "epoch: 1 step: 148, loss is 0.5771703124046326\n",
      "epoch: 1 step: 149, loss is 0.5930287837982178\n",
      "epoch: 1 step: 150, loss is 0.8736748695373535\n",
      "epoch: 1 step: 151, loss is 0.4437073767185211\n",
      "epoch: 1 step: 152, loss is 0.6133917570114136\n",
      "epoch: 1 step: 153, loss is 0.38534456491470337\n",
      "epoch: 1 step: 154, loss is 0.8108964562416077\n",
      "epoch: 1 step: 155, loss is 0.6253189444541931\n",
      "epoch: 1 step: 156, loss is 0.5520498752593994\n",
      "epoch: 1 step: 157, loss is 0.5706183314323425\n",
      "epoch: 1 step: 158, loss is 0.6105393171310425\n",
      "epoch: 1 step: 159, loss is 0.6866334080696106\n",
      "epoch: 1 step: 160, loss is 0.5651822686195374\n",
      "epoch: 1 step: 161, loss is 0.6147800087928772\n",
      "epoch: 1 step: 162, loss is 0.5546427369117737\n",
      "epoch: 1 step: 163, loss is 0.5254218578338623\n",
      "epoch: 1 step: 164, loss is 0.5815243721008301\n",
      "epoch: 1 step: 165, loss is 0.6919645667076111\n",
      "epoch: 1 step: 166, loss is 0.5302700400352478\n",
      "epoch: 1 step: 167, loss is 0.6006948351860046\n",
      "epoch: 1 step: 168, loss is 0.6870743632316589\n",
      "epoch: 1 step: 169, loss is 0.5700881481170654\n",
      "epoch: 1 step: 170, loss is 0.6728699207305908\n",
      "epoch: 1 step: 171, loss is 0.7007701396942139\n",
      "epoch: 1 step: 172, loss is 0.46229881048202515\n",
      "epoch: 1 step: 173, loss is 0.6143938899040222\n",
      "epoch: 1 step: 174, loss is 0.6984418630599976\n",
      "epoch: 1 step: 175, loss is 0.7680472135543823\n",
      "epoch: 1 step: 176, loss is 0.6331058144569397\n",
      "epoch: 1 step: 177, loss is 0.4555874764919281\n",
      "epoch: 1 step: 178, loss is 0.4165714383125305\n",
      "epoch: 1 step: 179, loss is 0.5954097509384155\n",
      "epoch: 1 step: 180, loss is 0.6427536010742188\n",
      "epoch: 1 step: 181, loss is 0.46962499618530273\n",
      "epoch: 1 step: 182, loss is 0.4730125069618225\n",
      "epoch: 1 step: 183, loss is 0.6380017399787903\n",
      "epoch: 1 step: 184, loss is 0.3370511531829834\n",
      "epoch: 1 step: 185, loss is 0.6292951107025146\n",
      "epoch: 1 step: 186, loss is 0.4004534184932709\n",
      "epoch: 1 step: 187, loss is 0.3483184278011322\n",
      "epoch: 1 step: 188, loss is 0.6192416548728943\n",
      "epoch: 1 step: 189, loss is 0.5733094215393066\n",
      "epoch: 1 step: 190, loss is 0.45987963676452637\n",
      "epoch: 1 step: 191, loss is 0.6981323957443237\n",
      "epoch: 1 step: 192, loss is 0.5433598160743713\n",
      "epoch: 1 step: 193, loss is 0.5563194155693054\n",
      "epoch: 1 step: 194, loss is 0.6029611229896545\n",
      "epoch: 1 step: 195, loss is 0.6771261692047119\n",
      "epoch: 1 step: 196, loss is 0.6627750992774963\n",
      "epoch: 1 step: 197, loss is 0.47466692328453064\n",
      "epoch: 1 step: 198, loss is 0.38983502984046936\n",
      "epoch: 1 step: 199, loss is 0.5630642175674438\n",
      "epoch: 1 step: 200, loss is 0.6292898058891296\n",
      "epoch: 1 step: 201, loss is 0.48342812061309814\n",
      "epoch: 1 step: 202, loss is 0.5399001836776733\n",
      "epoch: 1 step: 203, loss is 0.6483008861541748\n",
      "epoch: 1 step: 204, loss is 0.6533843278884888\n",
      "epoch: 1 step: 205, loss is 0.6979197263717651\n",
      "epoch: 1 step: 206, loss is 0.44303467869758606\n",
      "epoch: 1 step: 207, loss is 0.7246983051300049\n",
      "epoch: 1 step: 208, loss is 0.5385419726371765\n",
      "epoch: 1 step: 209, loss is 0.5056507587432861\n",
      "epoch: 1 step: 210, loss is 0.6031620502471924\n",
      "epoch: 1 step: 211, loss is 0.5158283710479736\n",
      "epoch: 1 step: 212, loss is 0.4531007409095764\n",
      "epoch: 1 step: 213, loss is 0.5356941223144531\n",
      "epoch: 1 step: 214, loss is 0.5249335169792175\n",
      "epoch: 1 step: 215, loss is 0.5271558165550232\n",
      "epoch: 1 step: 216, loss is 0.4079182744026184\n",
      "epoch: 1 step: 217, loss is 0.5081391930580139\n",
      "epoch: 1 step: 218, loss is 0.3825438916683197\n",
      "epoch: 1 step: 219, loss is 0.47591155767440796\n",
      "epoch: 1 step: 220, loss is 0.42884695529937744\n",
      "epoch: 1 step: 221, loss is 0.3771533668041229\n",
      "epoch: 1 step: 222, loss is 0.38496989011764526\n",
      "epoch: 1 step: 223, loss is 0.42583057284355164\n",
      "epoch: 1 step: 224, loss is 0.4816925823688507\n",
      "epoch: 1 step: 225, loss is 0.5957873463630676\n",
      "epoch: 1 step: 226, loss is 0.41014423966407776\n",
      "epoch: 1 step: 227, loss is 0.5740292072296143\n",
      "epoch: 1 step: 228, loss is 0.2972075343132019\n",
      "epoch: 1 step: 229, loss is 0.39656856656074524\n",
      "epoch: 1 step: 230, loss is 0.47270944714546204\n",
      "epoch: 1 step: 231, loss is 0.631851077079773\n",
      "epoch: 1 step: 232, loss is 0.5225651860237122\n",
      "epoch: 1 step: 233, loss is 0.5331349968910217\n",
      "epoch: 1 step: 234, loss is 0.5350829362869263\n",
      "epoch: 1 step: 235, loss is 0.5593381524085999\n",
      "epoch: 1 step: 236, loss is 0.6126567125320435\n",
      "epoch: 1 step: 237, loss is 0.6690244078636169\n",
      "epoch: 1 step: 238, loss is 0.5122232437133789\n",
      "epoch: 1 step: 239, loss is 0.45780932903289795\n",
      "epoch: 1 step: 240, loss is 0.42980697751045227\n",
      "epoch: 1 step: 241, loss is 0.4948996901512146\n",
      "epoch: 1 step: 242, loss is 0.29926082491874695\n",
      "epoch: 1 step: 243, loss is 0.3731718361377716\n",
      "epoch: 1 step: 244, loss is 0.6453486084938049\n",
      "epoch: 1 step: 245, loss is 0.4126800298690796\n",
      "epoch: 1 step: 246, loss is 0.626843273639679\n",
      "epoch: 1 step: 247, loss is 0.4262557625770569\n",
      "epoch: 1 step: 248, loss is 0.5738285779953003\n",
      "epoch: 1 step: 249, loss is 0.6692399978637695\n",
      "epoch: 1 step: 250, loss is 0.44341182708740234\n",
      "epoch: 1 step: 251, loss is 0.7565235495567322\n",
      "epoch: 1 step: 252, loss is 0.3810908794403076\n",
      "epoch: 1 step: 253, loss is 0.5783759951591492\n",
      "epoch: 1 step: 254, loss is 0.5034536719322205\n",
      "epoch: 1 step: 255, loss is 0.5587002038955688\n",
      "epoch: 1 step: 256, loss is 0.3972678780555725\n",
      "epoch: 1 step: 257, loss is 0.5596818327903748\n",
      "epoch: 1 step: 258, loss is 0.538104236125946\n",
      "epoch: 1 step: 259, loss is 0.6692636013031006\n",
      "epoch: 1 step: 260, loss is 0.5355929136276245\n",
      "epoch: 1 step: 261, loss is 0.3976796269416809\n",
      "epoch: 1 step: 262, loss is 0.38843661546707153\n",
      "epoch: 1 step: 263, loss is 0.32495439052581787\n",
      "epoch: 1 step: 264, loss is 0.3623090386390686\n",
      "epoch: 1 step: 265, loss is 0.5117101073265076\n",
      "epoch: 1 step: 266, loss is 0.4830462634563446\n",
      "epoch: 1 step: 267, loss is 0.5262198448181152\n",
      "epoch: 1 step: 268, loss is 0.5294775366783142\n",
      "epoch: 1 step: 269, loss is 0.5485149025917053\n",
      "epoch: 1 step: 270, loss is 0.42610281705856323\n",
      "epoch: 1 step: 271, loss is 0.4083425998687744\n",
      "epoch: 1 step: 272, loss is 0.4103469252586365\n",
      "epoch: 1 step: 273, loss is 0.4517388641834259\n",
      "epoch: 1 step: 274, loss is 0.663386881351471\n",
      "epoch: 1 step: 275, loss is 0.36780017614364624\n",
      "epoch: 1 step: 276, loss is 0.3842044472694397\n",
      "epoch: 1 step: 277, loss is 0.33602654933929443\n",
      "epoch: 1 step: 278, loss is 0.5270519852638245\n",
      "epoch: 1 step: 279, loss is 0.497831791639328\n",
      "epoch: 1 step: 280, loss is 0.7949578166007996\n",
      "epoch: 1 step: 281, loss is 0.5366043448448181\n",
      "epoch: 1 step: 282, loss is 0.4143725037574768\n",
      "epoch: 1 step: 283, loss is 0.5424333810806274\n",
      "epoch: 1 step: 284, loss is 0.5008870363235474\n",
      "epoch: 1 step: 285, loss is 0.5517313480377197\n",
      "epoch: 1 step: 286, loss is 0.535262405872345\n",
      "epoch: 1 step: 287, loss is 0.5062736868858337\n",
      "epoch: 1 step: 288, loss is 0.4836841821670532\n",
      "epoch: 1 step: 289, loss is 0.4977351129055023\n",
      "epoch: 1 step: 290, loss is 0.5586862564086914\n",
      "epoch: 1 step: 291, loss is 0.44631701707839966\n",
      "epoch: 1 step: 292, loss is 0.7440878748893738\n",
      "epoch: 1 step: 293, loss is 0.48701566457748413\n",
      "epoch: 1 step: 294, loss is 0.526041567325592\n",
      "epoch: 1 step: 295, loss is 0.4790618419647217\n",
      "epoch: 1 step: 296, loss is 0.38676783442497253\n",
      "epoch: 1 step: 297, loss is 0.50648432970047\n",
      "epoch: 1 step: 298, loss is 0.5335561633110046\n",
      "epoch: 1 step: 299, loss is 0.7877342104911804\n",
      "epoch: 1 step: 300, loss is 0.4224756360054016\n",
      "epoch: 1 step: 301, loss is 0.4088033437728882\n",
      "epoch: 1 step: 302, loss is 0.5905209183692932\n",
      "epoch: 1 step: 303, loss is 0.5901142954826355\n",
      "epoch: 1 step: 304, loss is 0.3904636800289154\n",
      "epoch: 1 step: 305, loss is 0.3543005585670471\n",
      "epoch: 1 step: 306, loss is 0.5484930872917175\n",
      "epoch: 1 step: 307, loss is 0.5145792365074158\n",
      "epoch: 1 step: 308, loss is 0.33110493421554565\n",
      "epoch: 1 step: 309, loss is 0.5278794765472412\n",
      "epoch: 1 step: 310, loss is 0.5556355714797974\n",
      "epoch: 1 step: 311, loss is 0.4086187481880188\n",
      "epoch: 1 step: 312, loss is 0.5365784764289856\n",
      "epoch: 1 step: 313, loss is 0.4013417363166809\n",
      "epoch: 1 step: 314, loss is 0.6117514371871948\n",
      "epoch: 1 step: 315, loss is 0.42763417959213257\n",
      "epoch: 1 step: 316, loss is 0.3571224808692932\n",
      "epoch: 1 step: 317, loss is 0.38689565658569336\n",
      "epoch: 1 step: 318, loss is 0.5812652707099915\n",
      "epoch: 1 step: 319, loss is 0.36441248655319214\n",
      "epoch: 1 step: 320, loss is 0.3286285102367401\n",
      "epoch: 1 step: 321, loss is 0.5025374293327332\n",
      "epoch: 1 step: 322, loss is 0.3522269129753113\n",
      "epoch: 1 step: 323, loss is 0.6832680702209473\n",
      "epoch: 1 step: 324, loss is 0.5215872526168823\n",
      "epoch: 1 step: 325, loss is 0.32538700103759766\n",
      "epoch: 1 step: 326, loss is 0.6281641125679016\n",
      "epoch: 1 step: 327, loss is 0.5731307864189148\n",
      "epoch: 1 step: 328, loss is 0.41352540254592896\n",
      "epoch: 1 step: 329, loss is 0.6795465350151062\n",
      "epoch: 1 step: 330, loss is 0.49288907647132874\n",
      "epoch: 1 step: 331, loss is 0.8049488663673401\n",
      "epoch: 1 step: 332, loss is 0.2657226324081421\n",
      "epoch: 1 step: 333, loss is 0.5870128273963928\n",
      "epoch: 1 step: 334, loss is 0.5049577355384827\n",
      "epoch: 1 step: 335, loss is 0.4047590494155884\n",
      "epoch: 1 step: 336, loss is 0.3338949382305145\n",
      "epoch: 1 step: 337, loss is 0.3765408396720886\n",
      "epoch: 1 step: 338, loss is 0.5152895450592041\n",
      "epoch: 1 step: 339, loss is 0.43505048751831055\n",
      "epoch: 1 step: 340, loss is 0.5061817169189453\n",
      "epoch: 1 step: 341, loss is 0.3629193603992462\n",
      "epoch: 1 step: 342, loss is 0.5190849900245667\n",
      "epoch: 1 step: 343, loss is 0.3965536952018738\n",
      "epoch: 1 step: 344, loss is 0.6790423393249512\n",
      "epoch: 1 step: 345, loss is 0.5830590724945068\n",
      "epoch: 1 step: 346, loss is 0.46698951721191406\n",
      "epoch: 1 step: 347, loss is 0.4007733464241028\n",
      "epoch: 1 step: 348, loss is 0.43921124935150146\n",
      "epoch: 1 step: 349, loss is 0.515346348285675\n",
      "epoch: 1 step: 350, loss is 0.3708554804325104\n",
      "epoch: 1 step: 351, loss is 0.6392248868942261\n",
      "epoch: 1 step: 352, loss is 0.5591052174568176\n",
      "epoch: 1 step: 353, loss is 0.3146800994873047\n",
      "epoch: 1 step: 354, loss is 0.5640235543251038\n",
      "epoch: 1 step: 355, loss is 0.6093132495880127\n",
      "epoch: 1 step: 356, loss is 0.29221978783607483\n",
      "epoch: 1 step: 357, loss is 0.5494697690010071\n",
      "epoch: 1 step: 358, loss is 0.3488757014274597\n",
      "epoch: 1 step: 359, loss is 0.4592736065387726\n",
      "epoch: 1 step: 360, loss is 0.48732462525367737\n",
      "epoch: 1 step: 361, loss is 0.5295073390007019\n",
      "epoch: 1 step: 362, loss is 0.5599330067634583\n",
      "epoch: 1 step: 363, loss is 0.42711061239242554\n",
      "epoch: 1 step: 364, loss is 0.6580225825309753\n",
      "epoch: 1 step: 365, loss is 0.22936579585075378\n",
      "epoch: 1 step: 366, loss is 0.3132467567920685\n",
      "epoch: 1 step: 367, loss is 0.3215149939060211\n",
      "epoch: 1 step: 368, loss is 0.3685184717178345\n",
      "epoch: 1 step: 369, loss is 0.6123830676078796\n",
      "epoch: 1 step: 370, loss is 0.5324080586433411\n",
      "epoch: 1 step: 371, loss is 0.41166022419929504\n",
      "epoch: 1 step: 372, loss is 0.5015456676483154\n",
      "epoch: 1 step: 373, loss is 0.5170236229896545\n",
      "epoch: 1 step: 374, loss is 0.25133734941482544\n",
      "epoch: 1 step: 375, loss is 0.37336310744285583\n",
      "epoch: 1 step: 376, loss is 0.7062394618988037\n",
      "epoch: 1 step: 377, loss is 0.48409363627433777\n",
      "epoch: 1 step: 378, loss is 0.31266164779663086\n",
      "epoch: 1 step: 379, loss is 0.31887632608413696\n",
      "epoch: 1 step: 380, loss is 0.4138985276222229\n",
      "epoch: 1 step: 381, loss is 0.43498313426971436\n",
      "epoch: 1 step: 382, loss is 0.5350412726402283\n",
      "epoch: 1 step: 383, loss is 0.3721267580986023\n",
      "epoch: 1 step: 384, loss is 0.45744046568870544\n",
      "epoch: 1 step: 385, loss is 0.4713985323905945\n",
      "epoch: 1 step: 386, loss is 0.5612191557884216\n",
      "epoch: 1 step: 387, loss is 0.4752418100833893\n",
      "epoch: 1 step: 388, loss is 0.5789132118225098\n",
      "epoch: 1 step: 389, loss is 0.4580966830253601\n",
      "epoch: 1 step: 390, loss is 0.4365919232368469\n",
      "epoch: 1 step: 391, loss is 0.397724449634552\n",
      "epoch: 1 step: 392, loss is 0.5891370177268982\n",
      "epoch: 1 step: 393, loss is 0.4745085835456848\n",
      "epoch: 1 step: 394, loss is 0.44158029556274414\n",
      "epoch: 1 step: 395, loss is 0.4669188857078552\n",
      "epoch: 1 step: 396, loss is 0.4039748013019562\n",
      "epoch: 1 step: 397, loss is 0.4288147985935211\n",
      "epoch: 1 step: 398, loss is 0.8078905344009399\n",
      "epoch: 1 step: 399, loss is 0.4341728091239929\n",
      "epoch: 1 step: 400, loss is 0.38038456439971924\n",
      "epoch: 1 step: 401, loss is 0.31465378403663635\n",
      "epoch: 1 step: 402, loss is 0.5340346097946167\n",
      "epoch: 1 step: 403, loss is 0.3811050355434418\n",
      "epoch: 1 step: 404, loss is 0.5064753890037537\n",
      "epoch: 1 step: 405, loss is 0.5262776613235474\n",
      "epoch: 1 step: 406, loss is 0.3598347306251526\n",
      "epoch: 1 step: 407, loss is 0.3842144012451172\n",
      "epoch: 1 step: 408, loss is 0.35521870851516724\n",
      "epoch: 1 step: 409, loss is 0.3572608232498169\n",
      "epoch: 1 step: 410, loss is 0.6244120001792908\n",
      "epoch: 1 step: 411, loss is 0.3176672160625458\n",
      "epoch: 1 step: 412, loss is 0.415576696395874\n",
      "epoch: 1 step: 413, loss is 0.44787871837615967\n",
      "epoch: 1 step: 414, loss is 0.34100988507270813\n",
      "epoch: 1 step: 415, loss is 0.587599515914917\n",
      "epoch: 1 step: 416, loss is 0.43089064955711365\n",
      "epoch: 1 step: 417, loss is 0.4751266539096832\n",
      "epoch: 1 step: 418, loss is 0.2938167452812195\n",
      "epoch: 1 step: 419, loss is 0.41494491696357727\n",
      "epoch: 1 step: 420, loss is 0.4240882694721222\n",
      "epoch: 1 step: 421, loss is 0.4084879457950592\n",
      "epoch: 1 step: 422, loss is 0.6021934747695923\n",
      "epoch: 1 step: 423, loss is 0.4207657277584076\n",
      "epoch: 1 step: 424, loss is 0.6063413023948669\n",
      "epoch: 1 step: 425, loss is 0.3516009449958801\n",
      "epoch: 1 step: 426, loss is 0.46743854880332947\n",
      "epoch: 1 step: 427, loss is 0.3876870274543762\n",
      "epoch: 1 step: 428, loss is 0.3351510167121887\n",
      "epoch: 1 step: 429, loss is 0.5503567457199097\n",
      "epoch: 1 step: 430, loss is 0.4445646107196808\n",
      "epoch: 1 step: 431, loss is 0.30273446440696716\n",
      "epoch: 1 step: 432, loss is 0.4131010174751282\n",
      "epoch: 1 step: 433, loss is 0.6287292242050171\n",
      "epoch: 1 step: 434, loss is 0.3598330318927765\n",
      "epoch: 1 step: 435, loss is 0.5274789929389954\n",
      "epoch: 1 step: 436, loss is 0.3141835629940033\n",
      "epoch: 1 step: 437, loss is 0.4364696741104126\n",
      "epoch: 1 step: 438, loss is 0.2744761109352112\n",
      "epoch: 1 step: 439, loss is 0.39717528223991394\n",
      "epoch: 1 step: 440, loss is 0.4490179717540741\n",
      "epoch: 1 step: 441, loss is 0.4159514605998993\n",
      "epoch: 1 step: 442, loss is 0.4532948136329651\n",
      "epoch: 1 step: 443, loss is 0.215781107544899\n",
      "epoch: 1 step: 444, loss is 0.5938277840614319\n",
      "epoch: 1 step: 445, loss is 0.6030886769294739\n",
      "epoch: 1 step: 446, loss is 0.334365576505661\n",
      "epoch: 1 step: 447, loss is 0.49435287714004517\n",
      "epoch: 1 step: 448, loss is 0.5268601179122925\n",
      "epoch: 1 step: 449, loss is 0.4043480455875397\n",
      "epoch: 1 step: 450, loss is 0.30999717116355896\n",
      "epoch: 1 step: 451, loss is 0.4893147945404053\n",
      "epoch: 1 step: 452, loss is 0.4074462056159973\n",
      "epoch: 1 step: 453, loss is 0.40932679176330566\n",
      "epoch: 1 step: 454, loss is 0.5951820611953735\n",
      "epoch: 1 step: 455, loss is 0.44755101203918457\n",
      "epoch: 1 step: 456, loss is 0.774353563785553\n",
      "epoch: 1 step: 457, loss is 0.3473060727119446\n",
      "epoch: 1 step: 458, loss is 0.6157721281051636\n",
      "epoch: 1 step: 459, loss is 0.466276615858078\n",
      "epoch: 1 step: 460, loss is 0.4248981177806854\n",
      "epoch: 1 step: 461, loss is 0.5126234889030457\n",
      "epoch: 1 step: 462, loss is 0.5213094353675842\n",
      "epoch: 1 step: 463, loss is 0.6223922967910767\n",
      "epoch: 1 step: 464, loss is 0.45099133253097534\n",
      "epoch: 1 step: 465, loss is 0.4097973108291626\n",
      "epoch: 1 step: 466, loss is 0.34615275263786316\n",
      "epoch: 1 step: 467, loss is 0.5461050271987915\n",
      "epoch: 1 step: 468, loss is 0.46810489892959595\n",
      "epoch: 1 step: 469, loss is 0.3070879876613617\n",
      "epoch: 1 step: 470, loss is 0.4981505274772644\n",
      "epoch: 1 step: 471, loss is 0.4737216532230377\n",
      "epoch: 1 step: 472, loss is 0.3677122890949249\n",
      "epoch: 1 step: 473, loss is 0.38116455078125\n",
      "epoch: 1 step: 474, loss is 0.41428452730178833\n",
      "epoch: 1 step: 475, loss is 0.5603821277618408\n",
      "epoch: 1 step: 476, loss is 0.497331440448761\n",
      "epoch: 1 step: 477, loss is 0.22776828706264496\n",
      "epoch: 1 step: 478, loss is 0.42370036244392395\n",
      "epoch: 1 step: 479, loss is 0.2785934805870056\n",
      "epoch: 1 step: 480, loss is 0.4097086489200592\n",
      "epoch: 1 step: 481, loss is 0.2776902914047241\n",
      "epoch: 1 step: 482, loss is 0.5204654335975647\n",
      "epoch: 1 step: 483, loss is 0.29209890961647034\n",
      "epoch: 1 step: 484, loss is 0.5451591610908508\n",
      "epoch: 1 step: 485, loss is 0.289108008146286\n",
      "epoch: 1 step: 486, loss is 0.3232254981994629\n",
      "epoch: 1 step: 487, loss is 0.4069974720478058\n",
      "epoch: 1 step: 488, loss is 0.3173205554485321\n",
      "epoch: 1 step: 489, loss is 0.3176904618740082\n",
      "epoch: 1 step: 490, loss is 0.4988975524902344\n",
      "epoch: 1 step: 491, loss is 0.4511541426181793\n",
      "epoch: 1 step: 492, loss is 0.3980369567871094\n",
      "epoch: 1 step: 493, loss is 0.22523020207881927\n",
      "epoch: 1 step: 494, loss is 0.40572038292884827\n",
      "epoch: 1 step: 495, loss is 0.3198169767856598\n",
      "epoch: 1 step: 496, loss is 0.4523557424545288\n",
      "epoch: 1 step: 497, loss is 0.47923025488853455\n",
      "epoch: 1 step: 498, loss is 0.41030189394950867\n",
      "epoch: 1 step: 499, loss is 0.28548532724380493\n",
      "epoch: 1 step: 500, loss is 0.35195520520210266\n",
      "epoch: 1 step: 501, loss is 0.4924371540546417\n",
      "epoch: 1 step: 502, loss is 0.46884337067604065\n",
      "epoch: 1 step: 503, loss is 0.280823677778244\n",
      "epoch: 1 step: 504, loss is 0.2772623598575592\n",
      "epoch: 1 step: 505, loss is 0.506527841091156\n",
      "epoch: 1 step: 506, loss is 0.3146974742412567\n",
      "epoch: 1 step: 507, loss is 0.548545777797699\n",
      "epoch: 1 step: 508, loss is 0.42927977442741394\n",
      "epoch: 1 step: 509, loss is 0.268993616104126\n",
      "epoch: 1 step: 510, loss is 0.3349095582962036\n",
      "epoch: 1 step: 511, loss is 0.4483068585395813\n",
      "epoch: 1 step: 512, loss is 0.3171652555465698\n",
      "epoch: 1 step: 513, loss is 0.453254759311676\n",
      "epoch: 1 step: 514, loss is 0.36599379777908325\n",
      "epoch: 1 step: 515, loss is 0.3801732063293457\n",
      "epoch: 1 step: 516, loss is 0.25400376319885254\n",
      "epoch: 1 step: 517, loss is 0.36872318387031555\n",
      "epoch: 1 step: 518, loss is 0.3405906856060028\n",
      "epoch: 1 step: 519, loss is 0.4924565851688385\n",
      "epoch: 1 step: 520, loss is 0.2582496404647827\n",
      "epoch: 1 step: 521, loss is 0.38473787903785706\n",
      "epoch: 1 step: 522, loss is 0.360736221075058\n",
      "epoch: 1 step: 523, loss is 0.3233794867992401\n",
      "epoch: 1 step: 524, loss is 0.29025745391845703\n",
      "epoch: 1 step: 525, loss is 0.520308792591095\n",
      "epoch: 1 step: 526, loss is 0.4762919247150421\n",
      "epoch: 1 step: 527, loss is 0.32609254121780396\n",
      "epoch: 1 step: 528, loss is 0.49324262142181396\n",
      "epoch: 1 step: 529, loss is 0.29700908064842224\n",
      "epoch: 1 step: 530, loss is 0.4084054231643677\n",
      "epoch: 1 step: 531, loss is 0.29618069529533386\n",
      "epoch: 1 step: 532, loss is 0.2545124292373657\n",
      "epoch: 1 step: 533, loss is 0.279209166765213\n",
      "epoch: 1 step: 534, loss is 0.5250298976898193\n",
      "epoch: 1 step: 535, loss is 0.2869994640350342\n",
      "epoch: 1 step: 536, loss is 0.47801753878593445\n",
      "epoch: 1 step: 537, loss is 0.33401092886924744\n",
      "epoch: 1 step: 538, loss is 0.3913932144641876\n",
      "epoch: 1 step: 539, loss is 0.6371594071388245\n",
      "epoch: 1 step: 540, loss is 0.39605268836021423\n",
      "epoch: 1 step: 541, loss is 0.46911367774009705\n",
      "epoch: 1 step: 542, loss is 0.427187442779541\n",
      "epoch: 1 step: 543, loss is 0.39974623918533325\n",
      "epoch: 1 step: 544, loss is 0.490408331155777\n",
      "epoch: 1 step: 545, loss is 0.4107610881328583\n",
      "epoch: 1 step: 546, loss is 0.510289192199707\n",
      "epoch: 1 step: 547, loss is 0.2443413883447647\n",
      "epoch: 1 step: 548, loss is 0.5041215419769287\n",
      "epoch: 1 step: 549, loss is 0.32771340012550354\n",
      "epoch: 1 step: 550, loss is 0.4302774667739868\n",
      "epoch: 1 step: 551, loss is 0.4515787363052368\n",
      "epoch: 1 step: 552, loss is 0.2847278416156769\n",
      "epoch: 1 step: 553, loss is 0.3141638934612274\n",
      "epoch: 1 step: 554, loss is 0.4933951795101166\n",
      "epoch: 1 step: 555, loss is 0.3361566960811615\n",
      "epoch: 1 step: 556, loss is 0.5894668102264404\n",
      "epoch: 1 step: 557, loss is 0.3461463153362274\n",
      "epoch: 1 step: 558, loss is 0.3084610104560852\n",
      "epoch: 1 step: 559, loss is 0.3894723653793335\n",
      "epoch: 1 step: 560, loss is 0.31292298436164856\n",
      "epoch: 1 step: 561, loss is 0.4464246332645416\n",
      "epoch: 1 step: 562, loss is 0.48250389099121094\n",
      "epoch: 1 step: 563, loss is 0.3707432448863983\n",
      "epoch: 1 step: 564, loss is 0.460808664560318\n",
      "epoch: 1 step: 565, loss is 0.5188188552856445\n",
      "epoch: 1 step: 566, loss is 0.4983617067337036\n",
      "epoch: 1 step: 567, loss is 0.3172791004180908\n",
      "epoch: 1 step: 568, loss is 0.46663299202919006\n",
      "epoch: 1 step: 569, loss is 0.34381407499313354\n",
      "epoch: 1 step: 570, loss is 0.24029070138931274\n",
      "epoch: 1 step: 571, loss is 0.2920287847518921\n",
      "epoch: 1 step: 572, loss is 0.5340662598609924\n",
      "epoch: 1 step: 573, loss is 0.38304466009140015\n",
      "epoch: 1 step: 574, loss is 0.3720851540565491\n",
      "epoch: 1 step: 575, loss is 0.508729100227356\n",
      "epoch: 1 step: 576, loss is 0.3405000567436218\n",
      "epoch: 1 step: 577, loss is 0.21842804551124573\n",
      "epoch: 1 step: 578, loss is 0.29546114802360535\n",
      "epoch: 1 step: 579, loss is 0.3703988790512085\n",
      "epoch: 1 step: 580, loss is 0.7716236114501953\n",
      "epoch: 1 step: 581, loss is 0.3294941782951355\n",
      "epoch: 1 step: 582, loss is 0.4803601801395416\n",
      "epoch: 1 step: 583, loss is 0.4444867670536041\n",
      "epoch: 1 step: 584, loss is 0.4230240285396576\n",
      "epoch: 1 step: 585, loss is 0.36675164103507996\n",
      "epoch: 1 step: 586, loss is 0.3407955765724182\n",
      "epoch: 1 step: 587, loss is 0.463767945766449\n",
      "epoch: 1 step: 588, loss is 0.45466703176498413\n",
      "epoch: 1 step: 589, loss is 0.41915661096572876\n",
      "epoch: 1 step: 590, loss is 0.27555713057518005\n",
      "epoch: 1 step: 591, loss is 0.35396820306777954\n",
      "epoch: 1 step: 592, loss is 0.45903480052948\n",
      "epoch: 1 step: 593, loss is 0.3237624168395996\n",
      "epoch: 1 step: 594, loss is 0.27486270666122437\n",
      "epoch: 1 step: 595, loss is 0.35988396406173706\n",
      "epoch: 1 step: 596, loss is 0.3244350254535675\n",
      "epoch: 1 step: 597, loss is 0.2505640685558319\n",
      "epoch: 1 step: 598, loss is 0.41004645824432373\n",
      "epoch: 1 step: 599, loss is 0.43023061752319336\n",
      "epoch: 1 step: 600, loss is 0.20848432183265686\n",
      "epoch: 1 step: 601, loss is 0.46011021733283997\n",
      "epoch: 1 step: 602, loss is 0.3908798098564148\n",
      "epoch: 1 step: 603, loss is 0.3389507234096527\n",
      "epoch: 1 step: 604, loss is 0.4045093357563019\n",
      "epoch: 1 step: 605, loss is 0.4122990369796753\n",
      "epoch: 1 step: 606, loss is 0.4728129208087921\n",
      "epoch: 1 step: 607, loss is 0.41267138719558716\n",
      "epoch: 1 step: 608, loss is 0.4148355722427368\n",
      "epoch: 1 step: 609, loss is 0.3732844591140747\n",
      "epoch: 1 step: 610, loss is 0.6010602116584778\n",
      "epoch: 1 step: 611, loss is 0.36322253942489624\n",
      "epoch: 1 step: 612, loss is 0.49635419249534607\n",
      "epoch: 1 step: 613, loss is 0.33695098757743835\n",
      "epoch: 1 step: 614, loss is 0.4747624695301056\n",
      "epoch: 1 step: 615, loss is 0.34230154752731323\n",
      "epoch: 1 step: 616, loss is 0.32623547315597534\n",
      "epoch: 1 step: 617, loss is 0.2758404314517975\n",
      "epoch: 1 step: 618, loss is 0.32657521963119507\n",
      "epoch: 1 step: 619, loss is 0.34770387411117554\n",
      "epoch: 1 step: 620, loss is 0.30387407541275024\n",
      "epoch: 1 step: 621, loss is 0.5243809819221497\n",
      "epoch: 1 step: 622, loss is 0.45521849393844604\n",
      "epoch: 1 step: 623, loss is 0.4091942310333252\n",
      "epoch: 1 step: 624, loss is 0.4620378613471985\n",
      "epoch: 1 step: 625, loss is 0.4187939465045929\n",
      "epoch: 1 step: 626, loss is 0.415559858083725\n",
      "epoch: 1 step: 627, loss is 0.48600560426712036\n",
      "epoch: 1 step: 628, loss is 0.454446017742157\n",
      "epoch: 1 step: 629, loss is 0.41361698508262634\n",
      "epoch: 1 step: 630, loss is 0.33806681632995605\n",
      "epoch: 1 step: 631, loss is 0.5438151359558105\n",
      "epoch: 1 step: 632, loss is 0.37722501158714294\n",
      "epoch: 1 step: 633, loss is 0.5392829775810242\n",
      "epoch: 1 step: 634, loss is 0.2546272277832031\n",
      "epoch: 1 step: 635, loss is 0.23752577602863312\n",
      "epoch: 1 step: 636, loss is 0.343226820230484\n",
      "epoch: 1 step: 637, loss is 0.3829004466533661\n",
      "epoch: 1 step: 638, loss is 0.39504125714302063\n",
      "epoch: 1 step: 639, loss is 0.498039186000824\n",
      "epoch: 1 step: 640, loss is 0.4959961175918579\n",
      "epoch: 1 step: 641, loss is 0.2316792756319046\n",
      "epoch: 1 step: 642, loss is 0.39843282103538513\n",
      "epoch: 1 step: 643, loss is 0.5458277463912964\n",
      "epoch: 1 step: 644, loss is 0.2495764195919037\n",
      "epoch: 1 step: 645, loss is 0.3885282576084137\n",
      "epoch: 1 step: 646, loss is 0.3272915780544281\n",
      "epoch: 1 step: 647, loss is 0.35683169960975647\n",
      "epoch: 1 step: 648, loss is 0.35502907633781433\n",
      "epoch: 1 step: 649, loss is 0.3235800564289093\n",
      "epoch: 1 step: 650, loss is 0.3035148084163666\n",
      "epoch: 1 step: 651, loss is 0.43530353903770447\n",
      "epoch: 1 step: 652, loss is 0.4075453281402588\n",
      "epoch: 1 step: 653, loss is 0.5314235091209412\n",
      "epoch: 1 step: 654, loss is 0.35313865542411804\n",
      "epoch: 1 step: 655, loss is 0.3391092121601105\n",
      "epoch: 1 step: 656, loss is 0.3413771986961365\n",
      "epoch: 1 step: 657, loss is 0.39075767993927\n",
      "epoch: 1 step: 658, loss is 0.3321763575077057\n",
      "epoch: 1 step: 659, loss is 0.350040078163147\n",
      "epoch: 1 step: 660, loss is 0.3477603793144226\n",
      "epoch: 1 step: 661, loss is 0.40570706129074097\n",
      "epoch: 1 step: 662, loss is 0.5862613916397095\n",
      "epoch: 1 step: 663, loss is 0.3142574429512024\n",
      "epoch: 1 step: 664, loss is 0.4454025626182556\n",
      "epoch: 1 step: 665, loss is 0.34331604838371277\n",
      "epoch: 1 step: 666, loss is 0.4433887302875519\n",
      "epoch: 1 step: 667, loss is 0.3842693865299225\n",
      "epoch: 1 step: 668, loss is 0.28093791007995605\n",
      "epoch: 1 step: 669, loss is 0.21104133129119873\n",
      "epoch: 1 step: 670, loss is 0.7106446623802185\n",
      "epoch: 1 step: 671, loss is 0.32354530692100525\n",
      "epoch: 1 step: 672, loss is 0.4434346556663513\n",
      "epoch: 1 step: 673, loss is 0.548686146736145\n",
      "epoch: 1 step: 674, loss is 0.4962942898273468\n",
      "epoch: 1 step: 675, loss is 0.35998865962028503\n",
      "epoch: 1 step: 676, loss is 0.3312873840332031\n",
      "epoch: 1 step: 677, loss is 0.2701495587825775\n",
      "epoch: 1 step: 678, loss is 0.32217296957969666\n",
      "epoch: 1 step: 679, loss is 0.5208457708358765\n",
      "epoch: 1 step: 680, loss is 0.46186408400535583\n",
      "epoch: 1 step: 681, loss is 0.31005096435546875\n",
      "epoch: 1 step: 682, loss is 0.4294668436050415\n",
      "epoch: 1 step: 683, loss is 0.468769907951355\n",
      "epoch: 1 step: 684, loss is 0.31046661734580994\n",
      "epoch: 1 step: 685, loss is 0.7057067155838013\n",
      "epoch: 1 step: 686, loss is 0.3924857974052429\n",
      "epoch: 1 step: 687, loss is 0.33736440539360046\n",
      "epoch: 1 step: 688, loss is 0.3697379231452942\n",
      "epoch: 1 step: 689, loss is 0.2676874101161957\n",
      "epoch: 1 step: 690, loss is 0.42577457427978516\n",
      "epoch: 1 step: 691, loss is 0.43235793709754944\n",
      "epoch: 1 step: 692, loss is 0.4168641269207001\n",
      "epoch: 1 step: 693, loss is 0.3870145380496979\n",
      "epoch: 1 step: 694, loss is 0.2542709410190582\n",
      "epoch: 1 step: 695, loss is 0.3566093444824219\n",
      "epoch: 1 step: 696, loss is 0.2974192500114441\n",
      "epoch: 1 step: 697, loss is 0.40387216210365295\n",
      "epoch: 1 step: 698, loss is 0.33870071172714233\n",
      "epoch: 1 step: 699, loss is 0.2488803118467331\n",
      "epoch: 1 step: 700, loss is 0.31574103236198425\n",
      "epoch: 1 step: 701, loss is 0.36810165643692017\n",
      "epoch: 1 step: 702, loss is 0.3823481798171997\n",
      "epoch: 1 step: 703, loss is 0.3261755704879761\n",
      "epoch: 1 step: 704, loss is 0.4453114867210388\n",
      "epoch: 1 step: 705, loss is 0.6378400325775146\n",
      "epoch: 1 step: 706, loss is 0.45803946256637573\n",
      "epoch: 1 step: 707, loss is 0.47724539041519165\n",
      "epoch: 1 step: 708, loss is 0.18181589245796204\n",
      "epoch: 1 step: 709, loss is 0.6243608593940735\n",
      "epoch: 1 step: 710, loss is 0.2642049789428711\n",
      "epoch: 1 step: 711, loss is 0.34754979610443115\n",
      "epoch: 1 step: 712, loss is 0.33108699321746826\n",
      "epoch: 1 step: 713, loss is 0.3605702817440033\n",
      "epoch: 1 step: 714, loss is 0.2534468472003937\n",
      "epoch: 1 step: 715, loss is 0.3140203058719635\n",
      "epoch: 1 step: 716, loss is 0.42221277952194214\n",
      "epoch: 1 step: 717, loss is 0.29591214656829834\n",
      "epoch: 1 step: 718, loss is 0.42816415429115295\n",
      "epoch: 1 step: 719, loss is 0.4164857268333435\n",
      "epoch: 1 step: 720, loss is 0.4572715163230896\n",
      "epoch: 1 step: 721, loss is 0.4351058304309845\n",
      "epoch: 1 step: 722, loss is 0.38313838839530945\n",
      "epoch: 1 step: 723, loss is 0.5265597701072693\n",
      "epoch: 1 step: 724, loss is 0.4182218909263611\n",
      "epoch: 1 step: 725, loss is 0.278491348028183\n",
      "epoch: 1 step: 726, loss is 0.31063032150268555\n",
      "epoch: 1 step: 727, loss is 0.4944723844528198\n",
      "epoch: 1 step: 728, loss is 0.22727751731872559\n",
      "epoch: 1 step: 729, loss is 0.42994219064712524\n",
      "epoch: 1 step: 730, loss is 0.3405480980873108\n",
      "epoch: 1 step: 731, loss is 0.37051355838775635\n",
      "epoch: 1 step: 732, loss is 0.2800332009792328\n",
      "epoch: 1 step: 733, loss is 0.42805901169776917\n",
      "epoch: 1 step: 734, loss is 0.4408310353755951\n",
      "epoch: 1 step: 735, loss is 0.4338690936565399\n",
      "epoch: 1 step: 736, loss is 0.26121488213539124\n",
      "epoch: 1 step: 737, loss is 0.5679867267608643\n",
      "epoch: 1 step: 738, loss is 0.3519430160522461\n",
      "epoch: 1 step: 739, loss is 0.33587825298309326\n",
      "epoch: 1 step: 740, loss is 0.2863362729549408\n",
      "epoch: 1 step: 741, loss is 0.32598090171813965\n",
      "epoch: 1 step: 742, loss is 0.4430995285511017\n",
      "epoch: 1 step: 743, loss is 0.4228581488132477\n",
      "epoch: 1 step: 744, loss is 0.23476019501686096\n",
      "epoch: 1 step: 745, loss is 0.7284278869628906\n",
      "epoch: 1 step: 746, loss is 0.4277559518814087\n",
      "epoch: 1 step: 747, loss is 0.4584839642047882\n",
      "epoch: 1 step: 748, loss is 0.24970975518226624\n",
      "epoch: 1 step: 749, loss is 0.3652404248714447\n",
      "epoch: 1 step: 750, loss is 0.610209584236145\n",
      "epoch: 1 step: 751, loss is 0.3237590491771698\n",
      "epoch: 1 step: 752, loss is 0.3879225552082062\n",
      "epoch: 1 step: 753, loss is 0.3723274767398834\n",
      "epoch: 1 step: 754, loss is 0.30737748742103577\n",
      "epoch: 1 step: 755, loss is 0.25763848423957825\n",
      "epoch: 1 step: 756, loss is 0.46586349606513977\n",
      "epoch: 1 step: 757, loss is 0.4683167040348053\n",
      "epoch: 1 step: 758, loss is 0.33370617032051086\n",
      "epoch: 1 step: 759, loss is 0.32039397954940796\n",
      "epoch: 1 step: 760, loss is 0.29548609256744385\n",
      "epoch: 1 step: 761, loss is 0.4119027554988861\n",
      "epoch: 1 step: 762, loss is 0.6575479507446289\n",
      "epoch: 1 step: 763, loss is 0.35059601068496704\n",
      "epoch: 1 step: 764, loss is 0.4213521182537079\n",
      "epoch: 1 step: 765, loss is 0.3387893736362457\n",
      "epoch: 1 step: 766, loss is 0.35726624727249146\n",
      "epoch: 1 step: 767, loss is 0.23647689819335938\n",
      "epoch: 1 step: 768, loss is 0.248977929353714\n",
      "epoch: 1 step: 769, loss is 0.4330323338508606\n",
      "epoch: 1 step: 770, loss is 0.3497411012649536\n",
      "epoch: 1 step: 771, loss is 0.4073754847049713\n",
      "epoch: 1 step: 772, loss is 0.41908735036849976\n",
      "epoch: 1 step: 773, loss is 0.3956919312477112\n",
      "epoch: 1 step: 774, loss is 0.25106388330459595\n",
      "epoch: 1 step: 775, loss is 0.44643068313598633\n",
      "epoch: 1 step: 776, loss is 0.3760121464729309\n",
      "epoch: 1 step: 777, loss is 0.2615339159965515\n",
      "epoch: 1 step: 778, loss is 0.3838658332824707\n",
      "epoch: 1 step: 779, loss is 0.4402466416358948\n",
      "epoch: 1 step: 780, loss is 0.30650991201400757\n",
      "epoch: 1 step: 781, loss is 0.2922375798225403\n",
      "epoch: 1 step: 782, loss is 0.5774204134941101\n",
      "epoch: 1 step: 783, loss is 0.6800072193145752\n",
      "epoch: 1 step: 784, loss is 0.5556687116622925\n",
      "epoch: 1 step: 785, loss is 0.5006515383720398\n",
      "epoch: 1 step: 786, loss is 0.4724370539188385\n",
      "epoch: 1 step: 787, loss is 0.23331318795681\n",
      "epoch: 1 step: 788, loss is 0.3804302215576172\n",
      "epoch: 1 step: 789, loss is 0.32224732637405396\n",
      "epoch: 1 step: 790, loss is 0.35855063796043396\n",
      "epoch: 1 step: 791, loss is 0.2611219882965088\n",
      "epoch: 1 step: 792, loss is 0.3857080936431885\n",
      "epoch: 1 step: 793, loss is 0.38554224371910095\n",
      "epoch: 1 step: 794, loss is 0.2811168134212494\n",
      "epoch: 1 step: 795, loss is 0.3437390923500061\n",
      "epoch: 1 step: 796, loss is 0.6226203441619873\n",
      "epoch: 1 step: 797, loss is 0.49356719851493835\n",
      "epoch: 1 step: 798, loss is 0.3491072654724121\n",
      "epoch: 1 step: 799, loss is 0.19926150143146515\n",
      "epoch: 1 step: 800, loss is 0.40901196002960205\n",
      "epoch: 1 step: 801, loss is 0.411125510931015\n",
      "epoch: 1 step: 802, loss is 0.3824303150177002\n",
      "epoch: 1 step: 803, loss is 0.6114126443862915\n",
      "epoch: 1 step: 804, loss is 0.29599636793136597\n",
      "epoch: 1 step: 805, loss is 0.2995244264602661\n",
      "epoch: 1 step: 806, loss is 0.5334932208061218\n",
      "epoch: 1 step: 807, loss is 0.42008572816848755\n",
      "epoch: 1 step: 808, loss is 0.1998349279165268\n",
      "epoch: 1 step: 809, loss is 0.24958744645118713\n",
      "epoch: 1 step: 810, loss is 0.32994043827056885\n",
      "epoch: 1 step: 811, loss is 0.45758625864982605\n",
      "epoch: 1 step: 812, loss is 0.29581424593925476\n",
      "epoch: 1 step: 813, loss is 0.41347336769104004\n",
      "epoch: 1 step: 814, loss is 0.44561174511909485\n",
      "epoch: 1 step: 815, loss is 0.14373141527175903\n",
      "epoch: 1 step: 816, loss is 0.32085201144218445\n",
      "epoch: 1 step: 817, loss is 0.41384533047676086\n",
      "epoch: 1 step: 818, loss is 0.4693461060523987\n",
      "epoch: 1 step: 819, loss is 0.2726839482784271\n",
      "epoch: 1 step: 820, loss is 0.35305115580558777\n",
      "epoch: 1 step: 821, loss is 0.6483519077301025\n",
      "epoch: 1 step: 822, loss is 0.359600305557251\n",
      "epoch: 1 step: 823, loss is 0.4491155743598938\n",
      "epoch: 1 step: 824, loss is 0.30193305015563965\n",
      "epoch: 1 step: 825, loss is 0.4351891875267029\n",
      "epoch: 1 step: 826, loss is 0.2965397834777832\n",
      "epoch: 1 step: 827, loss is 0.20789775252342224\n",
      "epoch: 1 step: 828, loss is 0.35634586215019226\n",
      "epoch: 1 step: 829, loss is 0.46189549565315247\n",
      "epoch: 1 step: 830, loss is 0.41659191250801086\n",
      "epoch: 1 step: 831, loss is 0.31099140644073486\n",
      "epoch: 1 step: 832, loss is 0.45655134320259094\n",
      "epoch: 1 step: 833, loss is 0.5011407136917114\n",
      "epoch: 1 step: 834, loss is 0.33897244930267334\n",
      "epoch: 1 step: 835, loss is 0.29254451394081116\n",
      "epoch: 1 step: 836, loss is 0.3250444233417511\n",
      "epoch: 1 step: 837, loss is 0.23338890075683594\n",
      "epoch: 1 step: 838, loss is 0.4991517961025238\n",
      "epoch: 1 step: 839, loss is 0.4647220969200134\n",
      "epoch: 1 step: 840, loss is 0.2727319002151489\n",
      "epoch: 1 step: 841, loss is 0.24579614400863647\n",
      "epoch: 1 step: 842, loss is 0.22308093309402466\n",
      "epoch: 1 step: 843, loss is 0.456760048866272\n",
      "epoch: 1 step: 844, loss is 0.23674319684505463\n",
      "epoch: 1 step: 845, loss is 0.43392428755760193\n",
      "epoch: 1 step: 846, loss is 0.41370564699172974\n",
      "epoch: 1 step: 847, loss is 0.5165471434593201\n",
      "epoch: 1 step: 848, loss is 0.3179742097854614\n",
      "epoch: 1 step: 849, loss is 0.27774181962013245\n",
      "epoch: 1 step: 850, loss is 0.3811069130897522\n",
      "epoch: 1 step: 851, loss is 0.34785017371177673\n",
      "epoch: 1 step: 852, loss is 0.2836645245552063\n",
      "epoch: 1 step: 853, loss is 0.5367813110351562\n",
      "epoch: 1 step: 854, loss is 0.27077609300613403\n",
      "epoch: 1 step: 855, loss is 0.45621925592422485\n",
      "epoch: 1 step: 856, loss is 0.3185732364654541\n",
      "epoch: 1 step: 857, loss is 0.49939456582069397\n",
      "epoch: 1 step: 858, loss is 0.23296794295310974\n",
      "epoch: 1 step: 859, loss is 0.3939172029495239\n",
      "epoch: 1 step: 860, loss is 0.3902592062950134\n",
      "epoch: 1 step: 861, loss is 0.4574814438819885\n",
      "epoch: 1 step: 862, loss is 0.40086933970451355\n",
      "epoch: 1 step: 863, loss is 0.2706035077571869\n",
      "epoch: 1 step: 864, loss is 0.4970986247062683\n",
      "epoch: 1 step: 865, loss is 0.32502803206443787\n",
      "epoch: 1 step: 866, loss is 0.32941076159477234\n",
      "epoch: 1 step: 867, loss is 0.28557851910591125\n",
      "epoch: 1 step: 868, loss is 0.2926824688911438\n",
      "epoch: 1 step: 869, loss is 0.4151451289653778\n",
      "epoch: 1 step: 870, loss is 0.2976662516593933\n",
      "epoch: 1 step: 871, loss is 0.49396058917045593\n",
      "epoch: 1 step: 872, loss is 0.4762164056301117\n",
      "epoch: 1 step: 873, loss is 0.44265297055244446\n",
      "epoch: 1 step: 874, loss is 0.4029790163040161\n",
      "epoch: 1 step: 875, loss is 0.4852356016635895\n",
      "epoch: 1 step: 876, loss is 0.34182268381118774\n",
      "epoch: 1 step: 877, loss is 0.36495140194892883\n",
      "epoch: 1 step: 878, loss is 0.35192087292671204\n",
      "epoch: 1 step: 879, loss is 0.3176333010196686\n",
      "epoch: 1 step: 880, loss is 0.359536737203598\n",
      "epoch: 1 step: 881, loss is 0.4706534445285797\n",
      "epoch: 1 step: 882, loss is 0.3959779143333435\n",
      "epoch: 1 step: 883, loss is 0.3668099641799927\n",
      "epoch: 1 step: 884, loss is 0.4685784578323364\n",
      "epoch: 1 step: 885, loss is 0.4216233789920807\n",
      "epoch: 1 step: 886, loss is 0.4933338165283203\n",
      "epoch: 1 step: 887, loss is 0.3730190098285675\n",
      "epoch: 1 step: 888, loss is 0.4575841724872589\n",
      "epoch: 1 step: 889, loss is 0.547000527381897\n",
      "epoch: 1 step: 890, loss is 0.4042130708694458\n",
      "epoch: 1 step: 891, loss is 0.451023131608963\n",
      "epoch: 1 step: 892, loss is 0.26148274540901184\n",
      "epoch: 1 step: 893, loss is 0.33735302090644836\n",
      "epoch: 1 step: 894, loss is 0.340445876121521\n",
      "epoch: 1 step: 895, loss is 0.3586087226867676\n",
      "epoch: 1 step: 896, loss is 0.3022657334804535\n",
      "epoch: 1 step: 897, loss is 0.2584971785545349\n",
      "epoch: 1 step: 898, loss is 0.31220194697380066\n",
      "epoch: 1 step: 899, loss is 0.39473578333854675\n",
      "epoch: 1 step: 900, loss is 0.3569380044937134\n",
      "epoch: 1 step: 901, loss is 0.3050137162208557\n",
      "epoch: 1 step: 902, loss is 0.3806911110877991\n",
      "epoch: 1 step: 903, loss is 0.3616909384727478\n",
      "epoch: 1 step: 904, loss is 0.32857784628868103\n",
      "epoch: 1 step: 905, loss is 0.22143834829330444\n",
      "epoch: 1 step: 906, loss is 0.25938302278518677\n",
      "epoch: 1 step: 907, loss is 0.41494038701057434\n",
      "epoch: 1 step: 908, loss is 0.43082737922668457\n",
      "epoch: 1 step: 909, loss is 0.26910334825515747\n",
      "epoch: 1 step: 910, loss is 0.20470541715621948\n",
      "epoch: 1 step: 911, loss is 0.27484092116355896\n",
      "epoch: 1 step: 912, loss is 0.558481752872467\n",
      "epoch: 1 step: 913, loss is 0.2079254388809204\n",
      "epoch: 1 step: 914, loss is 0.33498111367225647\n",
      "epoch: 1 step: 915, loss is 0.35296887159347534\n",
      "epoch: 1 step: 916, loss is 0.26637977361679077\n",
      "epoch: 1 step: 917, loss is 0.19120337069034576\n",
      "epoch: 1 step: 918, loss is 0.3014881908893585\n",
      "epoch: 1 step: 919, loss is 0.3247791826725006\n",
      "epoch: 1 step: 920, loss is 0.32141435146331787\n",
      "epoch: 1 step: 921, loss is 0.27217715978622437\n",
      "epoch: 1 step: 922, loss is 0.2792833149433136\n",
      "epoch: 1 step: 923, loss is 0.6070530414581299\n",
      "epoch: 1 step: 924, loss is 0.3506768047809601\n",
      "epoch: 1 step: 925, loss is 0.3686034679412842\n",
      "epoch: 1 step: 926, loss is 0.3538646101951599\n",
      "epoch: 1 step: 927, loss is 0.2830810546875\n",
      "epoch: 1 step: 928, loss is 0.6049668192863464\n",
      "epoch: 1 step: 929, loss is 0.47830289602279663\n",
      "epoch: 1 step: 930, loss is 0.42538073658943176\n",
      "epoch: 1 step: 931, loss is 0.2612915337085724\n",
      "epoch: 1 step: 932, loss is 0.18259912729263306\n",
      "epoch: 1 step: 933, loss is 0.39771077036857605\n",
      "epoch: 1 step: 934, loss is 0.31863218545913696\n",
      "epoch: 1 step: 935, loss is 0.1847561150789261\n",
      "epoch: 1 step: 936, loss is 0.3737122416496277\n",
      "epoch: 1 step: 937, loss is 0.30848708748817444\n",
      "{'acc': 0.8694911858974359}\n"
     ]
    }
   ],
   "source": [
    "# 训练无正则化的网络\n",
    "model = train(ForwardFashion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(16032:21436,MainProcess):2023-05-14-19:22:32.891.227 [mindspore\\nn\\layer\\basic.py:167] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(16032:21436,MainProcess):2023-05-14-19:22:32.926.230 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(16032:21436,MainProcess):2023-05-14-19:22:32.930.228 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(16032:21436,MainProcess):2023-05-14-19:22:32.940.229 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(16032:21436,MainProcess):2023-05-14-19:22:32.941.231 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(16032:21436,MainProcess):2023-05-14-19:22:32.967.239 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(16032:21436,MainProcess):2023-05-14-19:22:33.529.3 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(16032:21436,MainProcess):2023-05-14-19:22:33.218.13 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Training ==============\n",
      "epoch: 1 step: 1, loss is 2.2993295192718506\n",
      "epoch: 1 step: 2, loss is 2.287247657775879\n",
      "epoch: 1 step: 3, loss is 2.253066062927246\n",
      "epoch: 1 step: 4, loss is 2.159172296524048\n",
      "epoch: 1 step: 5, loss is 2.1047818660736084\n",
      "epoch: 1 step: 6, loss is 2.0446059703826904\n",
      "epoch: 1 step: 7, loss is 1.9721177816390991\n",
      "epoch: 1 step: 8, loss is 1.944969654083252\n",
      "epoch: 1 step: 9, loss is 1.904735803604126\n",
      "epoch: 1 step: 10, loss is 1.8913612365722656\n",
      "epoch: 1 step: 11, loss is 1.7719639539718628\n",
      "epoch: 1 step: 12, loss is 1.8083610534667969\n",
      "epoch: 1 step: 13, loss is 1.7371975183486938\n",
      "epoch: 1 step: 14, loss is 1.7522292137145996\n",
      "epoch: 1 step: 15, loss is 1.6234487295150757\n",
      "epoch: 1 step: 16, loss is 1.7264823913574219\n",
      "epoch: 1 step: 17, loss is 1.6801667213439941\n",
      "epoch: 1 step: 18, loss is 1.7266433238983154\n",
      "epoch: 1 step: 19, loss is 1.6262800693511963\n",
      "epoch: 1 step: 20, loss is 1.6261721849441528\n",
      "epoch: 1 step: 21, loss is 1.5996160507202148\n",
      "epoch: 1 step: 22, loss is 1.5713263750076294\n",
      "epoch: 1 step: 23, loss is 1.5325305461883545\n",
      "epoch: 1 step: 24, loss is 1.4738879203796387\n",
      "epoch: 1 step: 25, loss is 1.4958478212356567\n",
      "epoch: 1 step: 26, loss is 1.4413607120513916\n",
      "epoch: 1 step: 27, loss is 1.431338906288147\n",
      "epoch: 1 step: 28, loss is 1.388460397720337\n",
      "epoch: 1 step: 29, loss is 1.4128127098083496\n",
      "epoch: 1 step: 30, loss is 1.4698578119277954\n",
      "epoch: 1 step: 31, loss is 1.356004238128662\n",
      "epoch: 1 step: 32, loss is 1.3383265733718872\n",
      "epoch: 1 step: 33, loss is 1.2996946573257446\n",
      "epoch: 1 step: 34, loss is 1.426937222480774\n",
      "epoch: 1 step: 35, loss is 1.3164311647415161\n",
      "epoch: 1 step: 36, loss is 1.4043190479278564\n",
      "epoch: 1 step: 37, loss is 1.295641541481018\n",
      "epoch: 1 step: 38, loss is 1.2052247524261475\n",
      "epoch: 1 step: 39, loss is 1.1841720342636108\n",
      "epoch: 1 step: 40, loss is 1.210127830505371\n",
      "epoch: 1 step: 41, loss is 1.2490156888961792\n",
      "epoch: 1 step: 42, loss is 1.3313701152801514\n",
      "epoch: 1 step: 43, loss is 1.2131341695785522\n",
      "epoch: 1 step: 44, loss is 1.136168360710144\n",
      "epoch: 1 step: 45, loss is 1.3240896463394165\n",
      "epoch: 1 step: 46, loss is 1.1109837293624878\n",
      "epoch: 1 step: 47, loss is 1.0740995407104492\n",
      "epoch: 1 step: 48, loss is 0.9766831994056702\n",
      "epoch: 1 step: 49, loss is 1.164006233215332\n",
      "epoch: 1 step: 50, loss is 1.1214094161987305\n",
      "epoch: 1 step: 51, loss is 1.1063117980957031\n",
      "epoch: 1 step: 52, loss is 1.0809911489486694\n",
      "epoch: 1 step: 53, loss is 1.227832317352295\n",
      "epoch: 1 step: 54, loss is 0.9250523447990417\n",
      "epoch: 1 step: 55, loss is 1.164008378982544\n",
      "epoch: 1 step: 56, loss is 1.1415019035339355\n",
      "epoch: 1 step: 57, loss is 1.070984959602356\n",
      "epoch: 1 step: 58, loss is 0.9836975932121277\n",
      "epoch: 1 step: 59, loss is 1.0118916034698486\n",
      "epoch: 1 step: 60, loss is 0.8878852128982544\n",
      "epoch: 1 step: 61, loss is 0.8363736271858215\n",
      "epoch: 1 step: 62, loss is 0.8000892400741577\n",
      "epoch: 1 step: 63, loss is 0.8474143147468567\n",
      "epoch: 1 step: 64, loss is 0.9813751578330994\n",
      "epoch: 1 step: 65, loss is 0.8601166009902954\n",
      "epoch: 1 step: 66, loss is 0.8076276183128357\n",
      "epoch: 1 step: 67, loss is 0.9329221844673157\n",
      "epoch: 1 step: 68, loss is 1.0317314863204956\n",
      "epoch: 1 step: 69, loss is 1.1001269817352295\n",
      "epoch: 1 step: 70, loss is 0.7663689851760864\n",
      "epoch: 1 step: 71, loss is 0.8081665635108948\n",
      "epoch: 1 step: 72, loss is 0.8943106532096863\n",
      "epoch: 1 step: 73, loss is 0.8176321983337402\n",
      "epoch: 1 step: 74, loss is 0.7647092342376709\n",
      "epoch: 1 step: 75, loss is 0.8775689601898193\n",
      "epoch: 1 step: 76, loss is 0.7602844834327698\n",
      "epoch: 1 step: 77, loss is 0.7809112668037415\n",
      "epoch: 1 step: 78, loss is 0.7645713090896606\n",
      "epoch: 1 step: 79, loss is 0.8529901504516602\n",
      "epoch: 1 step: 80, loss is 0.9453762173652649\n",
      "epoch: 1 step: 81, loss is 0.9157158136367798\n",
      "epoch: 1 step: 82, loss is 0.7722049355506897\n",
      "epoch: 1 step: 83, loss is 0.9469813704490662\n",
      "epoch: 1 step: 84, loss is 0.9117358326911926\n",
      "epoch: 1 step: 85, loss is 0.9455726742744446\n",
      "epoch: 1 step: 86, loss is 0.8884661197662354\n",
      "epoch: 1 step: 87, loss is 0.867330014705658\n",
      "epoch: 1 step: 88, loss is 0.8697208166122437\n",
      "epoch: 1 step: 89, loss is 0.8555769920349121\n",
      "epoch: 1 step: 90, loss is 0.8848599791526794\n",
      "epoch: 1 step: 91, loss is 0.9721093773841858\n",
      "epoch: 1 step: 92, loss is 0.6489425301551819\n",
      "epoch: 1 step: 93, loss is 0.8661969304084778\n",
      "epoch: 1 step: 94, loss is 0.7123807072639465\n",
      "epoch: 1 step: 95, loss is 0.7515702247619629\n",
      "epoch: 1 step: 96, loss is 0.7286695241928101\n",
      "epoch: 1 step: 97, loss is 0.8189712166786194\n",
      "epoch: 1 step: 98, loss is 0.72145676612854\n",
      "epoch: 1 step: 99, loss is 0.850513756275177\n",
      "epoch: 1 step: 100, loss is 0.7288964986801147\n",
      "epoch: 1 step: 101, loss is 0.7278618812561035\n",
      "epoch: 1 step: 102, loss is 0.6750957369804382\n",
      "epoch: 1 step: 103, loss is 0.7898657321929932\n",
      "epoch: 1 step: 104, loss is 0.6711403727531433\n",
      "epoch: 1 step: 105, loss is 0.8416872024536133\n",
      "epoch: 1 step: 106, loss is 0.9134107232093811\n",
      "epoch: 1 step: 107, loss is 0.7070919871330261\n",
      "epoch: 1 step: 108, loss is 0.8186070919036865\n",
      "epoch: 1 step: 109, loss is 0.7060631513595581\n",
      "epoch: 1 step: 110, loss is 0.8494048714637756\n",
      "epoch: 1 step: 111, loss is 0.7189416885375977\n",
      "epoch: 1 step: 112, loss is 0.706279993057251\n",
      "epoch: 1 step: 113, loss is 0.5968851447105408\n",
      "epoch: 1 step: 114, loss is 0.7121814489364624\n",
      "epoch: 1 step: 115, loss is 0.656912624835968\n",
      "epoch: 1 step: 116, loss is 0.6834301948547363\n",
      "epoch: 1 step: 117, loss is 0.5857200026512146\n",
      "epoch: 1 step: 118, loss is 0.8147660493850708\n",
      "epoch: 1 step: 119, loss is 0.8854566216468811\n",
      "epoch: 1 step: 120, loss is 0.7274801135063171\n",
      "epoch: 1 step: 121, loss is 0.7767615914344788\n",
      "epoch: 1 step: 122, loss is 0.7442585825920105\n",
      "epoch: 1 step: 123, loss is 0.7125955820083618\n",
      "epoch: 1 step: 124, loss is 0.660292387008667\n",
      "epoch: 1 step: 125, loss is 0.6651310324668884\n",
      "epoch: 1 step: 126, loss is 0.9251004457473755\n",
      "epoch: 1 step: 127, loss is 0.7023743987083435\n",
      "epoch: 1 step: 128, loss is 0.6506158709526062\n",
      "epoch: 1 step: 129, loss is 0.7636711001396179\n",
      "epoch: 1 step: 130, loss is 0.8581992387771606\n",
      "epoch: 1 step: 131, loss is 0.7142046093940735\n",
      "epoch: 1 step: 132, loss is 0.6958312392234802\n",
      "epoch: 1 step: 133, loss is 0.8525756597518921\n",
      "epoch: 1 step: 134, loss is 0.5312067866325378\n",
      "epoch: 1 step: 135, loss is 0.6807422637939453\n",
      "epoch: 1 step: 136, loss is 0.6893506050109863\n",
      "epoch: 1 step: 137, loss is 0.7698373198509216\n",
      "epoch: 1 step: 138, loss is 0.7087786793708801\n",
      "epoch: 1 step: 139, loss is 0.7024246454238892\n",
      "epoch: 1 step: 140, loss is 0.666962742805481\n",
      "epoch: 1 step: 141, loss is 0.5871880054473877\n",
      "epoch: 1 step: 142, loss is 0.6679468750953674\n",
      "epoch: 1 step: 143, loss is 0.6944754719734192\n",
      "epoch: 1 step: 144, loss is 0.6075438857078552\n",
      "epoch: 1 step: 145, loss is 0.5651323795318604\n",
      "epoch: 1 step: 146, loss is 0.7093276977539062\n",
      "epoch: 1 step: 147, loss is 0.738831102848053\n",
      "epoch: 1 step: 148, loss is 0.6000880002975464\n",
      "epoch: 1 step: 149, loss is 0.8643268346786499\n",
      "epoch: 1 step: 150, loss is 0.6488711833953857\n",
      "epoch: 1 step: 151, loss is 0.870347797870636\n",
      "epoch: 1 step: 152, loss is 0.7450833916664124\n",
      "epoch: 1 step: 153, loss is 0.7387661933898926\n",
      "epoch: 1 step: 154, loss is 0.8582340478897095\n",
      "epoch: 1 step: 155, loss is 0.9707796573638916\n",
      "epoch: 1 step: 156, loss is 0.6060663461685181\n",
      "epoch: 1 step: 157, loss is 0.6453912854194641\n",
      "epoch: 1 step: 158, loss is 0.7041310667991638\n",
      "epoch: 1 step: 159, loss is 0.7061097621917725\n",
      "epoch: 1 step: 160, loss is 0.6196986436843872\n",
      "epoch: 1 step: 161, loss is 0.720747172832489\n",
      "epoch: 1 step: 162, loss is 0.759781002998352\n",
      "epoch: 1 step: 163, loss is 0.7489617466926575\n",
      "epoch: 1 step: 164, loss is 0.6200942993164062\n",
      "epoch: 1 step: 165, loss is 0.6151925921440125\n",
      "epoch: 1 step: 166, loss is 0.646134078502655\n",
      "epoch: 1 step: 167, loss is 0.48098403215408325\n",
      "epoch: 1 step: 168, loss is 0.6436849236488342\n",
      "epoch: 1 step: 169, loss is 0.7020646333694458\n",
      "epoch: 1 step: 170, loss is 0.5186972618103027\n",
      "epoch: 1 step: 171, loss is 0.6257724761962891\n",
      "epoch: 1 step: 172, loss is 0.82271808385849\n",
      "epoch: 1 step: 173, loss is 0.6004550457000732\n",
      "epoch: 1 step: 174, loss is 0.6797778606414795\n",
      "epoch: 1 step: 175, loss is 0.7049867510795593\n",
      "epoch: 1 step: 176, loss is 0.5592749118804932\n",
      "epoch: 1 step: 177, loss is 0.6438062787055969\n",
      "epoch: 1 step: 178, loss is 0.702692449092865\n",
      "epoch: 1 step: 179, loss is 0.7712180614471436\n",
      "epoch: 1 step: 180, loss is 0.6964536309242249\n",
      "epoch: 1 step: 181, loss is 0.5691781640052795\n",
      "epoch: 1 step: 182, loss is 0.5883275866508484\n",
      "epoch: 1 step: 183, loss is 0.6865478754043579\n",
      "epoch: 1 step: 184, loss is 0.5865216255187988\n",
      "epoch: 1 step: 185, loss is 0.6116974949836731\n",
      "epoch: 1 step: 186, loss is 0.6601123213768005\n",
      "epoch: 1 step: 187, loss is 0.6030518412590027\n",
      "epoch: 1 step: 188, loss is 0.7150747179985046\n",
      "epoch: 1 step: 189, loss is 0.7097728252410889\n",
      "epoch: 1 step: 190, loss is 0.6815410852432251\n",
      "epoch: 1 step: 191, loss is 0.5684782266616821\n",
      "epoch: 1 step: 192, loss is 0.7140102982521057\n",
      "epoch: 1 step: 193, loss is 0.6799850463867188\n",
      "epoch: 1 step: 194, loss is 0.5016355514526367\n",
      "epoch: 1 step: 195, loss is 0.658359944820404\n",
      "epoch: 1 step: 196, loss is 0.7640999555587769\n",
      "epoch: 1 step: 197, loss is 0.608025312423706\n",
      "epoch: 1 step: 198, loss is 0.7661974430084229\n",
      "epoch: 1 step: 199, loss is 0.7471367120742798\n",
      "epoch: 1 step: 200, loss is 0.7655529379844666\n",
      "epoch: 1 step: 201, loss is 0.6825621724128723\n",
      "epoch: 1 step: 202, loss is 0.8908304572105408\n",
      "epoch: 1 step: 203, loss is 0.5530457496643066\n",
      "epoch: 1 step: 204, loss is 0.5183602571487427\n",
      "epoch: 1 step: 205, loss is 0.6091272234916687\n",
      "epoch: 1 step: 206, loss is 0.5427112579345703\n",
      "epoch: 1 step: 207, loss is 0.5942574739456177\n",
      "epoch: 1 step: 208, loss is 0.6775373816490173\n",
      "epoch: 1 step: 209, loss is 0.713929295539856\n",
      "epoch: 1 step: 210, loss is 0.6402801871299744\n",
      "epoch: 1 step: 211, loss is 0.6076700091362\n",
      "epoch: 1 step: 212, loss is 0.5984398722648621\n",
      "epoch: 1 step: 213, loss is 0.5073562860488892\n",
      "epoch: 1 step: 214, loss is 0.5717490911483765\n",
      "epoch: 1 step: 215, loss is 0.49517571926116943\n",
      "epoch: 1 step: 216, loss is 0.5033055543899536\n",
      "epoch: 1 step: 217, loss is 0.6587977409362793\n",
      "epoch: 1 step: 218, loss is 0.41252321004867554\n",
      "epoch: 1 step: 219, loss is 0.5547941327095032\n",
      "epoch: 1 step: 220, loss is 0.6710444688796997\n",
      "epoch: 1 step: 221, loss is 0.41965779662132263\n",
      "epoch: 1 step: 222, loss is 0.8028268218040466\n",
      "epoch: 1 step: 223, loss is 0.6168603897094727\n",
      "epoch: 1 step: 224, loss is 0.5356589555740356\n",
      "epoch: 1 step: 225, loss is 0.5574105978012085\n",
      "epoch: 1 step: 226, loss is 0.6798080801963806\n",
      "epoch: 1 step: 227, loss is 0.43901413679122925\n",
      "epoch: 1 step: 228, loss is 0.6496768593788147\n",
      "epoch: 1 step: 229, loss is 0.38797035813331604\n",
      "epoch: 1 step: 230, loss is 0.6429533958435059\n",
      "epoch: 1 step: 231, loss is 0.5129265189170837\n",
      "epoch: 1 step: 232, loss is 0.6599381566047668\n",
      "epoch: 1 step: 233, loss is 0.5848374366760254\n",
      "epoch: 1 step: 234, loss is 0.7993493676185608\n",
      "epoch: 1 step: 235, loss is 0.842925488948822\n",
      "epoch: 1 step: 236, loss is 0.5688956379890442\n",
      "epoch: 1 step: 237, loss is 0.5057307481765747\n",
      "epoch: 1 step: 238, loss is 0.6867139339447021\n",
      "epoch: 1 step: 239, loss is 0.3920626938343048\n",
      "epoch: 1 step: 240, loss is 0.5238391757011414\n",
      "epoch: 1 step: 241, loss is 0.642952561378479\n",
      "epoch: 1 step: 242, loss is 0.7602178454399109\n",
      "epoch: 1 step: 243, loss is 0.7741365432739258\n",
      "epoch: 1 step: 244, loss is 0.6344396471977234\n",
      "epoch: 1 step: 245, loss is 0.5942538380622864\n",
      "epoch: 1 step: 246, loss is 0.6514673829078674\n",
      "epoch: 1 step: 247, loss is 0.610562264919281\n",
      "epoch: 1 step: 248, loss is 0.593762993812561\n",
      "epoch: 1 step: 249, loss is 0.5863198637962341\n",
      "epoch: 1 step: 250, loss is 0.6040825247764587\n",
      "epoch: 1 step: 251, loss is 0.8432183265686035\n",
      "epoch: 1 step: 252, loss is 0.6877530813217163\n",
      "epoch: 1 step: 253, loss is 0.5224414467811584\n",
      "epoch: 1 step: 254, loss is 0.5489861369132996\n",
      "epoch: 1 step: 255, loss is 0.5310643315315247\n",
      "epoch: 1 step: 256, loss is 0.7235339283943176\n",
      "epoch: 1 step: 257, loss is 0.601651668548584\n",
      "epoch: 1 step: 258, loss is 0.6038009524345398\n",
      "epoch: 1 step: 259, loss is 0.6257474422454834\n",
      "epoch: 1 step: 260, loss is 0.6159182190895081\n",
      "epoch: 1 step: 261, loss is 0.6779019236564636\n",
      "epoch: 1 step: 262, loss is 0.5606898665428162\n",
      "epoch: 1 step: 263, loss is 0.7536044120788574\n",
      "epoch: 1 step: 264, loss is 0.578801691532135\n",
      "epoch: 1 step: 265, loss is 0.7845122218132019\n",
      "epoch: 1 step: 266, loss is 0.6277201771736145\n",
      "epoch: 1 step: 267, loss is 0.5100435614585876\n",
      "epoch: 1 step: 268, loss is 0.700408935546875\n",
      "epoch: 1 step: 269, loss is 0.604038655757904\n",
      "epoch: 1 step: 270, loss is 0.8150824904441833\n",
      "epoch: 1 step: 271, loss is 0.5146926641464233\n",
      "epoch: 1 step: 272, loss is 0.5919150114059448\n",
      "epoch: 1 step: 273, loss is 0.5662570595741272\n",
      "epoch: 1 step: 274, loss is 0.7561687231063843\n",
      "epoch: 1 step: 275, loss is 0.6709166765213013\n",
      "epoch: 1 step: 276, loss is 0.6449644565582275\n",
      "epoch: 1 step: 277, loss is 0.7218877673149109\n",
      "epoch: 1 step: 278, loss is 0.5225196480751038\n",
      "epoch: 1 step: 279, loss is 0.4906309247016907\n",
      "epoch: 1 step: 280, loss is 0.6476309299468994\n",
      "epoch: 1 step: 281, loss is 0.6680254936218262\n",
      "epoch: 1 step: 282, loss is 0.6422033309936523\n",
      "epoch: 1 step: 283, loss is 0.3659384250640869\n",
      "epoch: 1 step: 284, loss is 0.4372950792312622\n",
      "epoch: 1 step: 285, loss is 0.584381639957428\n",
      "epoch: 1 step: 286, loss is 0.5806525945663452\n",
      "epoch: 1 step: 287, loss is 0.7269942164421082\n",
      "epoch: 1 step: 288, loss is 0.7546830177307129\n",
      "epoch: 1 step: 289, loss is 0.5170106887817383\n",
      "epoch: 1 step: 290, loss is 0.4483661651611328\n",
      "epoch: 1 step: 291, loss is 0.4910193085670471\n",
      "epoch: 1 step: 292, loss is 0.46483322978019714\n",
      "epoch: 1 step: 293, loss is 0.5553561449050903\n",
      "epoch: 1 step: 294, loss is 0.707042396068573\n",
      "epoch: 1 step: 295, loss is 0.6252838373184204\n",
      "epoch: 1 step: 296, loss is 0.35846075415611267\n",
      "epoch: 1 step: 297, loss is 0.7478961944580078\n",
      "epoch: 1 step: 298, loss is 0.5560287237167358\n",
      "epoch: 1 step: 299, loss is 0.695545494556427\n",
      "epoch: 1 step: 300, loss is 0.4811519682407379\n",
      "epoch: 1 step: 301, loss is 0.6129775047302246\n",
      "epoch: 1 step: 302, loss is 0.5792140960693359\n",
      "epoch: 1 step: 303, loss is 0.5789102911949158\n",
      "epoch: 1 step: 304, loss is 0.739534318447113\n",
      "epoch: 1 step: 305, loss is 0.5631477236747742\n",
      "epoch: 1 step: 306, loss is 0.5637902617454529\n",
      "epoch: 1 step: 307, loss is 0.5173830389976501\n",
      "epoch: 1 step: 308, loss is 0.5605231523513794\n",
      "epoch: 1 step: 309, loss is 0.8679834008216858\n",
      "epoch: 1 step: 310, loss is 0.6801915168762207\n",
      "epoch: 1 step: 311, loss is 0.3963155746459961\n",
      "epoch: 1 step: 312, loss is 0.5260686278343201\n",
      "epoch: 1 step: 313, loss is 0.5515739917755127\n",
      "epoch: 1 step: 314, loss is 0.4764549136161804\n",
      "epoch: 1 step: 315, loss is 0.4022878408432007\n",
      "epoch: 1 step: 316, loss is 0.6332740187644958\n",
      "epoch: 1 step: 317, loss is 0.6250516176223755\n",
      "epoch: 1 step: 318, loss is 0.7191259860992432\n",
      "epoch: 1 step: 319, loss is 0.7682937979698181\n",
      "epoch: 1 step: 320, loss is 0.37844613194465637\n",
      "epoch: 1 step: 321, loss is 0.5775009989738464\n",
      "epoch: 1 step: 322, loss is 0.39396417140960693\n",
      "epoch: 1 step: 323, loss is 0.5627115368843079\n",
      "epoch: 1 step: 324, loss is 0.8359760046005249\n",
      "epoch: 1 step: 325, loss is 0.48914071917533875\n",
      "epoch: 1 step: 326, loss is 0.8712893128395081\n",
      "epoch: 1 step: 327, loss is 0.5422031879425049\n",
      "epoch: 1 step: 328, loss is 0.4020693302154541\n",
      "epoch: 1 step: 329, loss is 0.6045554876327515\n",
      "epoch: 1 step: 330, loss is 0.4975823760032654\n",
      "epoch: 1 step: 331, loss is 0.6244634985923767\n",
      "epoch: 1 step: 332, loss is 0.5130311846733093\n",
      "epoch: 1 step: 333, loss is 0.4963790774345398\n",
      "epoch: 1 step: 334, loss is 0.7324033975601196\n",
      "epoch: 1 step: 335, loss is 0.575128972530365\n",
      "epoch: 1 step: 336, loss is 0.48957017064094543\n",
      "epoch: 1 step: 337, loss is 0.4641761779785156\n",
      "epoch: 1 step: 338, loss is 0.5325232744216919\n",
      "epoch: 1 step: 339, loss is 0.5730056762695312\n",
      "epoch: 1 step: 340, loss is 0.587645411491394\n",
      "epoch: 1 step: 341, loss is 0.5786023736000061\n",
      "epoch: 1 step: 342, loss is 0.534136950969696\n",
      "epoch: 1 step: 343, loss is 0.5932207107543945\n",
      "epoch: 1 step: 344, loss is 0.3834682106971741\n",
      "epoch: 1 step: 345, loss is 0.8025766015052795\n",
      "epoch: 1 step: 346, loss is 0.36989492177963257\n",
      "epoch: 1 step: 347, loss is 0.49257969856262207\n",
      "epoch: 1 step: 348, loss is 0.6652992367744446\n",
      "epoch: 1 step: 349, loss is 0.6254744529724121\n",
      "epoch: 1 step: 350, loss is 0.4432710111141205\n",
      "epoch: 1 step: 351, loss is 0.527270495891571\n",
      "epoch: 1 step: 352, loss is 0.48439228534698486\n",
      "epoch: 1 step: 353, loss is 0.6619811654090881\n",
      "epoch: 1 step: 354, loss is 0.6748752593994141\n",
      "epoch: 1 step: 355, loss is 0.38782739639282227\n",
      "epoch: 1 step: 356, loss is 0.39353469014167786\n",
      "epoch: 1 step: 357, loss is 0.4194113314151764\n",
      "epoch: 1 step: 358, loss is 0.5029553771018982\n",
      "epoch: 1 step: 359, loss is 0.6302973628044128\n",
      "epoch: 1 step: 360, loss is 0.6415576338768005\n",
      "epoch: 1 step: 361, loss is 0.36879220604896545\n",
      "epoch: 1 step: 362, loss is 0.5241703987121582\n",
      "epoch: 1 step: 363, loss is 0.51433926820755\n",
      "epoch: 1 step: 364, loss is 0.5354058146476746\n",
      "epoch: 1 step: 365, loss is 0.45266419649124146\n",
      "epoch: 1 step: 366, loss is 0.482298880815506\n",
      "epoch: 1 step: 367, loss is 0.5021887421607971\n",
      "epoch: 1 step: 368, loss is 0.4769575595855713\n",
      "epoch: 1 step: 369, loss is 0.4835166931152344\n",
      "epoch: 1 step: 370, loss is 0.42868566513061523\n",
      "epoch: 1 step: 371, loss is 0.5493764281272888\n",
      "epoch: 1 step: 372, loss is 0.4551451802253723\n",
      "epoch: 1 step: 373, loss is 0.4675118029117584\n",
      "epoch: 1 step: 374, loss is 0.6571168899536133\n",
      "epoch: 1 step: 375, loss is 0.5009267926216125\n",
      "epoch: 1 step: 376, loss is 0.6909496188163757\n",
      "epoch: 1 step: 377, loss is 0.4160042107105255\n",
      "epoch: 1 step: 378, loss is 0.618607759475708\n",
      "epoch: 1 step: 379, loss is 0.4968762993812561\n",
      "epoch: 1 step: 380, loss is 0.6312633752822876\n",
      "epoch: 1 step: 381, loss is 0.5817604660987854\n",
      "epoch: 1 step: 382, loss is 0.5115672945976257\n",
      "epoch: 1 step: 383, loss is 0.5590757727622986\n",
      "epoch: 1 step: 384, loss is 0.7095488905906677\n",
      "epoch: 1 step: 385, loss is 0.6433991193771362\n",
      "epoch: 1 step: 386, loss is 0.4903690218925476\n",
      "epoch: 1 step: 387, loss is 0.5405804514884949\n",
      "epoch: 1 step: 388, loss is 0.4427970051765442\n",
      "epoch: 1 step: 389, loss is 0.5916881561279297\n",
      "epoch: 1 step: 390, loss is 0.5509684681892395\n",
      "epoch: 1 step: 391, loss is 0.37944909930229187\n",
      "epoch: 1 step: 392, loss is 0.5437805652618408\n",
      "epoch: 1 step: 393, loss is 0.5479977130889893\n",
      "epoch: 1 step: 394, loss is 0.5729895234107971\n",
      "epoch: 1 step: 395, loss is 0.40312957763671875\n",
      "epoch: 1 step: 396, loss is 0.49126917123794556\n",
      "epoch: 1 step: 397, loss is 0.44198721647262573\n",
      "epoch: 1 step: 398, loss is 0.492914080619812\n",
      "epoch: 1 step: 399, loss is 0.6380577087402344\n",
      "epoch: 1 step: 400, loss is 0.3946779668331146\n",
      "epoch: 1 step: 401, loss is 0.5881463289260864\n",
      "epoch: 1 step: 402, loss is 0.5701442956924438\n",
      "epoch: 1 step: 403, loss is 0.4839702546596527\n",
      "epoch: 1 step: 404, loss is 0.6276884078979492\n",
      "epoch: 1 step: 405, loss is 0.49221545457839966\n",
      "epoch: 1 step: 406, loss is 0.5580170154571533\n",
      "epoch: 1 step: 407, loss is 0.5687566995620728\n",
      "epoch: 1 step: 408, loss is 0.5108482837677002\n",
      "epoch: 1 step: 409, loss is 0.34794315695762634\n",
      "epoch: 1 step: 410, loss is 0.38962844014167786\n",
      "epoch: 1 step: 411, loss is 0.5605971217155457\n",
      "epoch: 1 step: 412, loss is 0.44122371077537537\n",
      "epoch: 1 step: 413, loss is 0.4824782609939575\n",
      "epoch: 1 step: 414, loss is 0.6323534250259399\n",
      "epoch: 1 step: 415, loss is 0.4612298309803009\n",
      "epoch: 1 step: 416, loss is 0.5017843842506409\n",
      "epoch: 1 step: 417, loss is 0.5949023962020874\n",
      "epoch: 1 step: 418, loss is 0.46655037999153137\n",
      "epoch: 1 step: 419, loss is 0.5150131583213806\n",
      "epoch: 1 step: 420, loss is 0.553248405456543\n",
      "epoch: 1 step: 421, loss is 0.5763574242591858\n",
      "epoch: 1 step: 422, loss is 0.5237385630607605\n",
      "epoch: 1 step: 423, loss is 0.5836272835731506\n",
      "epoch: 1 step: 424, loss is 0.4403434991836548\n",
      "epoch: 1 step: 425, loss is 0.5241978168487549\n",
      "epoch: 1 step: 426, loss is 0.4623112380504608\n",
      "epoch: 1 step: 427, loss is 0.43572166562080383\n",
      "epoch: 1 step: 428, loss is 0.5414063334465027\n",
      "epoch: 1 step: 429, loss is 0.4688006043434143\n",
      "epoch: 1 step: 430, loss is 0.6179259419441223\n",
      "epoch: 1 step: 431, loss is 0.5585160851478577\n",
      "epoch: 1 step: 432, loss is 0.3589668273925781\n",
      "epoch: 1 step: 433, loss is 0.7049636840820312\n",
      "epoch: 1 step: 434, loss is 0.48397794365882874\n",
      "epoch: 1 step: 435, loss is 0.4022253453731537\n",
      "epoch: 1 step: 436, loss is 0.6419752240180969\n",
      "epoch: 1 step: 437, loss is 0.608556866645813\n",
      "epoch: 1 step: 438, loss is 0.41224879026412964\n",
      "epoch: 1 step: 439, loss is 0.6418613791465759\n",
      "epoch: 1 step: 440, loss is 0.6095641255378723\n",
      "epoch: 1 step: 441, loss is 0.6213299036026001\n",
      "epoch: 1 step: 442, loss is 0.5522524118423462\n",
      "epoch: 1 step: 443, loss is 0.5167907476425171\n",
      "epoch: 1 step: 444, loss is 0.6920855045318604\n",
      "epoch: 1 step: 445, loss is 0.5795454978942871\n",
      "epoch: 1 step: 446, loss is 0.5129801034927368\n",
      "epoch: 1 step: 447, loss is 0.5961388945579529\n",
      "epoch: 1 step: 448, loss is 0.58747798204422\n",
      "epoch: 1 step: 449, loss is 0.5862252116203308\n",
      "epoch: 1 step: 450, loss is 0.46786850690841675\n",
      "epoch: 1 step: 451, loss is 0.4073498547077179\n",
      "epoch: 1 step: 452, loss is 0.5870190262794495\n",
      "epoch: 1 step: 453, loss is 0.4006054699420929\n",
      "epoch: 1 step: 454, loss is 0.32635658979415894\n",
      "epoch: 1 step: 455, loss is 0.5114679932594299\n",
      "epoch: 1 step: 456, loss is 0.7219265103340149\n",
      "epoch: 1 step: 457, loss is 0.7279096841812134\n",
      "epoch: 1 step: 458, loss is 0.6212482452392578\n",
      "epoch: 1 step: 459, loss is 0.73755943775177\n",
      "epoch: 1 step: 460, loss is 0.5227996706962585\n",
      "epoch: 1 step: 461, loss is 0.543934166431427\n",
      "epoch: 1 step: 462, loss is 0.45503103733062744\n",
      "epoch: 1 step: 463, loss is 0.4124158024787903\n",
      "epoch: 1 step: 464, loss is 0.41980844736099243\n",
      "epoch: 1 step: 465, loss is 0.5049773454666138\n",
      "epoch: 1 step: 466, loss is 0.5782217979431152\n",
      "epoch: 1 step: 467, loss is 0.6308454275131226\n",
      "epoch: 1 step: 468, loss is 0.48634105920791626\n",
      "epoch: 1 step: 469, loss is 0.4143281877040863\n",
      "epoch: 1 step: 470, loss is 0.5553328394889832\n",
      "epoch: 1 step: 471, loss is 0.44503772258758545\n",
      "epoch: 1 step: 472, loss is 0.6055711507797241\n",
      "epoch: 1 step: 473, loss is 0.41041404008865356\n",
      "epoch: 1 step: 474, loss is 0.3831706941127777\n",
      "epoch: 1 step: 475, loss is 0.4563245475292206\n",
      "epoch: 1 step: 476, loss is 0.4395902454853058\n",
      "epoch: 1 step: 477, loss is 0.5340160727500916\n",
      "epoch: 1 step: 478, loss is 0.5959119200706482\n",
      "epoch: 1 step: 479, loss is 0.39931467175483704\n",
      "epoch: 1 step: 480, loss is 0.41977235674858093\n",
      "epoch: 1 step: 481, loss is 0.587547242641449\n",
      "epoch: 1 step: 482, loss is 0.3888653814792633\n",
      "epoch: 1 step: 483, loss is 0.4373738169670105\n",
      "epoch: 1 step: 484, loss is 0.5191713571548462\n",
      "epoch: 1 step: 485, loss is 0.690261960029602\n",
      "epoch: 1 step: 486, loss is 0.42701461911201477\n",
      "epoch: 1 step: 487, loss is 0.7349700927734375\n",
      "epoch: 1 step: 488, loss is 0.6296036839485168\n",
      "epoch: 1 step: 489, loss is 0.523818850517273\n",
      "epoch: 1 step: 490, loss is 0.39056694507598877\n",
      "epoch: 1 step: 491, loss is 0.4915499985218048\n",
      "epoch: 1 step: 492, loss is 0.442333847284317\n",
      "epoch: 1 step: 493, loss is 0.7130272388458252\n",
      "epoch: 1 step: 494, loss is 0.6125983595848083\n",
      "epoch: 1 step: 495, loss is 0.7224545478820801\n",
      "epoch: 1 step: 496, loss is 0.6125187277793884\n",
      "epoch: 1 step: 497, loss is 0.715978741645813\n",
      "epoch: 1 step: 498, loss is 0.445677250623703\n",
      "epoch: 1 step: 499, loss is 0.40112578868865967\n",
      "epoch: 1 step: 500, loss is 0.4300678074359894\n",
      "epoch: 1 step: 501, loss is 0.6969926357269287\n",
      "epoch: 1 step: 502, loss is 0.3249002695083618\n",
      "epoch: 1 step: 503, loss is 0.4516252875328064\n",
      "epoch: 1 step: 504, loss is 0.5007809996604919\n",
      "epoch: 1 step: 505, loss is 0.528144121170044\n",
      "epoch: 1 step: 506, loss is 0.6960035562515259\n",
      "epoch: 1 step: 507, loss is 0.5581105351448059\n",
      "epoch: 1 step: 508, loss is 0.4318988621234894\n",
      "epoch: 1 step: 509, loss is 0.4252958595752716\n",
      "epoch: 1 step: 510, loss is 0.32946231961250305\n",
      "epoch: 1 step: 511, loss is 0.3262718915939331\n",
      "epoch: 1 step: 512, loss is 0.5992528200149536\n",
      "epoch: 1 step: 513, loss is 0.4806191325187683\n",
      "epoch: 1 step: 514, loss is 0.42421087622642517\n",
      "epoch: 1 step: 515, loss is 0.3491091728210449\n",
      "epoch: 1 step: 516, loss is 0.5211177468299866\n",
      "epoch: 1 step: 517, loss is 0.5462532639503479\n",
      "epoch: 1 step: 518, loss is 0.5954273343086243\n",
      "epoch: 1 step: 519, loss is 0.445475310087204\n",
      "epoch: 1 step: 520, loss is 0.5078598856925964\n",
      "epoch: 1 step: 521, loss is 0.3327503800392151\n",
      "epoch: 1 step: 522, loss is 0.5369628071784973\n",
      "epoch: 1 step: 523, loss is 0.8252411484718323\n",
      "epoch: 1 step: 524, loss is 0.7064125537872314\n",
      "epoch: 1 step: 525, loss is 0.6051656007766724\n",
      "epoch: 1 step: 526, loss is 0.5667417049407959\n",
      "epoch: 1 step: 527, loss is 0.49943938851356506\n",
      "epoch: 1 step: 528, loss is 0.6246446371078491\n",
      "epoch: 1 step: 529, loss is 0.5936259031295776\n",
      "epoch: 1 step: 530, loss is 0.6428790092468262\n",
      "epoch: 1 step: 531, loss is 0.47108927369117737\n",
      "epoch: 1 step: 532, loss is 0.5007609128952026\n",
      "epoch: 1 step: 533, loss is 0.42847198247909546\n",
      "epoch: 1 step: 534, loss is 0.5255427360534668\n",
      "epoch: 1 step: 535, loss is 0.5156297087669373\n",
      "epoch: 1 step: 536, loss is 0.43976885080337524\n",
      "epoch: 1 step: 537, loss is 0.6797317862510681\n",
      "epoch: 1 step: 538, loss is 0.4158649146556854\n",
      "epoch: 1 step: 539, loss is 0.6421732902526855\n",
      "epoch: 1 step: 540, loss is 0.43044909834861755\n",
      "epoch: 1 step: 541, loss is 0.6433815360069275\n",
      "epoch: 1 step: 542, loss is 0.6376261711120605\n",
      "epoch: 1 step: 543, loss is 0.4052680730819702\n",
      "epoch: 1 step: 544, loss is 0.4807146191596985\n",
      "epoch: 1 step: 545, loss is 0.4351325035095215\n",
      "epoch: 1 step: 546, loss is 0.6484668254852295\n",
      "epoch: 1 step: 547, loss is 0.3854674994945526\n",
      "epoch: 1 step: 548, loss is 0.5473930239677429\n",
      "epoch: 1 step: 549, loss is 0.6768574118614197\n",
      "epoch: 1 step: 550, loss is 0.4497798979282379\n",
      "epoch: 1 step: 551, loss is 0.5160049796104431\n",
      "epoch: 1 step: 552, loss is 0.6001119613647461\n",
      "epoch: 1 step: 553, loss is 0.4574633240699768\n",
      "epoch: 1 step: 554, loss is 0.45866456627845764\n",
      "epoch: 1 step: 555, loss is 0.4874201714992523\n",
      "epoch: 1 step: 556, loss is 0.7994567155838013\n",
      "epoch: 1 step: 557, loss is 0.5478605031967163\n",
      "epoch: 1 step: 558, loss is 0.3294827342033386\n",
      "epoch: 1 step: 559, loss is 0.5118439793586731\n",
      "epoch: 1 step: 560, loss is 0.3894366919994354\n",
      "epoch: 1 step: 561, loss is 0.5680823922157288\n",
      "epoch: 1 step: 562, loss is 0.42847445607185364\n",
      "epoch: 1 step: 563, loss is 0.5941235423088074\n",
      "epoch: 1 step: 564, loss is 0.37022438645362854\n",
      "epoch: 1 step: 565, loss is 0.4285848140716553\n",
      "epoch: 1 step: 566, loss is 0.5406858325004578\n",
      "epoch: 1 step: 567, loss is 0.6191297769546509\n",
      "epoch: 1 step: 568, loss is 0.31975919008255005\n",
      "epoch: 1 step: 569, loss is 0.5046019554138184\n",
      "epoch: 1 step: 570, loss is 0.545868992805481\n",
      "epoch: 1 step: 571, loss is 0.3202671706676483\n",
      "epoch: 1 step: 572, loss is 0.6227229833602905\n",
      "epoch: 1 step: 573, loss is 0.5072889924049377\n",
      "epoch: 1 step: 574, loss is 0.5878419280052185\n",
      "epoch: 1 step: 575, loss is 0.6900707483291626\n",
      "epoch: 1 step: 576, loss is 0.5379816889762878\n",
      "epoch: 1 step: 577, loss is 0.408892959356308\n",
      "epoch: 1 step: 578, loss is 0.43776562809944153\n",
      "epoch: 1 step: 579, loss is 0.6229279041290283\n",
      "epoch: 1 step: 580, loss is 0.4544852077960968\n",
      "epoch: 1 step: 581, loss is 0.6870144605636597\n",
      "epoch: 1 step: 582, loss is 0.4443081021308899\n",
      "epoch: 1 step: 583, loss is 0.4011784493923187\n",
      "epoch: 1 step: 584, loss is 0.5142034292221069\n",
      "epoch: 1 step: 585, loss is 0.43400219082832336\n",
      "epoch: 1 step: 586, loss is 0.37963512539863586\n",
      "epoch: 1 step: 587, loss is 0.5210861563682556\n",
      "epoch: 1 step: 588, loss is 0.6425110101699829\n",
      "epoch: 1 step: 589, loss is 0.5541754961013794\n",
      "epoch: 1 step: 590, loss is 0.43475958704948425\n",
      "epoch: 1 step: 591, loss is 0.33823636174201965\n",
      "epoch: 1 step: 592, loss is 0.6248727440834045\n",
      "epoch: 1 step: 593, loss is 0.6276353001594543\n",
      "epoch: 1 step: 594, loss is 0.4415423572063446\n",
      "epoch: 1 step: 595, loss is 0.5914015769958496\n",
      "epoch: 1 step: 596, loss is 0.44847285747528076\n",
      "epoch: 1 step: 597, loss is 0.744346559047699\n",
      "epoch: 1 step: 598, loss is 0.2599191665649414\n",
      "epoch: 1 step: 599, loss is 0.3867958188056946\n",
      "epoch: 1 step: 600, loss is 0.4947046637535095\n",
      "epoch: 1 step: 601, loss is 0.5041908025741577\n",
      "epoch: 1 step: 602, loss is 0.4722621440887451\n",
      "epoch: 1 step: 603, loss is 0.7143712043762207\n",
      "epoch: 1 step: 604, loss is 0.4494612216949463\n",
      "epoch: 1 step: 605, loss is 0.7188661098480225\n",
      "epoch: 1 step: 606, loss is 0.6494811177253723\n",
      "epoch: 1 step: 607, loss is 0.34130051732063293\n",
      "epoch: 1 step: 608, loss is 0.36587733030319214\n",
      "epoch: 1 step: 609, loss is 0.4554148316383362\n",
      "epoch: 1 step: 610, loss is 0.4714914858341217\n",
      "epoch: 1 step: 611, loss is 0.5268990397453308\n",
      "epoch: 1 step: 612, loss is 0.4995957016944885\n",
      "epoch: 1 step: 613, loss is 0.272534042596817\n",
      "epoch: 1 step: 614, loss is 0.3525311052799225\n",
      "epoch: 1 step: 615, loss is 0.4718013405799866\n",
      "epoch: 1 step: 616, loss is 0.4548664391040802\n",
      "epoch: 1 step: 617, loss is 0.4665302038192749\n",
      "epoch: 1 step: 618, loss is 0.5388550162315369\n",
      "epoch: 1 step: 619, loss is 0.4736536741256714\n",
      "epoch: 1 step: 620, loss is 0.46498480439186096\n",
      "epoch: 1 step: 621, loss is 0.6030870676040649\n",
      "epoch: 1 step: 622, loss is 0.6281824111938477\n",
      "epoch: 1 step: 623, loss is 0.5388978719711304\n",
      "epoch: 1 step: 624, loss is 0.44654491543769836\n",
      "epoch: 1 step: 625, loss is 0.4835147261619568\n",
      "epoch: 1 step: 626, loss is 0.6275128722190857\n",
      "epoch: 1 step: 627, loss is 0.38677382469177246\n",
      "epoch: 1 step: 628, loss is 0.492666095495224\n",
      "epoch: 1 step: 629, loss is 0.5730670690536499\n",
      "epoch: 1 step: 630, loss is 0.46245691180229187\n",
      "epoch: 1 step: 631, loss is 0.40389660000801086\n",
      "epoch: 1 step: 632, loss is 0.3938050866127014\n",
      "epoch: 1 step: 633, loss is 0.4891778826713562\n",
      "epoch: 1 step: 634, loss is 0.4057712256908417\n",
      "epoch: 1 step: 635, loss is 0.47226664423942566\n",
      "epoch: 1 step: 636, loss is 0.558380663394928\n",
      "epoch: 1 step: 637, loss is 0.41961967945098877\n",
      "epoch: 1 step: 638, loss is 0.3039434552192688\n",
      "epoch: 1 step: 639, loss is 0.687598466873169\n",
      "epoch: 1 step: 640, loss is 0.4754268229007721\n",
      "epoch: 1 step: 641, loss is 0.3845822811126709\n",
      "epoch: 1 step: 642, loss is 0.4229597747325897\n",
      "epoch: 1 step: 643, loss is 0.47268712520599365\n",
      "epoch: 1 step: 644, loss is 0.7415720224380493\n",
      "epoch: 1 step: 645, loss is 0.44183817505836487\n",
      "epoch: 1 step: 646, loss is 0.3174474835395813\n",
      "epoch: 1 step: 647, loss is 0.5734320878982544\n",
      "epoch: 1 step: 648, loss is 0.5258834958076477\n",
      "epoch: 1 step: 649, loss is 0.4637402892112732\n",
      "epoch: 1 step: 650, loss is 0.5040205717086792\n",
      "epoch: 1 step: 651, loss is 0.4944172501564026\n",
      "epoch: 1 step: 652, loss is 0.3401588201522827\n",
      "epoch: 1 step: 653, loss is 0.48894599080085754\n",
      "epoch: 1 step: 654, loss is 0.5304723381996155\n",
      "epoch: 1 step: 655, loss is 0.5152566432952881\n",
      "epoch: 1 step: 656, loss is 0.4539625644683838\n",
      "epoch: 1 step: 657, loss is 0.30179503560066223\n",
      "epoch: 1 step: 658, loss is 0.5717233419418335\n",
      "epoch: 1 step: 659, loss is 0.292406290769577\n",
      "epoch: 1 step: 660, loss is 0.6951792240142822\n",
      "epoch: 1 step: 661, loss is 0.4923365116119385\n",
      "epoch: 1 step: 662, loss is 0.5736735463142395\n",
      "epoch: 1 step: 663, loss is 0.37173569202423096\n",
      "epoch: 1 step: 664, loss is 0.6023786067962646\n",
      "epoch: 1 step: 665, loss is 0.5049435496330261\n",
      "epoch: 1 step: 666, loss is 0.39346617460250854\n",
      "epoch: 1 step: 667, loss is 0.37318164110183716\n",
      "epoch: 1 step: 668, loss is 0.27907079458236694\n",
      "epoch: 1 step: 669, loss is 0.4752258360385895\n",
      "epoch: 1 step: 670, loss is 0.524501383304596\n",
      "epoch: 1 step: 671, loss is 0.49602627754211426\n",
      "epoch: 1 step: 672, loss is 0.4854343831539154\n",
      "epoch: 1 step: 673, loss is 0.41261810064315796\n",
      "epoch: 1 step: 674, loss is 0.36384233832359314\n",
      "epoch: 1 step: 675, loss is 0.510639488697052\n",
      "epoch: 1 step: 676, loss is 0.6879542469978333\n",
      "epoch: 1 step: 677, loss is 0.5194013118743896\n",
      "epoch: 1 step: 678, loss is 0.571169912815094\n",
      "epoch: 1 step: 679, loss is 0.4563595950603485\n",
      "epoch: 1 step: 680, loss is 0.5795917510986328\n",
      "epoch: 1 step: 681, loss is 0.4765222668647766\n",
      "epoch: 1 step: 682, loss is 0.41465139389038086\n",
      "epoch: 1 step: 683, loss is 0.3069702684879303\n",
      "epoch: 1 step: 684, loss is 0.4248574674129486\n",
      "epoch: 1 step: 685, loss is 0.45591044425964355\n",
      "epoch: 1 step: 686, loss is 0.514091968536377\n",
      "epoch: 1 step: 687, loss is 0.702957034111023\n",
      "epoch: 1 step: 688, loss is 0.3971507251262665\n",
      "epoch: 1 step: 689, loss is 0.5183736085891724\n",
      "epoch: 1 step: 690, loss is 0.3263552188873291\n",
      "epoch: 1 step: 691, loss is 0.476654976606369\n",
      "epoch: 1 step: 692, loss is 0.4124687612056732\n",
      "epoch: 1 step: 693, loss is 0.5309898257255554\n",
      "epoch: 1 step: 694, loss is 0.6563485860824585\n",
      "epoch: 1 step: 695, loss is 0.44545045495033264\n",
      "epoch: 1 step: 696, loss is 0.5943908095359802\n",
      "epoch: 1 step: 697, loss is 0.5207871198654175\n",
      "epoch: 1 step: 698, loss is 0.5901095867156982\n",
      "epoch: 1 step: 699, loss is 0.41141024231910706\n",
      "epoch: 1 step: 700, loss is 0.5094901919364929\n",
      "epoch: 1 step: 701, loss is 0.681171715259552\n",
      "epoch: 1 step: 702, loss is 0.3623238205909729\n",
      "epoch: 1 step: 703, loss is 0.4386318325996399\n",
      "epoch: 1 step: 704, loss is 0.5278468132019043\n",
      "epoch: 1 step: 705, loss is 0.2850748598575592\n",
      "epoch: 1 step: 706, loss is 0.4943729341030121\n",
      "epoch: 1 step: 707, loss is 0.5452497601509094\n",
      "epoch: 1 step: 708, loss is 0.3908437192440033\n",
      "epoch: 1 step: 709, loss is 0.40671080350875854\n",
      "epoch: 1 step: 710, loss is 0.670525312423706\n",
      "epoch: 1 step: 711, loss is 0.5956839919090271\n",
      "epoch: 1 step: 712, loss is 0.51994788646698\n",
      "epoch: 1 step: 713, loss is 0.5329359173774719\n",
      "epoch: 1 step: 714, loss is 0.5386820435523987\n",
      "epoch: 1 step: 715, loss is 0.4217734634876251\n",
      "epoch: 1 step: 716, loss is 0.5289247035980225\n",
      "epoch: 1 step: 717, loss is 0.39020854234695435\n",
      "epoch: 1 step: 718, loss is 0.2798062562942505\n",
      "epoch: 1 step: 719, loss is 0.5040698647499084\n",
      "epoch: 1 step: 720, loss is 0.41633325815200806\n",
      "epoch: 1 step: 721, loss is 0.5308440923690796\n",
      "epoch: 1 step: 722, loss is 0.4314042627811432\n",
      "epoch: 1 step: 723, loss is 0.3497960567474365\n",
      "epoch: 1 step: 724, loss is 0.476686030626297\n",
      "epoch: 1 step: 725, loss is 0.7494783997535706\n",
      "epoch: 1 step: 726, loss is 0.48535656929016113\n",
      "epoch: 1 step: 727, loss is 0.5324945449829102\n",
      "epoch: 1 step: 728, loss is 0.38390547037124634\n",
      "epoch: 1 step: 729, loss is 0.48989954590797424\n",
      "epoch: 1 step: 730, loss is 0.39460715651512146\n",
      "epoch: 1 step: 731, loss is 0.449730783700943\n",
      "epoch: 1 step: 732, loss is 0.5832861661911011\n",
      "epoch: 1 step: 733, loss is 0.5661333799362183\n",
      "epoch: 1 step: 734, loss is 0.5796301960945129\n",
      "epoch: 1 step: 735, loss is 0.6233956813812256\n",
      "epoch: 1 step: 736, loss is 0.4686209261417389\n",
      "epoch: 1 step: 737, loss is 0.47534188628196716\n",
      "epoch: 1 step: 738, loss is 0.5956196784973145\n",
      "epoch: 1 step: 739, loss is 0.5772587060928345\n",
      "epoch: 1 step: 740, loss is 0.43613401055336\n",
      "epoch: 1 step: 741, loss is 0.581554114818573\n",
      "epoch: 1 step: 742, loss is 0.47714582085609436\n",
      "epoch: 1 step: 743, loss is 0.5166231393814087\n",
      "epoch: 1 step: 744, loss is 0.3897322714328766\n",
      "epoch: 1 step: 745, loss is 0.4592408537864685\n",
      "epoch: 1 step: 746, loss is 0.4867127239704132\n",
      "epoch: 1 step: 747, loss is 0.4647156000137329\n",
      "epoch: 1 step: 748, loss is 0.48990029096603394\n",
      "epoch: 1 step: 749, loss is 0.44762924313545227\n",
      "epoch: 1 step: 750, loss is 0.44526758790016174\n",
      "epoch: 1 step: 751, loss is 0.44885149598121643\n",
      "epoch: 1 step: 752, loss is 0.531359851360321\n",
      "epoch: 1 step: 753, loss is 0.44783931970596313\n",
      "epoch: 1 step: 754, loss is 0.3660341501235962\n",
      "epoch: 1 step: 755, loss is 0.5269820690155029\n",
      "epoch: 1 step: 756, loss is 0.5860246419906616\n",
      "epoch: 1 step: 757, loss is 0.599227786064148\n",
      "epoch: 1 step: 758, loss is 0.42656445503234863\n",
      "epoch: 1 step: 759, loss is 0.565115213394165\n",
      "epoch: 1 step: 760, loss is 0.5127841830253601\n",
      "epoch: 1 step: 761, loss is 0.3272978365421295\n",
      "epoch: 1 step: 762, loss is 0.4698469936847687\n",
      "epoch: 1 step: 763, loss is 0.3920374810695648\n",
      "epoch: 1 step: 764, loss is 0.6114124059677124\n",
      "epoch: 1 step: 765, loss is 0.44365212321281433\n",
      "epoch: 1 step: 766, loss is 0.5048807859420776\n",
      "epoch: 1 step: 767, loss is 0.4606505334377289\n",
      "epoch: 1 step: 768, loss is 0.6845746040344238\n",
      "epoch: 1 step: 769, loss is 0.523685872554779\n",
      "epoch: 1 step: 770, loss is 0.39550668001174927\n",
      "epoch: 1 step: 771, loss is 0.47449377179145813\n",
      "epoch: 1 step: 772, loss is 0.40926462411880493\n",
      "epoch: 1 step: 773, loss is 0.5380632877349854\n",
      "epoch: 1 step: 774, loss is 0.3959277868270874\n",
      "epoch: 1 step: 775, loss is 0.339221328496933\n",
      "epoch: 1 step: 776, loss is 0.5915598273277283\n",
      "epoch: 1 step: 777, loss is 0.5741967558860779\n",
      "epoch: 1 step: 778, loss is 0.30270594358444214\n",
      "epoch: 1 step: 779, loss is 0.4160138666629791\n",
      "epoch: 1 step: 780, loss is 0.38425692915916443\n",
      "epoch: 1 step: 781, loss is 0.6264631152153015\n",
      "epoch: 1 step: 782, loss is 0.47140923142433167\n",
      "epoch: 1 step: 783, loss is 0.40118956565856934\n",
      "epoch: 1 step: 784, loss is 0.5049993991851807\n",
      "epoch: 1 step: 785, loss is 0.4268805980682373\n",
      "epoch: 1 step: 786, loss is 0.5399657487869263\n",
      "epoch: 1 step: 787, loss is 0.5451138615608215\n",
      "epoch: 1 step: 788, loss is 0.6390503644943237\n",
      "epoch: 1 step: 789, loss is 0.6633184552192688\n",
      "epoch: 1 step: 790, loss is 0.34729284048080444\n",
      "epoch: 1 step: 791, loss is 0.29532769322395325\n",
      "epoch: 1 step: 792, loss is 0.45140340924263\n",
      "epoch: 1 step: 793, loss is 0.4871801733970642\n",
      "epoch: 1 step: 794, loss is 0.3217269480228424\n",
      "epoch: 1 step: 795, loss is 0.42193877696990967\n",
      "epoch: 1 step: 796, loss is 0.6109015345573425\n",
      "epoch: 1 step: 797, loss is 0.3705238699913025\n",
      "epoch: 1 step: 798, loss is 0.3851616084575653\n",
      "epoch: 1 step: 799, loss is 0.423733115196228\n",
      "epoch: 1 step: 800, loss is 0.42460545897483826\n",
      "epoch: 1 step: 801, loss is 0.5384290814399719\n",
      "epoch: 1 step: 802, loss is 0.45260751247406006\n",
      "epoch: 1 step: 803, loss is 0.4354323148727417\n",
      "epoch: 1 step: 804, loss is 0.37733545899391174\n",
      "epoch: 1 step: 805, loss is 0.7517459988594055\n",
      "epoch: 1 step: 806, loss is 0.5672789812088013\n",
      "epoch: 1 step: 807, loss is 0.3669569492340088\n",
      "epoch: 1 step: 808, loss is 0.3942260444164276\n",
      "epoch: 1 step: 809, loss is 0.4460428059101105\n",
      "epoch: 1 step: 810, loss is 0.5730700492858887\n",
      "epoch: 1 step: 811, loss is 0.2452908605337143\n",
      "epoch: 1 step: 812, loss is 0.6658478379249573\n",
      "epoch: 1 step: 813, loss is 0.5571594834327698\n",
      "epoch: 1 step: 814, loss is 0.48058995604515076\n",
      "epoch: 1 step: 815, loss is 0.2800014019012451\n",
      "epoch: 1 step: 816, loss is 0.3369245231151581\n",
      "epoch: 1 step: 817, loss is 0.5232875943183899\n",
      "epoch: 1 step: 818, loss is 0.35038119554519653\n",
      "epoch: 1 step: 819, loss is 0.35768207907676697\n",
      "epoch: 1 step: 820, loss is 0.504863440990448\n",
      "epoch: 1 step: 821, loss is 0.4256930351257324\n",
      "epoch: 1 step: 822, loss is 0.3387782871723175\n",
      "epoch: 1 step: 823, loss is 0.4364915192127228\n",
      "epoch: 1 step: 824, loss is 0.6325021982192993\n",
      "epoch: 1 step: 825, loss is 0.30611327290534973\n",
      "epoch: 1 step: 826, loss is 0.388717919588089\n",
      "epoch: 1 step: 827, loss is 0.3494854271411896\n",
      "epoch: 1 step: 828, loss is 0.49765148758888245\n",
      "epoch: 1 step: 829, loss is 0.3885732889175415\n",
      "epoch: 1 step: 830, loss is 0.4590282142162323\n",
      "epoch: 1 step: 831, loss is 0.40161341428756714\n",
      "epoch: 1 step: 832, loss is 0.541486918926239\n",
      "epoch: 1 step: 833, loss is 0.6397915482521057\n",
      "epoch: 1 step: 834, loss is 0.37947744131088257\n",
      "epoch: 1 step: 835, loss is 0.4773268699645996\n",
      "epoch: 1 step: 836, loss is 0.36006873846054077\n",
      "epoch: 1 step: 837, loss is 0.4032733738422394\n",
      "epoch: 1 step: 838, loss is 0.2929871380329132\n",
      "epoch: 1 step: 839, loss is 0.5736163258552551\n",
      "epoch: 1 step: 840, loss is 0.37485411763191223\n",
      "epoch: 1 step: 841, loss is 0.41854333877563477\n",
      "epoch: 1 step: 842, loss is 0.3140392601490021\n",
      "epoch: 1 step: 843, loss is 0.44464975595474243\n",
      "epoch: 1 step: 844, loss is 0.38130006194114685\n",
      "epoch: 1 step: 845, loss is 0.5522915720939636\n",
      "epoch: 1 step: 846, loss is 0.5492780804634094\n",
      "epoch: 1 step: 847, loss is 0.37154996395111084\n",
      "epoch: 1 step: 848, loss is 0.5626766085624695\n",
      "epoch: 1 step: 849, loss is 0.29294341802597046\n",
      "epoch: 1 step: 850, loss is 0.38841989636421204\n",
      "epoch: 1 step: 851, loss is 0.2736574709415436\n",
      "epoch: 1 step: 852, loss is 0.3511616885662079\n",
      "epoch: 1 step: 853, loss is 0.4469512104988098\n",
      "epoch: 1 step: 854, loss is 0.3269836902618408\n",
      "epoch: 1 step: 855, loss is 0.4055157005786896\n",
      "epoch: 1 step: 856, loss is 0.486097127199173\n",
      "epoch: 1 step: 857, loss is 0.4122057557106018\n",
      "epoch: 1 step: 858, loss is 0.4869341552257538\n",
      "epoch: 1 step: 859, loss is 0.3199426829814911\n",
      "epoch: 1 step: 860, loss is 0.40655407309532166\n",
      "epoch: 1 step: 861, loss is 0.35097482800483704\n",
      "epoch: 1 step: 862, loss is 0.3811173141002655\n",
      "epoch: 1 step: 863, loss is 0.39903587102890015\n",
      "epoch: 1 step: 864, loss is 0.4409934878349304\n",
      "epoch: 1 step: 865, loss is 0.4104450047016144\n",
      "epoch: 1 step: 866, loss is 0.5739362835884094\n",
      "epoch: 1 step: 867, loss is 0.5027217268943787\n",
      "epoch: 1 step: 868, loss is 0.4157487452030182\n",
      "epoch: 1 step: 869, loss is 0.49935856461524963\n",
      "epoch: 1 step: 870, loss is 0.2945055067539215\n",
      "epoch: 1 step: 871, loss is 0.2696150541305542\n",
      "epoch: 1 step: 872, loss is 0.3362594246864319\n",
      "epoch: 1 step: 873, loss is 0.359333872795105\n",
      "epoch: 1 step: 874, loss is 0.4082452058792114\n",
      "epoch: 1 step: 875, loss is 0.5170366764068604\n",
      "epoch: 1 step: 876, loss is 0.5725368857383728\n",
      "epoch: 1 step: 877, loss is 0.37310975790023804\n",
      "epoch: 1 step: 878, loss is 0.3605698347091675\n",
      "epoch: 1 step: 879, loss is 0.5995571613311768\n",
      "epoch: 1 step: 880, loss is 0.7058065533638\n",
      "epoch: 1 step: 881, loss is 0.6292213201522827\n",
      "epoch: 1 step: 882, loss is 0.5100047588348389\n",
      "epoch: 1 step: 883, loss is 0.43796616792678833\n",
      "epoch: 1 step: 884, loss is 0.67635577917099\n",
      "epoch: 1 step: 885, loss is 0.3889719843864441\n",
      "epoch: 1 step: 886, loss is 0.3994287848472595\n",
      "epoch: 1 step: 887, loss is 0.3433140516281128\n",
      "epoch: 1 step: 888, loss is 0.35954177379608154\n",
      "epoch: 1 step: 889, loss is 0.4559018015861511\n",
      "epoch: 1 step: 890, loss is 0.3641045391559601\n",
      "epoch: 1 step: 891, loss is 0.40002697706222534\n",
      "epoch: 1 step: 892, loss is 0.29362574219703674\n",
      "epoch: 1 step: 893, loss is 0.37528669834136963\n",
      "epoch: 1 step: 894, loss is 0.4366265535354614\n",
      "epoch: 1 step: 895, loss is 0.3898468613624573\n",
      "epoch: 1 step: 896, loss is 0.2355245053768158\n",
      "epoch: 1 step: 897, loss is 0.26442569494247437\n",
      "epoch: 1 step: 898, loss is 0.2727627456188202\n",
      "epoch: 1 step: 899, loss is 0.5179061889648438\n",
      "epoch: 1 step: 900, loss is 0.5984154343605042\n",
      "epoch: 1 step: 901, loss is 0.4476337134838104\n",
      "epoch: 1 step: 902, loss is 0.45749613642692566\n",
      "epoch: 1 step: 903, loss is 0.3297300338745117\n",
      "epoch: 1 step: 904, loss is 0.2553096413612366\n",
      "epoch: 1 step: 905, loss is 0.504732608795166\n",
      "epoch: 1 step: 906, loss is 0.5117226243019104\n",
      "epoch: 1 step: 907, loss is 0.2889641225337982\n",
      "epoch: 1 step: 908, loss is 0.3513392210006714\n",
      "epoch: 1 step: 909, loss is 0.535987913608551\n",
      "epoch: 1 step: 910, loss is 0.5505468249320984\n",
      "epoch: 1 step: 911, loss is 0.2257145643234253\n",
      "epoch: 1 step: 912, loss is 0.4612357020378113\n",
      "epoch: 1 step: 913, loss is 0.42507222294807434\n",
      "epoch: 1 step: 914, loss is 0.4708962142467499\n",
      "epoch: 1 step: 915, loss is 0.4250236749649048\n",
      "epoch: 1 step: 916, loss is 0.6495829224586487\n",
      "epoch: 1 step: 917, loss is 0.32115858793258667\n",
      "epoch: 1 step: 918, loss is 0.3878529369831085\n",
      "epoch: 1 step: 919, loss is 0.5296509265899658\n",
      "epoch: 1 step: 920, loss is 0.4927193820476532\n",
      "epoch: 1 step: 921, loss is 0.42603522539138794\n",
      "epoch: 1 step: 922, loss is 0.47660690546035767\n",
      "epoch: 1 step: 923, loss is 0.317487895488739\n",
      "epoch: 1 step: 924, loss is 0.4468148648738861\n",
      "epoch: 1 step: 925, loss is 0.41879481077194214\n",
      "epoch: 1 step: 926, loss is 0.40982019901275635\n",
      "epoch: 1 step: 927, loss is 0.34302639961242676\n",
      "epoch: 1 step: 928, loss is 0.39925119280815125\n",
      "epoch: 1 step: 929, loss is 0.45596832036972046\n",
      "epoch: 1 step: 930, loss is 0.3580434322357178\n",
      "epoch: 1 step: 931, loss is 0.7299321889877319\n",
      "epoch: 1 step: 932, loss is 0.5123023986816406\n",
      "epoch: 1 step: 933, loss is 0.5047776103019714\n",
      "epoch: 1 step: 934, loss is 0.46926355361938477\n",
      "epoch: 1 step: 935, loss is 0.6659408211708069\n",
      "epoch: 1 step: 936, loss is 0.49288228154182434\n",
      "epoch: 1 step: 937, loss is 0.3949384391307831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(16032:21436,MainProcess):2023-05-14-19:23:45.598.502 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(16032:21436,MainProcess):2023-05-14-19:23:45.606.503 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(16032:21436,MainProcess):2023-05-14-19:23:45.617.501 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(16032:21436,MainProcess):2023-05-14-19:23:45.639.501 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(16032:21436,MainProcess):2023-05-14-19:23:45.651.502 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.858573717948718}\n"
     ]
    }
   ],
   "source": [
    "# 训练有正则化的网络\n",
    "model = train(ForwardFashionRegularization)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(16032:21436,MainProcess):2023-05-14-16:58:22.669.214 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(16032:21436,MainProcess):2023-05-14-16:58:22.674.230 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(16032:21436,MainProcess):2023-05-14-16:58:22.684.216 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(16032:21436,MainProcess):2023-05-14-16:58:22.690.230 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个sample预测结果： 7    真实结果： 7\n",
      "第1个sample预测结果： 9    真实结果： 9\n",
      "第2个sample预测结果： 8    真实结果： 8\n",
      "第3个sample预测结果： 0    真实结果： 6\n",
      "第4个sample预测结果： 1    真实结果： 1\n",
      "第5个sample预测结果： 1    真实结果： 1\n",
      "第6个sample预测结果： 1    真实结果： 1\n",
      "第7个sample预测结果： 3    真实结果： 3\n",
      "第8个sample预测结果： 5    真实结果： 5\n",
      "第9个sample预测结果： 3    真实结果： 1\n",
      "第10个sample预测结果： 3    真实结果： 1\n",
      "第11个sample预测结果： 6    真实结果： 6\n",
      "第12个sample预测结果： 3    真实结果： 3\n",
      "第13个sample预测结果： 7    真实结果： 7\n",
      "第14个sample预测结果： 9    真实结果： 9\n"
     ]
    }
   ],
   "source": [
    "# 预测\n",
    "ds_test, _ = create_dataset()\n",
    "test_ = ds_test.create_dict_iterator(output_numpy=True).__next__()\n",
    "predictions = model.predict(Tensor(test_['x']))\n",
    "predictions = predictions.asnumpy()\n",
    "for i in range(15):\n",
    "    p_np = predictions[i, :]\n",
    "    p_list = p_np.tolist()\n",
    "    print('第' + str(i) + '个sample预测结果：', p_list.index(max(p_list)), '   真实结果：', test_['y'][i])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 可视化结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------定义可视化函数--------------------------------\n",
    "# 输入预测结果序列，真实标签序列，以及图片序列\n",
    "# 目标是根据预测值对错，让其标签显示为红色或者蓝色。对：标签为红色；错：标签为蓝色\n",
    "def plot_image(predictions_array, true_label, img):\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    # 显示对应图片\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "    # 显示预测结果的颜色，如果对上了是蓝色，否则为红色\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "    # 显示对应标签的格式，样式\n",
    "    plt.xlabel('{},{:2.0f}% ({})'.format(class_names[predicted_label],\n",
    "                                         100 * np.max(predictions_array),\n",
    "                                         class_names[true_label]), color=color)\n",
    "# 将预测的结果以柱状图形状显示蓝对红错\n",
    "def plot_value_array(predictions_array, true_label):\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    this_plot = plt.bar(range(10), predictions_array, color='#777777')\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    this_plot[predicted_label].set_color('red')\n",
    "    this_plot[true_label].set_color('blue')\n",
    "\n",
    "import numpy as np\n",
    "def softmax_np(x):\n",
    "    x = x - np.max(x)\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x/np.sum(exp_x)\n",
    "    return softmax_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 预测15个图像与标签，并展现出来\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows * num_cols\n",
    "plt.figure(figsize=(2 * 2 * num_cols, 2 * num_rows))\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2 * num_cols, 2 * i + 1)\n",
    "    pred_np_ = predictions[i, :]\n",
    "    pred_np_ = softmax_np(pred_np_)\n",
    "    plot_image(pred_np_, test_['y'][i], test_['x'][i, 0, ...])\n",
    "    plt.subplot(num_rows, 2 * num_cols, 2 * i + 2)\n",
    "    plot_value_array(pred_np_, test_['y'][i])\n",
    "plt.show() \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mindspore_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
