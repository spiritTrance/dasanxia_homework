{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入实验环境"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://bbs.huaweicloud.com/blogs/344369"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import sys\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import mindspore\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.nn as nn\n",
    "from mindspore import context\n",
    "from mindspore.nn.metrics import Accuracy, Loss\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor, TimeMonitor\n",
    "from mindspore import Tensor\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target='CPU') \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = edict({\n",
    "    'train_size': 60000,  # 训练集大小\n",
    "    'test_size': 10000,  # 测试集大小\n",
    "    # 'train_size': 600,  # 训练集大小\n",
    "    # 'test_size': 100,  # 测试集大小\n",
    "    'channel': 1,  # 图片通道数\n",
    "    'image_height': 28,  # 图片高度\n",
    "    'image_width': 28,  # 图片宽度\n",
    "    'batch_size': 256,\n",
    "    'num_classes': 10,  # 分类类别\n",
    "    'lr': 0.001,  # 学习率\n",
    "    'epoch_size': 10,  # 训练次数\n",
    "    'data_dir_train': os.path.join('fashion-mnist', 'train'),\n",
    "    'data_dir_test': os.path.join('fashion-mnist', 'test'),\n",
    "}) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读取和预处理"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义函数用于读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(file_name):\n",
    "    '''\n",
    "    :param file_name: 文件路径\n",
    "    :return:  训练或者测试数据\n",
    "    如下是训练的图片的二进制格式\n",
    "    [offset] [type]          [value]          [description]\n",
    "    0000     32 bit integer  0x00000803(2051) magic number\n",
    "    0004     32 bit integer  60000            number of images\n",
    "    0008     32 bit integer  28               number of rows\n",
    "    0012     32 bit integer  28               number of columns\n",
    "    0016     unsigned byte   ??               pixel\n",
    "    0017     unsigned byte   ??               pixel\n",
    "    ........\n",
    "    xxxx     unsigned byte   ??               pixel\n",
    "    '''\n",
    "    file_handle = open(file_name, \"rb\")  # 以二进制打开文档\n",
    "    file_content = file_handle.read()  # 读取到缓冲区中\n",
    "    head = struct.unpack_from('>IIII', file_content, 0)  # 取前4个整数，返回一个元组\n",
    "    offset = struct.calcsize('>IIII')\n",
    "    imgNum = head[1]  # 图片数\n",
    "    width = head[2]  # 宽度\n",
    "    height = head[3]  # 高度\n",
    "    bits = imgNum * width * height  # data一共有60000*28*28个像素值\n",
    "    bitsString = '>' + str(bits) + 'B'  # fmt格式：'>47040000B'\n",
    "    imgs = struct.unpack_from(bitsString, file_content, offset)  # 取data数据，返回一个元组\n",
    "    imgs_array = np.array(imgs, np.float32).reshape((imgNum, width * height))  # 最后将读取的数据reshape成 【图片数，图片像素】二维数组\n",
    "    return imgs_array\n",
    "\n",
    "\n",
    "def read_label(file_name):\n",
    "    '''\n",
    "    :param file_name:\n",
    "    :return:\n",
    "    标签的格式如下：\n",
    "    [offset] [type]          [value]          [description]\n",
    "    0000     32 bit integer  0x00000801(2049) magic number (MSB first)\n",
    "    0004     32 bit integer  60000            number of items\n",
    "    0008     unsigned byte   ??               label\n",
    "    0009     unsigned byte   ??               label\n",
    "    ........\n",
    "    xxxx     unsigned byte   ??               label\n",
    "    The labels values are 0 to 9.\n",
    "    '''\n",
    "    file_handle = open(file_name, \"rb\")  # 以二进制打开文档\n",
    "    file_content = file_handle.read()  # 读取到缓冲区中\n",
    "    head = struct.unpack_from('>II', file_content, 0)  # 取前2个整数，返回一个元组\n",
    "    offset = struct.calcsize('>II')\n",
    "    labelNum = head[1]  # label数\n",
    "    bitsString = '>' + str(labelNum) + 'B'  # fmt格式：'>47040000B'\n",
    "    label = struct.unpack_from(bitsString, file_content, offset)  # 取data数据，返回一个元组\n",
    "    return np.array(label, np.int32)\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    # 文件获取\n",
    "    train_image = os.path.join(cfg.data_dir_train, 'train-images-idx3-ubyte')\n",
    "    test_image = os.path.join(cfg.data_dir_test, \"t10k-images-idx3-ubyte\")\n",
    "    train_label = os.path.join(cfg.data_dir_train, \"train-labels-idx1-ubyte\")\n",
    "    test_label = os.path.join(cfg.data_dir_test, \"t10k-labels-idx1-ubyte\")\n",
    "    # 读取数据\n",
    "    train_x = read_image(train_image)\n",
    "    test_x = read_image(test_image)\n",
    "    train_y = read_label(train_label)\n",
    "    test_y = read_label(test_label)\n",
    "    return train_x, train_y, test_x, test_y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据集样本数： 60000\n",
      "测试数据集样本数： 10000\n",
      "通道数/图像长/宽： (1, 28, 28)\n",
      "一张图像的标签样式： 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y = get_data()\n",
    "train_x = train_x.reshape(-1, 1, cfg.image_height, cfg.image_width)\n",
    "test_x = test_x.reshape(-1, 1, cfg.image_height, cfg.image_width)\n",
    "train_x = train_x / 255.0\n",
    "test_x = test_x / 255.0\n",
    "\n",
    "print('训练数据集样本数：', train_x.shape[0])\n",
    "print('测试数据集样本数：', test_y.shape[0])\n",
    "print('通道数/图像长/宽：', train_x.shape[1:])\n",
    "print('一张图像的标签样式：', train_y[0])  # 一共10类，用0-9的数字表达类别。\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(train_x[0,0,...])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换数据类型为Dataset\n",
    "def create_dataset():\n",
    "    XY_train = list(zip(train_x, train_y))\n",
    "    ds_train = ds.GeneratorDataset(XY_train, ['x', 'y'])\n",
    "    ds_train = ds_train.shuffle(buffer_size=1000).batch(cfg.batch_size, drop_remainder=True)\n",
    "    XY_test = list(zip(test_x, test_y))\n",
    "    ds_test = ds.GeneratorDataset(XY_test, ['x', 'y'])\n",
    "    ds_test = ds_test.shuffle(buffer_size=1000).batch(cfg.batch_size, drop_remainder=True)\n",
    "    return ds_train, ds_test \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回调函数声明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个自定义的回调函数，继承自Callback类\n",
    "from mindspore.train.callback import Callback\n",
    "class EvalCallBack(Callback):\n",
    "    def __init__(self, model, train_dataset, test_dataset, dataset_sink_mode = False, epochs_to_eval = 1):\n",
    "        self.model = model\n",
    "        self.train_dataset = train_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        # epochs_to_eval是一个int数字，代表着：每隔多少个epoch进行一次验证\n",
    "        self.epochs_to_eval = epochs_to_eval\n",
    "        self.per_eval = {\"epoch\": [], \"test_acc\": [], \"train_acc\": [], \"test_loss\": [], \"train_loss\": []}\n",
    "        self.dataset_sink_mode = dataset_sink_mode\n",
    "\n",
    "    def epoch_end(self, run_context):\n",
    "        # 获取到现在的epoch数\n",
    "        cb_param = run_context.original_args()\n",
    "        cur_epoch = cb_param.cur_epoch_num\n",
    "        # 如果达到进行验证的epoch数，则进行以下验证操作\n",
    "        if cur_epoch % self.epochs_to_eval == 0:\n",
    "            # 此处model设定的metrics是准确率Accuracy\n",
    "            train_acc = self.model.eval(self.train_dataset, dataset_sink_mode=self.dataset_sink_mode)[\"train_acc\"]\n",
    "            test_acc = self.model.eval(self.test_dataset, dataset_sink_mode=self.dataset_sink_mode)[\"test_acc\"]\n",
    "            train_loss = self.model.eval(self.train_dataset, dataset_sink_mode=self.dataset_sink_mode)[\"train_loss\"]\n",
    "            test_loss = self.model.eval(self.test_dataset, dataset_sink_mode=self.dataset_sink_mode)[\"test_loss\"]\n",
    "            self.per_eval[\"epoch\"].append(cur_epoch)\n",
    "            self.per_eval[\"test_acc\"].append(test_acc)\n",
    "            self.per_eval[\"train_acc\"].append(train_acc)\n",
    "            self.per_eval[\"train_loss\"].append(test_acc)\n",
    "            self.per_eval[\"test_loss\"].append(train_acc)\n",
    "            print(\"Epoch{}: train_acc: {}, test_acc: {}, train_loss: {}, test_loss{}\".format(cur_epoch, train_acc, test_acc, train_loss, test_loss))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NetWork"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaseLine NetWork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义卷积神经网络，BaseLine\n",
    "class ForwardFashion_baseline(nn.Cell):\n",
    "    def __init__(self, num_class=10):  # 一共分十类，图片通道数是1\n",
    "        super(ForwardFashion_baseline, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.conv1 = nn.Conv2d(1, 32,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "        self.conv2 = nn.Conv2d(32, 64,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "        self.conv3 = nn.Conv2d(64, 128,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "        self.maxpool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Dense(128 * 11 * 11, 128)\n",
    "        self.fc2 = nn.Dense(128, self.num_class)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2d(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network With BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义卷积神经网络，批量归一化\n",
    "class ForwardFashionWithBatchNorm(nn.Cell):\n",
    "    def __init__(self, num_class=10):  # 一共分十类，图片通道数是1\n",
    "        super(ForwardFashionWithBatchNorm, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.conv1 = nn.Conv2d(1, 32,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "        self.conv2 = nn.Conv2d(32, 64,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "        self.conv3 = nn.Conv2d(64, 128,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "        self.maxpool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Dense(3200, 128)\n",
    "        self.bn = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Dense(128, self.num_class)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2d(x)\n",
    "        # x = self.dropout(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2d(x)\n",
    "        # x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn(x)\n",
    "        # x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NetWork with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义卷积神经网络，有Dropout正则化\n",
    "class ForwardFashionWithDropout(nn.Cell):\n",
    "    def __init__(self, num_class=10):  # 一共分十类，图片通道数是1\n",
    "        super(ForwardFashionWithDropout, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.conv1 = nn.Conv2d(1, 32,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "        self.conv2 = nn.Conv2d(32, 64,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "        self.conv3 = nn.Conv2d(64, 128,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "        self.maxpool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.8)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Dense(3200, 128)\n",
    "        self.fc2 = nn.Dense(128, self.num_class)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2d(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2d(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network With BatchNorm And Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义卷积神经网络，批量归一化\n",
    "class ForwardFashionWithBatchNormAndDropout(nn.Cell):\n",
    "    def __init__(self, num_class=10):  # 一共分十类，图片通道数是1\n",
    "        super(ForwardFashionWithBatchNormAndDropout, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.conv1 = nn.Conv2d(1, 32,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "        self.conv2 = nn.Conv2d(32, 64,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "        self.conv3 = nn.Conv2d(64, 128,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "        self.maxpool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Dense(3200, 128)\n",
    "        self.bn = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Dense(128, self.num_class)\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2d(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2d(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1正则 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import ops\n",
    "# 定义具有L1正则化的交叉熵损失函数\n",
    "class L1CrossEntropyLoss(nn.Cell):\n",
    "    def __init__(self, params, l1_weight = 1e-4, reduction = \"mean\"):\n",
    "        super(L1CrossEntropyLoss, self).__init__(reduction)\n",
    "        self.params = params\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "        self.l1 = nn.L1Regularizer(l1_weight)\n",
    "        self.reduce_sum = ops.ReduceSum()\n",
    "        self.concat = ops.Concat(axis=0)\n",
    "        self.reshape = ops.Reshape()\n",
    "\n",
    "    def construct(self, pred, label):\n",
    "        flatten_params = self.concat([self.reshape(p, (-1,)) for p in self.params])\n",
    "        ce_loss = self.ce(pred, label)\n",
    "        l1_loss = self.reduce_sum(self.l1(flatten_params))      # 计算L1范数惩罚项\n",
    "        total_loss = ce_loss + l1_loss\n",
    "        return total_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2正则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import ops\n",
    "# 定义具有L2正则化的交叉熵损失函数\n",
    "class L2CrossEntropyLoss(nn.Cell):\n",
    "    def __init__(self, params, l2_weight = 1e-4, reduction = \"mean\"):\n",
    "        super(L2CrossEntropyLoss, self).__init__(reduction)\n",
    "        self.params = params\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "        self.l1 = nn.L1Regularizer(1)\n",
    "        self.l2_weight = l2_weight\n",
    "        self.reduce_sum = ops.ReduceSum()\n",
    "        self.concat = ops.Concat(axis=0)\n",
    "        self.reshape = ops.Reshape()\n",
    "\n",
    "    def construct(self, pred, label):\n",
    "        flatten_params = self.concat([self.reshape(p, (-1,)) for p in self.params])\n",
    "        ce_loss = self.ce(pred, label)\n",
    "        l1_loss = self.reduce_sum(self.l1(flatten_params)) * self.reduce_sum(self.l1(flatten_params)) * self.l2_weight      # 计算L1范数惩罚项\n",
    "        total_loss = ce_loss + l1_loss\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定义卷积神经网络，BaseLine\n",
    "# class ForwardFashion(nn.Cell):\n",
    "#     def __init__(self, num_class=10):  # 一共分十类，图片通道数是1\n",
    "#         super(ForwardFashion, self).__init__()\n",
    "#         self.num_class = num_class\n",
    "#         self.conv1 = nn.Conv2d(1, 32,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "#         self.conv2 = nn.Conv2d(32, 64,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "#         self.conv3 = nn.Conv2d(64, 128,kernel_size=3, stride=1, padding=0, has_bias=False, pad_mode=\"valid\")\n",
    "#         self.maxpool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.flatten = nn.Flatten()\n",
    "#         self.fc1 = nn.Dense(128 * 11 * 11, 128)\n",
    "#         self.fc2 = nn.Dense(128, self.num_class)\n",
    "\n",
    "#     def construct(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.conv3(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.maxpool2d(x)\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "    \n",
    "\n",
    "# def train_FTRL(Net):\n",
    "#     ds_train, ds_test = create_dataset()\n",
    "#     # 构建网络\n",
    "#     network = Net(cfg.num_classes)\n",
    "#     # 定义模型的损失函数，优化器    \n",
    "#     net_loss = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "#     net_opt = nn.Adam(network.trainable_params(), cfg.lr)\n",
    "#     conv_params = list(filter(lambda x: 'conv' in x.name, network.trainable_params()))\n",
    "#     no_conv_params = list(filter(lambda x: 'conv' not in x.name, network.trainable_params()))\n",
    "#     group_params = [{'params': conv_params, 'weight_decay': 0.01, 'grad_centralization':True},\n",
    "#                     {'params': no_conv_params},\n",
    "#                     {'order_params': network.trainable_params()}]\n",
    "#     optim = nn.FTRL(group_params, learning_rate=0.1, weight_decay=0.0)\n",
    "#     # 训练模型\n",
    "#     model = Model(network, loss_fn=net_loss, optimizer=optim, metrics={'acc': Accuracy()})\n",
    "#     loss_cb = LossMonitor()\n",
    "#     print(\"============== Starting Training ==============\")\n",
    "#     model.train(cfg.epoch_size, ds_train, callbacks=[loss_cb], dataset_sink_mode=True)\n",
    "#     # 验证\n",
    "#     metric = model.eval(ds_test)\n",
    "#     print(metric)\n",
    "#     return model\n",
    "\n",
    "# model_FTRL = train_FTRL(ForwardFashion)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, loss_fn):\n",
    "    ds_train, ds_test = create_dataset()\n",
    "    # 定义模型的损失函数，优化器    \n",
    "    net_opt = nn.Adam(network.trainable_params(), cfg.lr)\n",
    "    # 训练模型\n",
    "    model = Model(network, loss_fn=loss_fn, optimizer=net_opt, metrics={'test_acc': Accuracy(), 'train_acc': Accuracy(), 'test_loss': Loss(),  'train_loss': Loss()})\n",
    "    loss_cb = EvalCallBack(model=model, train_dataset=ds_train, test_dataset=ds_test)\n",
    "    print(\"============== Starting Training ==============\")\n",
    "    model.train(cfg.epoch_size, ds_train, callbacks=[loss_cb], dataset_sink_mode=True)\n",
    "    print(loss_cb.per_eval)\n",
    "    metricDic = loss_cb.per_eval\n",
    "    return model, metricDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveMetric(path, metric):\n",
    "    with open(path, encoding=\"utf8\", mode=\"w\") as f:\n",
    "        f.write(str(metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(path, model):\n",
    "    mindspore.save_checkpoint(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def drawAndSaveFig(path, metricList, title):\n",
    "    label = [\"train_acc\", \"test_acc\", \"train_loss\", \"test_loss\"]\n",
    "    plt.plot(metricList[label[0]], metricList[label[1]])\n",
    "    plt.legend(label[:2])\n",
    "    plt.title(title + \"_acc\")\n",
    "    plt.show()\n",
    "    plt.savefig(path+\"_acc\")\n",
    "    plt.plot(metricList[label[2]], metricList[label[3]])\n",
    "    plt.legend(label[2:])\n",
    "    plt.title(title + \"_loss\")\n",
    "    plt.show()\n",
    "    plt.savefig(path+\"_loss\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaseLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(32400:23808,MainProcess):2023-05-18-21:50:49.730.00 [mindspore\\train\\model.py:1094] For EvalCallBack callback, {'epoch_end'} methods may not be supported in later version, Use methods prefixed with 'on_train' or 'on_eval' instead when using customized callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Training ==============\n",
      "Epoch1: train_acc: 0.8442674946581197, test_acc: 0.8347355769230769, train_loss: 0.4406767497714768, test_loss0.4667505866441971\n",
      "Epoch2: train_acc: 0.8802250267094017, test_acc: 0.8673878205128205, train_loss: 0.3334465340161935, test_loss0.36994184591831303\n",
      "Epoch3: train_acc: 0.9018596420940171, test_acc: 0.8862179487179487, train_loss: 0.26995841369160223, test_loss0.31915530753441346\n",
      "Epoch4: train_acc: 0.904296875, test_acc: 0.8858173076923077, train_loss: 0.26382560378465897, test_loss0.3162946907373575\n",
      "Epoch5: train_acc: 0.9163494925213675, test_acc: 0.8939302884615384, train_loss: 0.22728929254743788, test_loss0.2983479110094217\n",
      "Epoch6: train_acc: 0.9305722489316239, test_acc: 0.9017427884615384, train_loss: 0.18974674289297855, test_loss0.28005740428582215\n",
      "Epoch7: train_acc: 0.9398704594017094, test_acc: 0.9067508012820513, train_loss: 0.16848084690351772, test_loss0.26954165177467543\n",
      "Epoch8: train_acc: 0.9446280715811965, test_acc: 0.9068509615384616, train_loss: 0.15305726443473092, test_loss0.27349554804655224\n",
      "Epoch9: train_acc: 0.9435596955128205, test_acc: 0.9020432692307693, train_loss: 0.14651896791835117, test_loss0.30002001501046693\n",
      "Epoch10: train_acc: 0.955879407051282, test_acc: 0.9067508012820513, train_loss: 0.11875486513997754, test_loss0.2982560212795551\n",
      "{'epoch': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'test_acc': [0.8347355769230769, 0.8673878205128205, 0.8862179487179487, 0.8858173076923077, 0.8939302884615384, 0.9017427884615384, 0.9067508012820513, 0.9068509615384616, 0.9020432692307693, 0.9067508012820513], 'train_acc': [0.8442674946581197, 0.8802250267094017, 0.9018596420940171, 0.904296875, 0.9163494925213675, 0.9305722489316239, 0.9398704594017094, 0.9446280715811965, 0.9435596955128205, 0.955879407051282], 'test_loss': [0.8442674946581197, 0.8802250267094017, 0.9018596420940171, 0.904296875, 0.9163494925213675, 0.9305722489316239, 0.9398704594017094, 0.9446280715811965, 0.9435596955128205, 0.955879407051282], 'train_loss': [0.8347355769230769, 0.8673878205128205, 0.8862179487179487, 0.8858173076923077, 0.8939302884615384, 0.9017427884615384, 0.9067508012820513, 0.9068509615384616, 0.9020432692307693, 0.9067508012820513]}\n"
     ]
    }
   ],
   "source": [
    "# Baseline\n",
    "network = ForwardFashion_baseline(cfg.num_classes)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model, metricDic = train(network, loss_fn)\n",
    "saveMetric(\"./metric/baseline_metric.txt\", metricDic)\n",
    "saveModel(\"./model/baseline_model.ckpt\", network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawAndSaveFig(\"./img/metric_baseLine\", metricDic, \"BaseLine\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(15008:31020,MainProcess):2023-05-18-11:47:11.686.819 [mindspore\\train\\model.py:1094] For EvalCallBack callback, {'epoch_end'} methods may not be supported in later version, Use methods prefixed with 'on_train' or 'on_eval' instead when using customized callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Training ==============\n",
      "Epoch1: train_acc: 0.10011017628205128, test_acc: 0.0999599358974359, train_loss: 2.329673836373875, test_loss2.329674243927002\n",
      "Epoch2: train_acc: 0.09990985576923077, test_acc: 0.0999599358974359, train_loss: 2.329407216137291, test_loss2.3294081626794276\n",
      "Epoch3: train_acc: 0.09999332264957266, test_acc: 0.10006009615384616, train_loss: 2.3296092055801654, test_loss2.3296094979995337\n",
      "Epoch4: train_acc: 0.10001001602564102, test_acc: 0.10006009615384616, train_loss: 2.3294762780523706, test_loss2.3294756901569857\n",
      "Epoch5: train_acc: 0.10002670940170941, test_acc: 0.10016025641025642, train_loss: 2.330023269368033, test_loss2.330022096633911\n",
      "Epoch6: train_acc: 0.10001001602564102, test_acc: 0.09975961538461539, train_loss: 2.3295277937864647, test_loss2.329527885485918\n",
      "Epoch7: train_acc: 0.10007678952991453, test_acc: 0.0999599358974359, train_loss: 2.330149208378588, test_loss2.330150005144951\n",
      "Epoch8: train_acc: 0.09992654914529915, test_acc: 0.0999599358974359, train_loss: 2.329045349716121, test_loss2.3290428198300877\n",
      "Epoch9: train_acc: 0.10001001602564102, test_acc: 0.09975961538461539, train_loss: 2.3298839126896653, test_loss2.3298870355654984\n",
      "Epoch10: train_acc: 0.09997662927350427, test_acc: 0.09985977564102565, train_loss: 2.3295467918754644, test_loss2.3295477414742494\n",
      "{'epoch': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'test_acc': [0.0999599358974359, 0.0999599358974359, 0.10006009615384616, 0.10006009615384616, 0.10016025641025642, 0.09975961538461539, 0.0999599358974359, 0.0999599358974359, 0.09975961538461539, 0.09985977564102565], 'train_acc': [0.10011017628205128, 0.09990985576923077, 0.09999332264957266, 0.10001001602564102, 0.10002670940170941, 0.10001001602564102, 0.10007678952991453, 0.09992654914529915, 0.10001001602564102, 0.09997662927350427], 'test_loss': [0.10011017628205128, 0.09990985576923077, 0.09999332264957266, 0.10001001602564102, 0.10002670940170941, 0.10001001602564102, 0.10007678952991453, 0.09992654914529915, 0.10001001602564102, 0.09997662927350427], 'train_loss': [0.0999599358974359, 0.0999599358974359, 0.10006009615384616, 0.10006009615384616, 0.10016025641025642, 0.09975961538461539, 0.0999599358974359, 0.0999599358974359, 0.09975961538461539, 0.09985977564102565]}\n"
     ]
    }
   ],
   "source": [
    "# L1\n",
    "network_L1 = ForwardFashion_baseline(cfg.num_classes)\n",
    "loss_fn_L1 = L1CrossEntropyLoss(network_L1.trainable_params(), l1_weight=1e-8)\n",
    "model_L1, metricDic_L1 = train(network_L1, loss_fn_L1)\n",
    "saveMetric(\"./metric/baseline_metric_L1.txt\", metricDic_L1)\n",
    "saveModel(\"./model/baseline_model_L1.ckpt\", network_L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawAndSaveFig(\"./img/metric_L1\", metricDic_L1, \"metric_L1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(15008:31020,MainProcess):2023-05-18-12:08:37.391.762 [mindspore\\train\\model.py:1094] For EvalCallBack callback, {'epoch_end'} methods may not be supported in later version, Use methods prefixed with 'on_train' or 'on_eval' instead when using customized callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Training ==============\n",
      "Epoch1: train_acc: 0.10001001602564102, test_acc: 0.0999599358974359, train_loss: 2.302834337593144, test_loss2.3028344985766287\n",
      "Epoch2: train_acc: 0.10002670940170941, test_acc: 0.0999599358974359, train_loss: 2.3028210462668004, test_loss2.30282090871762\n",
      "Epoch3: train_acc: 0.10001001602564102, test_acc: 0.09985977564102565, train_loss: 2.3028012544680863, test_loss2.30280134616754\n",
      "Epoch4: train_acc: 0.10004340277777778, test_acc: 0.0999599358974359, train_loss: 2.302768865202227, test_loss2.3027687684083595\n",
      "Epoch5: train_acc: 0.10002670940170941, test_acc: 0.10016025641025642, train_loss: 2.30273668276958, test_loss2.3027367775256815\n",
      "Epoch6: train_acc: 0.10006009615384616, test_acc: 0.0999599358974359, train_loss: 2.3027141787048078, test_loss2.3027144701052933\n",
      "Epoch7: train_acc: 0.10006009615384616, test_acc: 0.09985977564102565, train_loss: 2.302696520446712, test_loss2.302696478672517\n",
      "Epoch8: train_acc: 0.09994324252136752, test_acc: 0.09985977564102565, train_loss: 2.3026742700837617, test_loss2.302674379104223\n",
      "Epoch9: train_acc: 0.09997662927350427, test_acc: 0.0999599358974359, train_loss: 2.3026695760906253, test_loss2.3026698369246263\n",
      "Epoch10: train_acc: 0.10004340277777778, test_acc: 0.09985977564102565, train_loss: 2.30265859559051, test_loss2.302659150881645\n",
      "{'epoch': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'test_acc': [0.0999599358974359, 0.0999599358974359, 0.09985977564102565, 0.0999599358974359, 0.10016025641025642, 0.0999599358974359, 0.09985977564102565, 0.09985977564102565, 0.0999599358974359, 0.09985977564102565], 'train_acc': [0.10001001602564102, 0.10002670940170941, 0.10001001602564102, 0.10004340277777778, 0.10002670940170941, 0.10006009615384616, 0.10006009615384616, 0.09994324252136752, 0.09997662927350427, 0.10004340277777778], 'test_loss': [0.10001001602564102, 0.10002670940170941, 0.10001001602564102, 0.10004340277777778, 0.10002670940170941, 0.10006009615384616, 0.10006009615384616, 0.09994324252136752, 0.09997662927350427, 0.10004340277777778], 'train_loss': [0.0999599358974359, 0.0999599358974359, 0.09985977564102565, 0.0999599358974359, 0.10016025641025642, 0.0999599358974359, 0.09985977564102565, 0.09985977564102565, 0.0999599358974359, 0.09985977564102565]}\n"
     ]
    }
   ],
   "source": [
    "# L2\n",
    "network_L2 = ForwardFashion_baseline(cfg.num_classes)\n",
    "loss_fn_L2 = L2CrossEntropyLoss(network_L2.trainable_params(), l2_weight=1e-8)\n",
    "model_L2, metricDic_L2 = train(network_L2, loss_fn_L2)\n",
    "saveMetric(\"./metric/baseline_metric_L2.txt\", metricDic_L2)\n",
    "saveModel(\"./model/baseline_model_L2.ckpt\", network_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawAndSaveFig(\"./img/metric_L2\", metricDic_L2, \"metric_L2\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(32400:23808,MainProcess):2023-05-18-22:16:26.961.054 [mindspore\\train\\model.py:1094] For EvalCallBack callback, {'epoch_end'} methods may not be supported in later version, Use methods prefixed with 'on_train' or 'on_eval' instead when using customized callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Training ==============\n",
      "Epoch1: train_acc: 0.8827457264957265, test_acc: 0.871895032051282, train_loss: 0.33672214980818266, test_loss0.36438882121673\n",
      "Epoch2: train_acc: 0.9123263888888888, test_acc: 0.8951322115384616, train_loss: 0.2456147018660847, test_loss0.2869034829812172\n",
      "Epoch3: train_acc: 0.9289696848290598, test_acc: 0.9040464743589743, train_loss: 0.19909430145580545, test_loss0.2666639555723239\n",
      "Epoch4: train_acc: 0.9357805822649573, test_acc: 0.9066506410256411, train_loss: 0.1738591754856782, test_loss0.26687966248927975\n",
      "Epoch5: train_acc: 0.9524906517094017, test_acc: 0.9177684294871795, train_loss: 0.13457948504350123, test_loss0.23046769927709532\n",
      "Epoch6: train_acc: 0.9587339743589743, test_acc: 0.9185697115384616, train_loss: 0.11547611351323943, test_loss0.2342818814974565\n",
      "Epoch7: train_acc: 0.9581330128205128, test_acc: 0.9131610576923077, train_loss: 0.11155248653048123, test_loss0.2760899475751779\n",
      "Epoch8: train_acc: 0.9693676549145299, test_acc: 0.9139623397435898, train_loss: 0.08625711284132086, test_loss0.26422973626699203\n",
      "Epoch9: train_acc: 0.9809528579059829, test_acc: 0.918770032051282, train_loss: 0.0585220850383242, test_loss0.2648817831889177\n",
      "Epoch10: train_acc: 0.9761117788461539, test_acc: 0.9119591346153846, train_loss: 0.06873421114670415, test_loss0.28761958808470994\n",
      "{'epoch': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'test_acc': [0.871895032051282, 0.8951322115384616, 0.9040464743589743, 0.9066506410256411, 0.9177684294871795, 0.9185697115384616, 0.9131610576923077, 0.9139623397435898, 0.918770032051282, 0.9119591346153846], 'train_acc': [0.8827457264957265, 0.9123263888888888, 0.9289696848290598, 0.9357805822649573, 0.9524906517094017, 0.9587339743589743, 0.9581330128205128, 0.9693676549145299, 0.9809528579059829, 0.9761117788461539], 'test_loss': [0.8827457264957265, 0.9123263888888888, 0.9289696848290598, 0.9357805822649573, 0.9524906517094017, 0.9587339743589743, 0.9581330128205128, 0.9693676549145299, 0.9809528579059829, 0.9761117788461539], 'train_loss': [0.871895032051282, 0.8951322115384616, 0.9040464743589743, 0.9066506410256411, 0.9177684294871795, 0.9185697115384616, 0.9131610576923077, 0.9139623397435898, 0.918770032051282, 0.9119591346153846]}\n"
     ]
    }
   ],
   "source": [
    "# BN\n",
    "network_BN = ForwardFashionWithBatchNorm(cfg.num_classes)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model_BN, metricDic_BN = train(network_BN, loss_fn)\n",
    "saveMetric(\"./metric/baseline_metric_BN.txt\", metricDic_BN)\n",
    "saveModel(\"./model/baseline_model_BN.ckpt\", network_BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawAndSaveFig(\"./img/metric_BN\", metricDic_BN, \"metric_BN\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(32400:23808,MainProcess):2023-05-18-21:34:54.231.076 [mindspore\\nn\\layer\\basic.py:167] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(32400:23808,MainProcess):2023-05-18-21:34:54.260.059 [mindspore\\train\\model.py:1094] For EvalCallBack callback, {'epoch_end'} methods may not be supported in later version, Use methods prefixed with 'on_train' or 'on_eval' instead when using customized callbacks.\n",
      "[WARNING] ME(32400:23808,MainProcess):2023-05-18-21:34:54.284.055 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(32400:23808,MainProcess):2023-05-18-21:34:54.287.091 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(32400:23808,MainProcess):2023-05-18-21:34:54.295.082 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(32400:23808,MainProcess):2023-05-18-21:34:54.298.061 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(32400:23808,MainProcess):2023-05-18-21:34:54.324.620 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(32400:23808,MainProcess):2023-05-18-21:34:54.361.125 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(32400:23808,MainProcess):2023-05-18-21:34:54.374.125 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Training ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(32400:23808,MainProcess):2023-05-18-21:35:53.777.552 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(32400:23808,MainProcess):2023-05-18-21:35:53.787.552 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(32400:23808,MainProcess):2023-05-18-21:35:53.797.551 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(32400:23808,MainProcess):2023-05-18-21:35:53.810.551 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(32400:23808,MainProcess):2023-05-18-21:35:53.825.552 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1: train_acc: 0.7931189903846154, test_acc: 0.7848557692307693, train_loss: 0.54593772893278, test_loss0.5659783062262412\n",
      "Epoch2: train_acc: 0.8498263888888888, test_acc: 0.8421474358974359, train_loss: 0.4171484413309994, test_loss0.43928849620696825\n",
      "Epoch3: train_acc: 0.8600594284188035, test_acc: 0.8521634615384616, train_loss: 0.37497706240058964, test_loss0.40661043845690215\n",
      "Epoch4: train_acc: 0.8767194177350427, test_acc: 0.8665865384615384, train_loss: 0.33633567774907136, test_loss0.366913521136993\n",
      "Epoch5: train_acc: 0.8857672275641025, test_acc: 0.8745993589743589, train_loss: 0.31538262568477893, test_loss0.35130395682958454\n",
      "Epoch6: train_acc: 0.8958500267094017, test_acc: 0.8838141025641025, train_loss: 0.28740435106377316, test_loss0.32320695160291135\n",
      "Epoch7: train_acc: 0.898170405982906, test_acc: 0.8866185897435898, train_loss: 0.27517512771818375, test_loss0.31621793676645327\n",
      "Epoch8: train_acc: 0.9057992788461539, test_acc: 0.8938301282051282, train_loss: 0.2568966701117336, test_loss0.30033488533435726\n",
      "Epoch9: train_acc: 0.9062666933760684, test_acc: 0.8908253205128205, train_loss: 0.25166807470158636, test_loss0.2998172709575066\n",
      "Epoch10: train_acc: 0.9175180288461539, test_acc: 0.90234375, train_loss: 0.22707083359615415, test_loss0.274438827083661\n",
      "{'epoch': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'test_acc': [0.7848557692307693, 0.8421474358974359, 0.8521634615384616, 0.8665865384615384, 0.8745993589743589, 0.8838141025641025, 0.8866185897435898, 0.8938301282051282, 0.8908253205128205, 0.90234375], 'train_acc': [0.7931189903846154, 0.8498263888888888, 0.8600594284188035, 0.8767194177350427, 0.8857672275641025, 0.8958500267094017, 0.898170405982906, 0.9057992788461539, 0.9062666933760684, 0.9175180288461539], 'test_loss': [0.7931189903846154, 0.8498263888888888, 0.8600594284188035, 0.8767194177350427, 0.8857672275641025, 0.8958500267094017, 0.898170405982906, 0.9057992788461539, 0.9062666933760684, 0.9175180288461539], 'train_loss': [0.7848557692307693, 0.8421474358974359, 0.8521634615384616, 0.8665865384615384, 0.8745993589743589, 0.8838141025641025, 0.8866185897435898, 0.8938301282051282, 0.8908253205128205, 0.90234375]}\n"
     ]
    }
   ],
   "source": [
    "# Dropout\n",
    "network_Drop = ForwardFashionWithDropout(cfg.num_classes)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model_Drop, metricDic_Drop = train(network_Drop, loss_fn)\n",
    "saveMetric(\"./metric/baseline_metric_Drop.txt\", metricDic_Drop)\n",
    "saveModel(\"./model/baseline_model_Drop.ckpt\", network_Drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawAndSaveFig(\"./img/metric_Dropout\", metricDic_Drop, \"metric_Dropout\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BN + Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(15008:31020,MainProcess):2023-05-18-12:52:04.480.431 [mindspore\\nn\\layer\\basic.py:167] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(15008:31020,MainProcess):2023-05-18-12:52:04.506.448 [mindspore\\train\\model.py:1094] For EvalCallBack callback, {'epoch_end'} methods may not be supported in later version, Use methods prefixed with 'on_train' or 'on_eval' instead when using customized callbacks.\n",
      "[WARNING] ME(15008:31020,MainProcess):2023-05-18-12:52:04.527.122 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(15008:31020,MainProcess):2023-05-18-12:52:04.531.122 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(15008:31020,MainProcess):2023-05-18-12:52:04.544.141 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(15008:31020,MainProcess):2023-05-18-12:52:04.546.121 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(15008:31020,MainProcess):2023-05-18-12:52:04.571.660 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(15008:31020,MainProcess):2023-05-18-12:52:04.605.286 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(15008:31020,MainProcess):2023-05-18-12:52:04.618.285 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Training ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(15008:31020,MainProcess):2023-05-18-12:53:05.397.585 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(15008:31020,MainProcess):2023-05-18-12:53:05.406.588 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(15008:31020,MainProcess):2023-05-18-12:53:05.416.537 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(15008:31020,MainProcess):2023-05-18-12:53:05.435.389 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(15008:31020,MainProcess):2023-05-18-12:53:05.451.392 [mindspore\\nn\\layer\\basic.py:193] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1: train_acc: 0.8502604166666666, test_acc: 0.8399439102564102, train_loss: 0.42102854832624775, test_loss0.44137566364728487\n",
      "Epoch2: train_acc: 0.8923944978632479, test_acc: 0.8790064102564102, train_loss: 0.30164321047118586, test_loss0.33175548376181185\n",
      "Epoch3: train_acc: 0.9035957532051282, test_acc: 0.8917267628205128, train_loss: 0.2649496451147601, test_loss0.2983079560292073\n",
      "Epoch4: train_acc: 0.9114583333333334, test_acc: 0.8991386217948718, train_loss: 0.2426122664513751, test_loss0.27862640489370394\n",
      "Epoch5: train_acc: 0.9162326388888888, test_acc: 0.9037459935897436, train_loss: 0.22818779028379, test_loss0.2667615165313085\n",
      "Epoch6: train_acc: 0.9235944177350427, test_acc: 0.9098557692307693, train_loss: 0.2121520025225786, test_loss0.2518660135758229\n",
      "Epoch7: train_acc: 0.9239950587606838, test_acc: 0.9098557692307693, train_loss: 0.20592143128697687, test_loss0.24961869495037275\n",
      "Epoch8: train_acc: 0.9273838141025641, test_acc: 0.9138621794871795, train_loss: 0.19941327068158704, test_loss0.2390047292678784\n",
      "Epoch9: train_acc: 0.9290531517094017, test_acc: 0.9114583333333334, train_loss: 0.19436225906396523, test_loss0.2397110408697373\n",
      "Epoch10: train_acc: 0.927200186965812, test_acc: 0.91015625, train_loss: 0.19919845843926454, test_loss0.24391536567455682\n",
      "{'epoch': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'test_acc': [0.8399439102564102, 0.8790064102564102, 0.8917267628205128, 0.8991386217948718, 0.9037459935897436, 0.9098557692307693, 0.9098557692307693, 0.9138621794871795, 0.9114583333333334, 0.91015625], 'train_acc': [0.8502604166666666, 0.8923944978632479, 0.9035957532051282, 0.9114583333333334, 0.9162326388888888, 0.9235944177350427, 0.9239950587606838, 0.9273838141025641, 0.9290531517094017, 0.927200186965812], 'test_loss': [0.8502604166666666, 0.8923944978632479, 0.9035957532051282, 0.9114583333333334, 0.9162326388888888, 0.9235944177350427, 0.9239950587606838, 0.9273838141025641, 0.9290531517094017, 0.927200186965812], 'train_loss': [0.8399439102564102, 0.8790064102564102, 0.8917267628205128, 0.8991386217948718, 0.9037459935897436, 0.9098557692307693, 0.9098557692307693, 0.9138621794871795, 0.9114583333333334, 0.91015625]}\n"
     ]
    }
   ],
   "source": [
    "# Dropout + BN\n",
    "network_Drop_BN = ForwardFashionWithBatchNormAndDropout(cfg.num_classes)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model_Drop_BN, metricDic_Drop_BN = train(network_Drop_BN, loss_fn)\n",
    "saveMetric(\"./metric/baseline_metric_Drop_BN.txt\", metricDic_Drop_BN)\n",
    "saveModel(\"./model/baseline_model_Drop_BN.ckpt\", network_Drop_BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawAndSaveFig(\"./img/metric_Dropout_BN\", metricDic_Drop_BN, \"metric_Dropout_BN\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(32400:23808,MainProcess):2023-05-19-00:26:24.625.611 [mindspore\\train\\model.py:1094] For EvalCallBackWithEarlyStop callback, {'epoch_end'} methods may not be supported in later version, Use methods prefixed with 'on_train' or 'on_eval' instead when using customized callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Training ==============\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 64\u001b[0m\n\u001b[0;32m     62\u001b[0m network_earlyStop \u001b[39m=\u001b[39m ForwardFashion_baseline(cfg\u001b[39m.\u001b[39mnum_classes)\n\u001b[0;32m     63\u001b[0m loss_fn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m---> 64\u001b[0m model_earlyStop, metricDic_earlyStop \u001b[39m=\u001b[39m train_earlyStop(network_earlyStop, loss_fn)\n\u001b[0;32m     65\u001b[0m saveMetric(\u001b[39m\"\u001b[39m\u001b[39m./metric/baseline_metric_EarlyStop.txt\u001b[39m\u001b[39m\"\u001b[39m, metricDic_earlyStop)\n\u001b[0;32m     66\u001b[0m saveModel(\u001b[39m\"\u001b[39m\u001b[39m./model/baseline_model_EarlyStop.ckpt\u001b[39m\u001b[39m\"\u001b[39m, network_earlyStop)\n",
      "Cell \u001b[1;32mIn[35], line 56\u001b[0m, in \u001b[0;36mtrain_earlyStop\u001b[1;34m(network, loss_fn)\u001b[0m\n\u001b[0;32m     54\u001b[0m loss_cb \u001b[39m=\u001b[39m EvalCallBackWithEarlyStop(model\u001b[39m=\u001b[39mmodel, train_dataset\u001b[39m=\u001b[39mds_train, test_dataset\u001b[39m=\u001b[39mds_test, acc_delta_limit \u001b[39m=\u001b[39m \u001b[39m0.005\u001b[39m, patience \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m============== Starting Training ==============\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m model\u001b[39m.\u001b[39;49mtrain(cfg\u001b[39m.\u001b[39;49mepoch_size, ds_train, callbacks\u001b[39m=\u001b[39;49m[loss_cb], dataset_sink_mode\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     57\u001b[0m \u001b[39mprint\u001b[39m(loss_cb\u001b[39m.\u001b[39mper_eval)\n\u001b[0;32m     58\u001b[0m metricDic \u001b[39m=\u001b[39m loss_cb\u001b[39m.\u001b[39mper_eval\n",
      "File \u001b[1;32mc:\\Users\\15781\\anaconda3\\envs\\mindspore_py38\\lib\\site-packages\\mindspore\\train\\model.py:1056\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, epoch, train_dataset, callbacks, dataset_sink_mode, sink_size, initial_epoch)\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[39mif\u001b[39;00m callbacks:\n\u001b[0;32m   1054\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_methods_for_custom_callbacks(callbacks, \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1056\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(epoch,\n\u001b[0;32m   1057\u001b[0m             train_dataset,\n\u001b[0;32m   1058\u001b[0m             callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1059\u001b[0m             dataset_sink_mode\u001b[39m=\u001b[39;49mdataset_sink_mode,\n\u001b[0;32m   1060\u001b[0m             sink_size\u001b[39m=\u001b[39;49msink_size,\n\u001b[0;32m   1061\u001b[0m             initial_epoch\u001b[39m=\u001b[39;49minitial_epoch)\n\u001b[0;32m   1063\u001b[0m \u001b[39m# When it's distributed training and using MindRT,\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m \u001b[39m# the node id should be reset to start from 0.\u001b[39;00m\n\u001b[0;32m   1065\u001b[0m \u001b[39m# This is to avoid the timeout when finding the actor route tables in 'train' and 'eval' case(or 'fit').\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m \u001b[39mif\u001b[39;00m _enable_distributed_mindrt():\n",
      "File \u001b[1;32mc:\\Users\\15781\\anaconda3\\envs\\mindspore_py38\\lib\\site-packages\\mindspore\\train\\model.py:100\u001b[0m, in \u001b[0;36m_save_final_ckpt.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m     99\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 100\u001b[0m     func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\15781\\anaconda3\\envs\\mindspore_py38\\lib\\site-packages\\mindspore\\train\\model.py:614\u001b[0m, in \u001b[0;36mModel._train\u001b[1;34m(self, epoch, train_dataset, callbacks, dataset_sink_mode, sink_size, initial_epoch, valid_dataset, valid_frequency, valid_dataset_sink_mode)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[39melif\u001b[39;00m context\u001b[39m.\u001b[39mget_context(\u001b[39m\"\u001b[39m\u001b[39mdevice_target\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCPU\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    612\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mThe CPU cannot support dataset sink mode currently.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mSo the training process will be performed with dataset not sink.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 614\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_process(epoch, train_dataset, list_callback, cb_params, initial_epoch, valid_infos)\n\u001b[0;32m    615\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    616\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_dataset_sink_process(epoch, train_dataset, list_callback,\n\u001b[0;32m    617\u001b[0m                                      cb_params, sink_size, initial_epoch, valid_infos)\n",
      "File \u001b[1;32mc:\\Users\\15781\\anaconda3\\envs\\mindspore_py38\\lib\\site-packages\\mindspore\\train\\model.py:941\u001b[0m, in \u001b[0;36mModel._train_process\u001b[1;34m(self, epoch, train_dataset, list_callback, cb_params, initial_epoch, valid_infos)\u001b[0m\n\u001b[0;32m    939\u001b[0m \u001b[39m# Embedding cache server need not do epoch end callback, this process only run one step.\u001b[39;00m\n\u001b[0;32m    940\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_embedding_cache_server:\n\u001b[1;32m--> 941\u001b[0m     list_callback\u001b[39m.\u001b[39;49mon_train_epoch_end(run_context)\n\u001b[0;32m    942\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmetrics\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m cb_params \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39meval_results\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m cb_params:\n\u001b[0;32m    943\u001b[0m     cb_params\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mmetrics\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\15781\\anaconda3\\envs\\mindspore_py38\\lib\\site-packages\\mindspore\\train\\callback\\_callback.py:371\u001b[0m, in \u001b[0;36mCallbackManager.on_train_epoch_end\u001b[1;34m(self, run_context)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Called after each train epoch finished.\"\"\"\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callbacks:\n\u001b[1;32m--> 371\u001b[0m     cb\u001b[39m.\u001b[39;49mon_train_epoch_end(run_context)\n",
      "File \u001b[1;32mc:\\Users\\15781\\anaconda3\\envs\\mindspore_py38\\lib\\site-packages\\mindspore\\train\\callback\\_callback.py:205\u001b[0m, in \u001b[0;36mCallback.on_train_epoch_end\u001b[1;34m(self, run_context)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_epoch_end\u001b[39m(\u001b[39mself\u001b[39m, run_context):\n\u001b[0;32m    199\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[39m    Called after each training epoch end.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[39m        run_context (RunContext): Include some information of the model.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 205\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_end(run_context)\n",
      "Cell \u001b[1;32mIn[35], line 24\u001b[0m, in \u001b[0;36mEvalCallBackWithEarlyStop.epoch_end\u001b[1;34m(self, run_context)\u001b[0m\n\u001b[0;32m     22\u001b[0m train_acc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataset, dataset_sink_mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_sink_mode)[\u001b[39m\"\u001b[39m\u001b[39mtrain_acc\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     23\u001b[0m test_acc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_dataset, dataset_sink_mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_sink_mode)[\u001b[39m\"\u001b[39m\u001b[39mtest_acc\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m---> 24\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49meval(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_dataset, dataset_sink_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_sink_mode)[\u001b[39m\"\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     25\u001b[0m test_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_dataset, dataset_sink_mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_sink_mode)[\u001b[39m\"\u001b[39m\u001b[39mtest_loss\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mper_eval[\u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(cur_epoch)\n",
      "File \u001b[1;32mc:\\Users\\15781\\anaconda3\\envs\\mindspore_py38\\lib\\site-packages\\mindspore\\train\\model.py:1457\u001b[0m, in \u001b[0;36mModel.eval\u001b[1;34m(self, valid_dataset, callbacks, dataset_sink_mode)\u001b[0m\n\u001b[0;32m   1455\u001b[0m         eval_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_dataset_sink_process(valid_dataset, list_callback, cb_params)\n\u001b[0;32m   1456\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m         eval_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_eval_process(valid_dataset, list_callback, cb_params)\n\u001b[0;32m   1459\u001b[0m \u001b[39m# When it's distributed training and using MindRT,\u001b[39;00m\n\u001b[0;32m   1460\u001b[0m \u001b[39m# the node id should be reset to start from 0.\u001b[39;00m\n\u001b[0;32m   1461\u001b[0m \u001b[39m# This is to avoid the timeout when finding the actor route tables in 'train' and 'eval' case(or 'fit').\u001b[39;00m\n\u001b[0;32m   1462\u001b[0m \u001b[39mif\u001b[39;00m _enable_distributed_mindrt():\n",
      "File \u001b[1;32mc:\\Users\\15781\\anaconda3\\envs\\mindspore_py38\\lib\\site-packages\\mindspore\\train\\model.py:1359\u001b[0m, in \u001b[0;36mModel._eval_process\u001b[1;34m(self, valid_dataset, list_callback, cb_params, add_eval_loss)\u001b[0m\n\u001b[0;32m   1357\u001b[0m list_callback\u001b[39m.\u001b[39mon_eval_step_begin(run_context)\n\u001b[0;32m   1358\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_network_mode(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_network, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1359\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_eval_network(\u001b[39m*\u001b[39;49mnext_element)\n\u001b[0;32m   1360\u001b[0m cb_params\u001b[39m.\u001b[39mnet_outputs \u001b[39m=\u001b[39m outputs\n\u001b[0;32m   1361\u001b[0m list_callback\u001b[39m.\u001b[39mon_eval_step_end(run_context)\n",
      "File \u001b[1;32mc:\\Users\\15781\\anaconda3\\envs\\mindspore_py38\\lib\\site-packages\\mindspore\\nn\\cell.py:636\u001b[0m, in \u001b[0;36mCell.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_fn_registered():\n\u001b[0;32m    634\u001b[0m         logger\u001b[39m.\u001b[39mwarning(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFor \u001b[39m\u001b[39m'\u001b[39m\u001b[39mCell\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, it\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms not support hook function in graph mode. If you want to use hook \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    635\u001b[0m                        \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfunction, please use context.set_context to set pynative mode.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 636\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompile_and_run(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    637\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n\u001b[0;32m    639\u001b[0m \u001b[39m# Run in PyNative mode.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\15781\\anaconda3\\envs\\mindspore_py38\\lib\\site-packages\\mindspore\\nn\\cell.py:960\u001b[0m, in \u001b[0;36mCell.compile_and_run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompile(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    959\u001b[0m new_args \u001b[39m=\u001b[39m _get_args_for_run(\u001b[39mself\u001b[39m, args, kwargs)\n\u001b[1;32m--> 960\u001b[0m \u001b[39mreturn\u001b[39;00m _cell_graph_executor(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49mnew_args, phase\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mphase)\n",
      "File \u001b[1;32mc:\\Users\\15781\\anaconda3\\envs\\mindspore_py38\\lib\\site-packages\\mindspore\\common\\api.py:1435\u001b[0m, in \u001b[0;36m_CellGraphExecutor.__call__\u001b[1;34m(self, obj, phase, *args)\u001b[0m\n\u001b[0;32m   1433\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mget_context(\u001b[39m\"\u001b[39m\u001b[39mprecompile_only\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m _is_role_sched():\n\u001b[0;32m   1434\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1435\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(obj, \u001b[39m*\u001b[39;49margs, phase\u001b[39m=\u001b[39;49mphase)\n",
      "File \u001b[1;32mc:\\Users\\15781\\anaconda3\\envs\\mindspore_py38\\lib\\site-packages\\mindspore\\common\\api.py:1474\u001b[0m, in \u001b[0;36m_CellGraphExecutor.run\u001b[1;34m(self, obj, phase, *args)\u001b[0m\n\u001b[0;32m   1472\u001b[0m phase_real \u001b[39m=\u001b[39m phase \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(obj\u001b[39m.\u001b[39mcreate_time) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(obj)) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m obj\u001b[39m.\u001b[39marguments_key\n\u001b[0;32m   1473\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_compiled(phase_real):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exec_pip(obj, \u001b[39m*\u001b[39;49margs, phase\u001b[39m=\u001b[39;49mphase_real)\n\u001b[0;32m   1475\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m graph is not exist.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(phase_real))\n",
      "File \u001b[1;32mc:\\Users\\15781\\anaconda3\\envs\\mindspore_py38\\lib\\site-packages\\mindspore\\common\\api.py:102\u001b[0m, in \u001b[0;36m_wrap_func.<locals>.wrapper\u001b[1;34m(*arg, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39m@wraps\u001b[39m(fn)\n\u001b[0;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39marg, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 102\u001b[0m     results \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49marg, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    103\u001b[0m     \u001b[39mreturn\u001b[39;00m _convert_python_data(results)\n",
      "File \u001b[1;32mc:\\Users\\15781\\anaconda3\\envs\\mindspore_py38\\lib\\site-packages\\mindspore\\common\\api.py:1454\u001b[0m, in \u001b[0;36m_CellGraphExecutor._exec_pip\u001b[1;34m(self, obj, phase, *args)\u001b[0m\n\u001b[0;32m   1452\u001b[0m fn \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mconstruct\n\u001b[0;32m   1453\u001b[0m obj\u001b[39m.\u001b[39m__parse_method__ \u001b[39m=\u001b[39m fn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m-> 1454\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph_executor(args, phase)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from mindspore.train.callback import Callback\n",
    "class EvalCallBackWithEarlyStop(Callback):\n",
    "    def __init__(self, model, train_dataset, test_dataset, dataset_sink_mode = False, epochs_to_eval = 1, acc_delta_limit = 0.01, patience = 0):\n",
    "        self.model = model\n",
    "        self.train_dataset = train_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        # epochs_to_eval是一个int数字，代表着：每隔多少个epoch进行一次验证\n",
    "        self.epochs_to_eval = epochs_to_eval\n",
    "        self.per_eval = {\"epoch\": [], \"test_acc\": [], \"train_acc\": [], \"test_loss\": [], \"train_loss\": []}\n",
    "        self.dataset_sink_mode = dataset_sink_mode\n",
    "        self.accDelta = acc_delta_limit\n",
    "        self.patience = patience\n",
    "        self.failEpoch = 0\n",
    "\n",
    "    def epoch_end(self, run_context):\n",
    "        # 获取到现在的epoch数\n",
    "        cb_param = run_context.original_args()\n",
    "        cur_epoch = cb_param.cur_epoch_num\n",
    "        # 如果达到进行验证的epoch数，则进行以下验证操作\n",
    "        if cur_epoch % self.epochs_to_eval == 0:\n",
    "            # 此处model设定的metrics是准确率Accuracy\n",
    "            train_acc = self.model.eval(self.train_dataset, dataset_sink_mode=self.dataset_sink_mode)[\"train_acc\"]\n",
    "            test_acc = self.model.eval(self.test_dataset, dataset_sink_mode=self.dataset_sink_mode)[\"test_acc\"]\n",
    "            train_loss = self.model.eval(self.train_dataset, dataset_sink_mode=self.dataset_sink_mode)[\"train_loss\"]\n",
    "            test_loss = self.model.eval(self.test_dataset, dataset_sink_mode=self.dataset_sink_mode)[\"test_loss\"]\n",
    "            self.per_eval[\"epoch\"].append(cur_epoch)\n",
    "            self.per_eval[\"test_acc\"].append(test_acc)\n",
    "            self.per_eval[\"train_acc\"].append(train_acc)\n",
    "            self.per_eval[\"train_loss\"].append(test_acc)\n",
    "            self.per_eval[\"test_loss\"].append(train_acc)\n",
    "            print(\"Epoch{}: train_acc: {}, test_acc: {}, train_loss: {}, test_loss{}\".format(cur_epoch, train_acc, test_acc, train_loss, test_loss))\n",
    "            delta = test_acc\n",
    "            if len(self.per_eval[\"test_acc\"]) != 1:\n",
    "                delta -= self.per_eval[\"test_acc\"][-1]\n",
    "            print(delta, self.failEpoch, self. patience)\n",
    "            if delta < self.accDelta:\n",
    "                if self.failEpoch >= self.patience:\n",
    "                    print(\"Stop.\")\n",
    "                    run_context.request_stop()\n",
    "                else:\n",
    "                    self.failEpoch += 1\n",
    "                    print(\"本次更新未达标，相关参数: \", self.failEpoch)\n",
    "            else:\n",
    "                self.failEpoch = 0      # 达标，清空\n",
    "                    \n",
    "                    \n",
    "\n",
    "# early stop\n",
    "cfg.epoch_size = 100\n",
    "def train_earlyStop(network, loss_fn):\n",
    "    ds_train, ds_test = create_dataset()\n",
    "    net_opt = nn.Adam(network.trainable_params(), cfg.lr)\n",
    "    model = Model(network, loss_fn=loss_fn, optimizer=net_opt, metrics={'test_acc': Accuracy(), 'train_acc': Accuracy(), 'test_loss': Loss(),  'train_loss': Loss()})\n",
    "    loss_cb = EvalCallBackWithEarlyStop(model=model, train_dataset=ds_train, test_dataset=ds_test, acc_delta_limit = 0.01, patience = 2)\n",
    "    print(\"============== Starting Training ==============\")\n",
    "    model.train(cfg.epoch_size, ds_train, callbacks=[loss_cb], dataset_sink_mode=True)\n",
    "    print(loss_cb.per_eval)\n",
    "    metricDic = loss_cb.per_eval\n",
    "    return model, metricDic\n",
    "\n",
    "\n",
    "network_earlyStop = ForwardFashion_baseline(cfg.num_classes)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model_earlyStop, metricDic_earlyStop = train_earlyStop(network_earlyStop, loss_fn)\n",
    "saveMetric(\"./metric/baseline_metric_EarlyStop.txt\", metricDic_earlyStop)\n",
    "saveModel(\"./model/baseline_model_EarlyStop.ckpt\", network_earlyStop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘图"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------定义可视化函数--------------------------------\n",
    "# 输入预测结果序列，真实标签序列，以及图片序列\n",
    "# 目标是根据预测值对错，让其标签显示为红色或者蓝色。对：标签为红色；错：标签为蓝色\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "def plot_image(predictions_array, true_label, img):\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    # 显示对应图片\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "    # 显示预测结果的颜色，如果对上了是蓝色，否则为红色\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "    # 显示对应标签的格式，样式\n",
    "    plt.xlabel('{},{:2.0f}% ({})'.format(class_names[predicted_label],\n",
    "                                         100 * np.max(predictions_array),\n",
    "                                         class_names[true_label]), color=color)\n",
    "# 将预测的结果以柱状图形状显示蓝对红错\n",
    "def plot_value_array(predictions_array, true_label):\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    this_plot = plt.bar(range(10), predictions_array, color='#777777')\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    this_plot[predicted_label].set_color('red')\n",
    "    this_plot[true_label].set_color('blue')\n",
    "\n",
    "import numpy as np\n",
    "def softmax_np(x):\n",
    "    x = x - np.max(x)\n",
    "    exp_x = np.exp(x)\n",
    "    softmax_x = exp_x/np.sum(exp_x)\n",
    "    return softmax_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测\n",
    "ds_test, _ = create_dataset()\n",
    "test_ = ds_test.create_dict_iterator(output_numpy=True).__next__()\n",
    "predictions = model_regL2.predict(Tensor(test_['x']))\n",
    "predictions = predictions.asnumpy()\n",
    "for i in range(15):\n",
    "    p_np = predictions[i, :]\n",
    "    p_list = p_np.tolist()\n",
    "    print('第' + str(i) + '个sample预测结果：', p_list.index(max(p_list)), '   真实结果：', test_['y'][i])\n",
    "\n",
    "# 预测15个图像与标签，并展现出来\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows * num_cols\n",
    "plt.figure(figsize=(2 * 2 * num_cols, 2 * num_rows))\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2 * num_cols, 2 * i + 1)\n",
    "    pred_np_ = predictions[i, :]\n",
    "    pred_np_ = softmax_np(pred_np_)\n",
    "    plot_image(pred_np_, test_['y'][i], test_['x'][i, 0, ...])\n",
    "    plt.subplot(num_rows, 2 * num_cols, 2 * i + 2)\n",
    "    plot_value_array(pred_np_, test_['y'][i])\n",
    "plt.show() \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进一步测试：L1和L2选多大的decay才合适？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.epoch_size = 3  # 调小size测试"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1\n",
    "test_accLst_L1 = []\n",
    "for i in range(7,13):\n",
    "    l1_weight = 10 ** (-i)\n",
    "    network_L1 = ForwardFashion_baseline(cfg.num_classes)\n",
    "    loss_fn_L1 = L1CrossEntropyLoss(network_L1.trainable_params(), l1_weight=l1_weight)\n",
    "    model_L1, metricDic_L1 = train(network_L1, loss_fn_L1)\n",
    "    curr_acc = metricDic_L1[\"test_acc\"][-1]\n",
    "    test_accLst_L1.append(curr_acc)\n",
    "    print(i, curr_acc)\n",
    "saveMetric(\"./img/testForL1\", test_accLst_L1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2\n",
    "test_accLst_L2 = []\n",
    "for i in range(10,20):\n",
    "    l2_weight = 10 ** (-i)\n",
    "    network_L2 = ForwardFashion_baseline(cfg.num_classes)\n",
    "    loss_fn_L2 = L2CrossEntropyLoss(network_L2.trainable_params(), l2_weight=l2_weight)\n",
    "    model_L2, metricDic_L2 = train(network_L2, loss_fn_L2)\n",
    "    curr_acc = metricDic_L2[\"test_acc\"][-1]\n",
    "    test_accLst_L2.append(curr_acc)\n",
    "    print(i, curr_acc)\n",
    "saveMetric(\"./img/testForL2\", test_accLst_L2)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mindspore_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
