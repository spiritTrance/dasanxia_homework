# 1.This file shows the parsed IR info when graph evaluating failed to help find the problem.
# 2.You can search the last `------------------------>` to the node which is inferred failed.
# 3.Refer to https://www.mindspore.cn/search?inputValue=analyze_fail.ir to get more instructions.
# ===============================================================================

subgraph attr:
training : 1
subgraph instance: construct.Default.913 : 000002CD5DF4C7D0
# In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:385/    def construct(self, *inputs):/
subgraph @construct.Default.913(%para1_inputs0, %para2_inputs1, %para3_conv1.weight, %para4_conv2.weight, %para5_conv3.weight, %para6_fc1.weight, %para7_fc1.bias, %para8_fc2.weight, %para9_fc2.bias, %para10_moment1.conv1.weight, %para11_moment1.conv2.weight, %para12_moment1.conv3.weight, %para13_moment1.fc1.weight, %para14_moment1.fc1.bias, %para15_moment1.fc2.weight, %para16_moment1.fc2.bias, %para17_moment2.conv1.weight, %para18_moment2.conv2.weight, %para19_moment2.conv3.weight, %para20_moment2.fc1.weight, %para21_moment2.fc1.bias, %para22_moment2.fc2.weight, %para23_moment2.fc2.bias, %para24_beta1_power, %para25_beta2_power, %para26_learning_rate, %para27_global_step) {
  %1([CNode]921) = MakeTuple[is_dynamic_len=Bool(0)](%para1_inputs0, %para2_inputs1)
      : (<Tensor[Float32], (64, 1, 28, 28)>, <Tensor[Int32], (64)>) -> (<Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((64, 1, 28, 28), (64))>)
      #scope: (Default)
      # In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:385/    def construct(self, *inputs):/

#------------------------> 0
  %2(loss) = UnpackCall-unpack_call(call @construct.WithLossCell.917, %1)
      : (<Func, NoShape>, <Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((64, 1, 28, 28), (64))>) -> (<null>)
      #scope: (Default)
      # In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:386/        loss = self.network(*inputs)/
  %3([CNode]922) = getattr(%2, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:387/        sens = F.fill(loss.dtype, loss.shape, self.sens)/
  %4([CNode]923) = getattr(%2, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:387/        sens = F.fill(loss.dtype, loss.shape, self.sens)/
  %5(sens) = call @fill.924(%3, %4, F32(1))
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:387/        sens = F.fill(loss.dtype, loss.shape, self.sens)/
  %6([CNode]925) = S-Prim-MakeTuple[is_dynamic_len=Bool(0)](%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:388/        grads = self.grad(self.network, self.weights)(*inputs, sens)/
  %7(grads) = UnpackGraph(call @construct.WithLossCell.917, %1, %6)
      : (<null>, <Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((64, 1, 28, 28), (64))>, <null>) -> (<null>)
      #scope: (Default)
      # In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:388/        grads = self.grad(self.network, self.weights)(*inputs, sens)/
  %8([CNode]926) = MakeTuple[is_dynamic_len=Bool(0)](%para3_conv1.weight, %para4_conv2.weight, %para5_conv3.weight, %para6_fc1.weight, %para7_fc1.bias, %para8_fc2.weight, %para9_fc2.bias)
      : (<Ref[Tensor[Float32]], (32, 1, 3, 3)>, <Ref[Tensor[Float32]], (64, 32, 3, 3)>, <Ref[Tensor[Float32]], (128, 64, 3, 3)>, <Ref[Tensor[Float32]], (128, 15488)>, <Ref[Tensor[Float32]], (128)>, <Ref[Tensor[Float32]], (10, 128)>, <Ref[Tensor[Float32]], (10)>) -> (<null>)
      #scope: (Default)
      # In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:388/        grads = self.grad(self.network, self.weights)(*inputs, sens)/
  %9(grads) = S-Prim-grad(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:388/        grads = self.grad(self.network, self.weights)(*inputs, sens)/
  %10(grads) = UnpackCall-unpack_call(%9, %1, %6)
      : (<null>, <Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((64, 1, 28, 28), (64))>, <null>) -> (<null>)
      #scope: (Default)
      # In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:388/        grads = self.grad(self.network, self.weights)(*inputs, sens)/
  %11(grads) = S-Prim-identity[side_effect_propagate=I64(1)](%10)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:389/        grads = self.grad_reducer(grads)/
  %12([CNode]928) = call @construct.Adam.927(%11)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:390/        loss = F.depend(loss, self.optimizer(grads))/
  %13(loss) = S-Prim-Depend[side_effect_propagate=I64(1)](%2, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:390/        loss = F.depend(loss, self.optimizer(grads))/
  Return(%13)
      : (<null>)
      #scope: (Default)
      # In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:391/        return loss/
}
# order:
#   1: @construct.Default.913:loss{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.929, [1]: ValueNode<FuncGraph> construct.WithLossCell.917, [2]: [CNode]921}
#   2: @construct.Default.913:[CNode]922{[0]: ValueNode<Primitive> getattr, [1]: loss, [2]: ValueNode<StringImm> dtype}
#   3: @construct.Default.913:[CNode]923{[0]: ValueNode<Primitive> getattr, [1]: loss, [2]: ValueNode<StringImm> shape}
#   4: @construct.Default.913:sens{[0]: ValueNode<FuncGraph> fill.924, [1]: [CNode]922, [2]: [CNode]923, [3]: ValueNode<FP32Imm> 1}
#   5: @construct.Default.913:[CNode]925{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: sens}
#   6: @construct.Default.913:grads{[0]: ValueNode<UnpackGraphPrimitive> UnpackGraph, [1]: ValueNode<FuncGraph> construct.WithLossCell.917, [2]: [CNode]921, [3]: [CNode]925}
#   7: @construct.Default.913:grads{[0]: ValueNode<DoSignaturePrimitive> S-Prim-grad, [1]: grads, [2]: [CNode]926}
#   8: @construct.Default.913:grads{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.930, [1]: grads, [2]: [CNode]921, [3]: [CNode]925}
#   9: @construct.Default.913:grads{[0]: ValueNode<DoSignaturePrimitive> S-Prim-identity, [1]: grads}
#  10: @construct.Default.913:[CNode]928{[0]: ValueNode<FuncGraph> construct.Adam.927, [1]: grads}
#  11: @construct.Default.913:loss{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Depend, [1]: loss, [2]: [CNode]928}
#  12: @construct.Default.913:[CNode]931{[0]: ValueNode<Primitive> Return, [1]: loss}


subgraph attr:
core : 1
subgraph instance: UnpackCall.914 : 000002CD9C2CD380
# In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:386/        loss = self.network(*inputs)/
subgraph @UnpackCall.914(%para28_, %para29_) {
  %1(loss) = TupleGetItem(%para29_916, I64(0))
      : (<Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((64, 1, 28, 28), (64))>, <Int64, NoShape>) -> (<Tensor[Float32], (64, 1, 28, 28)>)
      #scope: (Default)
      # In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:386/        loss = self.network(*inputs)/
  %2(loss) = TupleGetItem(%para29_916, I64(1))
      : (<Tuple[Tensor[Float32],Tensor[Int32]], TupleShape((64, 1, 28, 28), (64))>, <Int64, NoShape>) -> (<Tensor[Int32], (64)>)
      #scope: (Default)
      # In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:386/        loss = self.network(*inputs)/

#------------------------> 1
  %3(loss) = %para28_915(%1, %2)
      : (<Tensor[Float32], (64, 1, 28, 28)>, <Tensor[Int32], (64)>) -> (<null>)
      #scope: (Default)
      # In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:386/        loss = self.network(*inputs)/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:386/        loss = self.network(*inputs)/
}
# order:
#   1: @UnpackCall.914:loss{[0]: 915, [1]: loss, [2]: loss}
#   2: @UnpackCall.914:loss{[0]: ValueNode<Primitive> Return, [1]: loss}


subgraph attr:
training : 1
subgraph instance: construct.WithLossCell.917 : 000002CD8710B4A0
# In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:116/    def construct(self, data, label):/
subgraph @construct.WithLossCell.917 parent: [subgraph @construct.Default.913](%para30_data, %para31_label) {
  %1(out) = call @construct.ForwardFashionWithRegL1.932(%para30_data)
      : (<Tensor[Float32], (64, 1, 28, 28)>) -> (<Tensor[Float32], (64, 10)>)
      #scope: (Default/network-WithLossCell)
      # In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:117/        out = self._backbone(data)/

#------------------------> 2
  %2([CNode]933) = call @construct.L1CrossEntropyLoss.918(%1, %para31_label)
      : (<Tensor[Float32], (64, 10)>, <Tensor[Int32], (64)>) -> (<null>)
      #scope: (Default/network-WithLossCell)
      # In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:118/        return self._loss_fn(out, label)/
  Return(%2)
      : (<null>)
      #scope: (Default/network-WithLossCell)
      # In file c:\Users\15781\anaconda3\envs\mindspore_py38\lib\site-packages\mindspore\nn\wrap\cell_wrapper.py:118/        return self._loss_fn(out, label)/
}
# order:
#   1: @construct.WithLossCell.917:out{[0]: ValueNode<FuncGraph> construct.ForwardFashionWithRegL1.932, [1]: data}
#   2: @construct.WithLossCell.917:[CNode]933{[0]: ValueNode<FuncGraph> construct.L1CrossEntropyLoss.918, [1]: out, [2]: label}
#   3: @construct.WithLossCell.917:[CNode]934{[0]: ValueNode<Primitive> Return, [1]: [CNode]933}


subgraph attr:
training : 1
subgraph instance: construct.L1CrossEntropyLoss.918 : 000002CD7A0C94D0
# In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:47/
subgraph @construct.L1CrossEntropyLoss.918(%para32_pred, %para33_label) {
  %1(ce_loss) = call @construct.CrossEntropyLoss.935(%para32_pred, %para33_label)
      : (<Tensor[Float32], (64, 10)>, <Tensor[Int32], (64)>) -> (<Tensor[Float32], ()>)
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:51/

#------------------------> 3
  %2(params) = call @G-construct.L1CrossEntropyLoss.919()
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:49/
  %3(params) = S-Prim-Concat[axis=I64(0)](%2)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:50/
  %4([CNode]937) = call @construct.L1Regularizer.936(%3)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:52/
  %5([CNode]938) = S-Prim-ReduceSum[keep_dims=Bool(0), skip_mode=Bool(0), input_names=["input_x", "axis"], output_names=["y"]](%4)
      : (<null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:52/
  %6(l1_loss) = S-Prim-mul(F32(0.01), %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:52/
  %7(total_loss) = S-Prim-add(%1, %6)
      : (<Tensor[Float32], ()>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:53/
  Return(%7)
      : (<null>)
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:54/
}
# order:
#   1: @construct.L1CrossEntropyLoss.918:params{[0]: ValueNode<Primitive> PyExecute, [1]: ValueNode<StringImm> __internal_getattr_callable_obj__(), [2]: ValueNode<ValueTuple> (__internal_getattr_callable_obj__), [3]: [CNode]939}
#   2: @construct.L1CrossEntropyLoss.918:params{[0]: ValueNode<FuncGraph> G-construct.L1CrossEntropyLoss.919}
#   3: @construct.L1CrossEntropyLoss.918:params{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Concat, [1]: params}
#   4: @construct.L1CrossEntropyLoss.918:ce_loss{[0]: ValueNode<FuncGraph> construct.CrossEntropyLoss.935, [1]: pred, [2]: label}
#   5: @construct.L1CrossEntropyLoss.918:[CNode]937{[0]: ValueNode<FuncGraph> construct.L1Regularizer.936, [1]: params}
#   6: @construct.L1CrossEntropyLoss.918:[CNode]938{[0]: ValueNode<DoSignaturePrimitive> S-Prim-ReduceSum, [1]: [CNode]937}
#   7: @construct.L1CrossEntropyLoss.918:l1_loss{[0]: ValueNode<DoSignaturePrimitive> S-Prim-mul, [1]: ValueNode<FP32Imm> 0.01, [2]: [CNode]938}
#   8: @construct.L1CrossEntropyLoss.918:total_loss{[0]: ValueNode<DoSignaturePrimitive> S-Prim-add, [1]: ce_loss, [2]: l1_loss}
#   9: @construct.L1CrossEntropyLoss.918:[CNode]940{[0]: ValueNode<Primitive> Return, [1]: total_loss}
#  10: @construct.L1CrossEntropyLoss.918:[CNode]941{[0]: ValueNode<Primitive> PyExecute, [1]: ValueNode<StringImm> __internal_getattr_owner__.trainable_params, [2]: ValueNode<ValueTuple> (__internal_getattr_owner__), [3]: [CNode]942}


subgraph attr:
training : 1
subgraph instance: G-construct.L1CrossEntropyLoss.919 : 000002CD9C2C5EA0
# In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:49/
subgraph @G-construct.L1CrossEntropyLoss.919 parent: [subgraph @construct.L1CrossEntropyLoss.918]() {
  %1([CNode]941) = $(construct.L1CrossEntropyLoss.918):getattr(NullType, "trainable_params")
      : (<TypeType, NoShape>, <String, NoShape>) -> (<Tensor[Float64], (-2)>)
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:48/
  %2(params) = $(construct.L1CrossEntropyLoss.918):%1()
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:48/

#------------------------> 4
  %3([CNode]943) = call @construct.L1CrossEntropyLoss.920(%2, [])
      : (<Tensor[Float64], (-2)>, <List[], ListShape[]>) -> (<null>)
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:49/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:49/
}
# order:
#   1: @G-construct.L1CrossEntropyLoss.919:[CNode]943{[0]: ValueNode<FuncGraph> construct.L1CrossEntropyLoss.920, [1]: params, [2]: ValueNode<ValueList> []}
#   2: @G-construct.L1CrossEntropyLoss.919:[CNode]944{[0]: ValueNode<Primitive> Return, [1]: [CNode]943}


subgraph attr:
training : 1
subgraph instance: construct.L1CrossEntropyLoss.920 : 000002CD9C2C6E90
# In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:49/
subgraph @construct.L1CrossEntropyLoss.920(%para34_iter, %para35_list) {
  %1([CNode]946) = call @ms_next_with_dyn_input_check.945(%para34_iter)
      : (<Tensor[Float64], (-2)>) -> (<Tensor[Float64], (-2)>)
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:49/
  %2([CNode]947) = Switch(%1, call @construct.L1CrossEntropyLoss.912, call @construct.L1CrossEntropyLoss.948)
      : (<Tensor[Float64], (-2)>, <Func, NoShape>, <Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:49/

#------------------------> 5
  %3([CNode]949) = %2()
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:49/
  Return(%3)
      : (<null>)
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:49/
}
# order:
#   1: @construct.L1CrossEntropyLoss.920:[CNode]946{[0]: ValueNode<FuncGraph> ms_next_with_dyn_input_check.945, [1]: iter}
#   2: @construct.L1CrossEntropyLoss.920:[CNode]947{[0]: ValueNode<Primitive> Switch, [1]: [CNode]946, [2]: ValueNode<FuncGraph> construct.L1CrossEntropyLoss.912, [3]: ValueNode<FuncGraph> construct.L1CrossEntropyLoss.948}
#   3: @construct.L1CrossEntropyLoss.920:[CNode]949{[0]: [CNode]947}
#   4: @construct.L1CrossEntropyLoss.920:[CNode]950{[0]: ValueNode<Primitive> Return, [1]: [CNode]949}


subgraph attr:
training : 1
subgraph instance: construct.L1CrossEntropyLoss.912 : 000002CD9C2CC8E0
# In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:49/
subgraph @construct.L1CrossEntropyLoss.912 parent: [subgraph @construct.L1CrossEntropyLoss.920]() {
  %1([CNode]952) = call @ms_next.951(%para34_iter)
      : (<Tensor[Float64], (-2)>) -> (<Tensor[Float64], (-2)>)
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:49/

#------------------------> 6
  %2([CNode]953) = S-Prim-getitem(%1, I64(1))
      : (<Tensor[Float64], (-2)>, <Int64, NoShape>) -> (<null>)
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:49/
  %3([CNode]954) = Switch(Bool(1), call @construct.L1CrossEntropyLoss.955, call @construct.L1CrossEntropyLoss.956)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:49/
  %4([CNode]957) = %3()
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:49/
  %5([CNode]958) = call @construct.L1CrossEntropyLoss.920(%2, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:49/
  Return(%5)
      : (<null>)
      #scope: (Default/network-WithLossCell/_loss_fn-L1CrossEntropyLoss)
      # In file C:\Users\15781\AppData\Local\Temp\ipykernel_26800\1859669102.py:49/
}
# order:
#   1: @construct.L1CrossEntropyLoss.912:[CNode]952{[0]: ValueNode<FuncGraph> ms_next.951, [1]: iter}
#   2: @construct.L1CrossEntropyLoss.912:p{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]952, [2]: ValueNode<Int64Imm> 0}
#   3: @construct.L1CrossEntropyLoss.912:[CNode]953{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]952, [2]: ValueNode<Int64Imm> 1}
#   4: @construct.L1CrossEntropyLoss.912:[CNode]959{[0]: ValueNode<DoSignaturePrimitive> S-Prim-negative, [1]: ValueNode<Int64Imm> 1}
#   5: @construct.L1CrossEntropyLoss.912:[CNode]960{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: [CNode]959}
#   6: @construct.L1CrossEntropyLoss.912:[CNode]961{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Reshape, [1]: p, [2]: [CNode]960}
#   7: @construct.L1CrossEntropyLoss.912:[CNode]962{[0]: ValueNode<ListAppend> MetaFuncGraph-ListAppend.963, [1]: list, [2]: [CNode]961}
#   8: @construct.L1CrossEntropyLoss.912:[CNode]954{[0]: ValueNode<Primitive> Switch, [1]: ValueNode<BoolImm> true, [2]: ValueNode<FuncGraph> construct.L1CrossEntropyLoss.955, [3]: ValueNode<FuncGraph> construct.L1CrossEntropyLoss.956}
#   9: @construct.L1CrossEntropyLoss.912:[CNode]957{[0]: [CNode]954}
#  10: @construct.L1CrossEntropyLoss.912:[CNode]958{[0]: ValueNode<FuncGraph> construct.L1CrossEntropyLoss.920, [1]: [CNode]953, [2]: [CNode]957}
#  11: @construct.L1CrossEntropyLoss.912:[CNode]964{[0]: ValueNode<Primitive> Return, [1]: [CNode]958}


#===============================================================================
# num of function graphs in stack: 7/8 (Ignored 1 internal frames).
